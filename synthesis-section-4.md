## Conclusion

This review has surveyed the landscape of research on procedural justification, market design, and AI governance to assess our capacity to evaluate agentic markets—economic systems where AI agents transact and allocate resources on behalf of human principals. Three key findings emerge from this analysis.

First, existing theoretical frameworks converge on the normative importance of procedural features. Procedural experimentalism demonstrates that certain decision-making procedures involving experimentation can justify normative principles through social learning and iterative refinement (Himmelreich 2023; Anderson 2006). Market design theory reveals how procedural details—information structures, auction rules, matching mechanisms—fundamentally shape fairness and efficiency outcomes, with seemingly minor variations producing dramatically different normative consequences (Roth 2002; Pathak and Sönmez 2013). AI ethics has increasingly emphasized procedural dimensions of algorithmic fairness, shifting from purely outcome-based metrics toward attention to transparency, accountability, and contestability as procedural requirements (Binns 2018; Rahwan 2018). This convergence suggests that evaluating agentic markets requires procedural analysis—but the frameworks developed within each domain do not straightforwardly extend to the AI-mediated market context.

Second, these frameworks fragment by context in ways that leave agentic markets in an evaluative gap. Procedural experimentalism addresses human institutions where participants deliberate and revise values. Market design assumes human market participants with human information processing and strategic capacities. AI ethics predominantly addresses systems making decisions about humans rather than AI agents acting for humans as representatives in economic contexts. Agentic markets fall at the intersection: AI agents representing human interests within market procedures. This intersection generates distinctive challenges that no single framework adequately addresses: Can procedural experiments justify market rules when agents execute procedures? What fairness criteria apply when agents represent humans? How do multi-agent strategic interactions create moral pathologies beyond those in single-agent systems? What role can simulation play in procedural experimentation?

Third, four systematic research gaps emerge from this intersection. The theoretical gap of extending procedural experimentalism to non-human agents requires specifying what counts as moral learning when experimenters are artificial. The normative gap of developing procedural standards for AI market representatives demands integration of market design's fairness criteria with AI ethics' accountability frameworks, reconceptualized for representational contexts. The empirical gap of identifying and mitigating moral pathologies in multi-agent market systems necessitates understanding how strategic interaction among sophisticated AI agents amplifies bias, manipulation, or epistemic injustice. The methodological gap of establishing validity criteria for normative simulation experiments requires determining when computational experiments contribute to procedural justification beyond mere empirical prediction.

The proposed research project fills these gaps by synthesizing procedural experimentalism, market design, AI governance, and computational methods into an integrated approach. It extends procedural experimentalism to agentic markets by operationalizing procedural experiments through controlled simulation: using Magentic Marketplace to systematically vary governance structures, information access, and oversight mechanisms, then evaluating whether iterations reveal stable fairness principles and effective safeguards against pathologies. It develops procedural standards for AI representatives by testing which market design features—transparency requirements, algorithmic auditing, contestability procedures—support legitimate representation when agents negotiate on behalf of humans. It identifies multi-agent moral pathologies through systematic simulation of agent interactions under varying market conditions. It establishes methodological validity through robustness analysis, demonstrating that convergent results across parameter variations provide evidence for normative conclusions.

This represents the first systematic attempt to apply procedural experimentalism to agentic markets, bridging political philosophy, economics, AI ethics, and computational social science. The contributions are both theoretical—extending procedural experimentalism's justificatory framework to AI-mediated contexts—and practical—providing guidance for designing legitimate automated market systems. As AI agents increasingly mediate economic decisions, normative frameworks must evolve beyond human-only institutional analysis or AI systems that classify humans. The research develops new methodology for this evolution: normative evaluation through procedural simulation experiments that investigate when and how AI-mediated markets can be procedurally justified.

The stakes are substantial. Agentic markets are not future speculation but present reality: algorithmic trading dominates financial markets, autonomous procurement systems manage global supply chains, and AI coordination increasingly governs energy grids and resource allocation. Without adequate normative frameworks, we risk either over-regulating—imposing human-designed procedural requirements that prevent beneficial automation—or under-regulating—allowing AI-mediated markets to operate without procedural safeguards against exploitation, bias, or structural injustice. Procedural experimentalism offers a middle path: iterative refinement of governance structures through controlled experimentation that reveals which procedural features support fairness, accountability, and legitimate representation. By extending this framework to computational agents and establishing methodological standards for normative simulation, the research advances both our theoretical understanding of procedural justification and our practical capacity to govern AI-mediated economic systems legitimately. As markets increasingly operate through artificial intelligence, ensuring these systems serve human interests requires not just technical sophistication but normative frameworks adequate to the distinctive challenges of AI representation in economic contexts. This research develops such a framework.
