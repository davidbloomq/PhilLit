# State-of-the-Art Literature Review Outline

**Research Project**: Social Experiments in the Agentic Economy: Procedural Justification and Moral Learning among Artificial Agents

**Date**: 2025-11-12

**Total Literature Base**: 87 papers across 6 domains

**Review Target**: 3000-4000 words, citing 18-24 papers (selective emphasis on key debates and gaps)

---

## Review Structure Summary

**Narrative Arc**: Problem → Theoretical Frameworks → Convergence & Gaps → Project Positioning

**Sections**:
1. Introduction (450 words) - Frame the convergence problem
2. Theoretical Frameworks for Evaluation (1500 words) - Three key frameworks
3. Research Gaps at the Intersection (1000 words) - Four specific gaps
4. Conclusion (450 words) - Project positioning and contributions

**Total**: ~3400 words

**Citation Strategy**:
- Emphasize Domain 1 (procedural experimentalism - core framework) and Domain 4 (AI ethics - moral pathologies)
- Selective citations from other domains where they illuminate key debates or gaps
- ~18-24 total citations (from 87 available), prioritizing High-importance papers

---

## Section 1: Introduction (450 words)

**Purpose**: Frame the research problem as convergence of three developments requiring new normative frameworks

**Content Structure**:

**Opening** (100 words):
- Rise of agentic markets: AI agents transact, negotiate, allocate resources on behalf of humans
- Examples: algorithmic trading, automated procurement, energy grid optimization
- Central question: How do we evaluate these systems normatively when decision-makers are non-human?

**Three Converging Developments** (250 words):

1. **Procedural Experimentalism** (80 words)
   - Recent philosophical framework (Adams & Himmelreich) for justifying normative principles through experimental procedures
   - Moral learning through institutional experimentation
   - Designed for human institutions—what about AI-mediated systems?
   - **Cite**: Himmelreich (2023), Anderson (2006)

2. **Agentic Markets** (80 words)
   - AI agents with increasing sophistication (LLM-based agents show strategic reasoning, negotiation)
   - Not just automated tools but representatives making decisions
   - New market dynamics emerge from agent interactions
   - **Cite**: Park et al. (2023), Wellman et al. (2007), Rahwan et al. (2019)

3. **AI Ethics & Governance Concerns** (90 words)
   - Recognition that AI systems raise distinctive fairness, accountability, legitimacy questions
   - Procedural fairness increasingly emphasized over purely outcome-based approaches
   - Moral pathologies: bias, manipulation, epistemic injustice
   - **Cite**: Binns (2018), Barocas & Selbst (2016), Rahwan (2018)

**Review Scope & Preview** (100 words):
- This review examines how procedural experimentalism might extend to agentic markets
- Section 2: Three theoretical frameworks (procedural experimentalism, market design, AI governance)
- Section 3: Four systematic gaps at their intersection
- Central finding: Existing frameworks address human institutions OR technical AI systems, not AI-mediated markets where agents represent human interests
- Project contribution: Extending procedural experimentalism to agentic contexts through controlled simulation experiments

**Key Papers to Cite** (5-6 papers):
- Himmelreich (2023) - procedural experimentalism for AI
- Anderson (2006) - epistemic experimentalism
- Park et al. (2023) - LLM agents capabilities
- Wellman et al. (2007) OR Rahwan et al. (2019) - agentic markets
- Binns (2018) - procedural fairness in AI
- Barocas & Selbst (2016) OR Rahwan (2018) - AI ethics issues

**Word Target**: 450 words

---

## Section 2: Theoretical Frameworks for Evaluating Agentic Markets (1500 words)

**Purpose**: Establish three key frameworks and show their strengths/limitations for agentic markets

**Structure**: Three subsections examining different approaches to normative evaluation

### Subsection 2.1: Procedural Experimentalism and Social Learning (500 words)

**Content**:

**Core Framework** (150 words):
- Adams & Himmelreich: procedures involving experimentation can justify mid-level normative principles
- Differs from pure proceduralism (Rawls) and outcome-based approaches
- Moral learning through institutional iteration and feedback
- Procedural experiments reveal which principles are action-guiding and stable
- **Cite**: Himmelreich (2023) for AI application, brief ref to Dewey (1927) & Anderson (2006) for experimental tradition

**Conditions for Success** (150 words):
- Requires genuine experimentation (not mere implementation)
- Feedback mechanisms that enable learning
- Reflective agents who can revise principles based on experience
- Assumption: human participants engage in deliberation and value revision
- Connection to epistemic democracy: procedures have epistemic value in discovering normative requirements
- **Cite**: Richardson (2002) on deliberative specification, Estlund (2009) on epistemic proceduralism

**Application Questions** (200 words):
- Can procedural experimentalism work when decision-makers are AI agents?
- Do AI agents engage in "moral learning"? (Functional vs genuine)
- Human oversight vs. agent autonomy: what's required for procedural legitimacy?
- Hybrid systems: humans + agents experiment together, but learning mechanisms unclear
- Market experiments in simulation (Magentic Marketplace) vs. real deployments: both forms of procedural experimentation?
- **Cite**: List & Pettit (2011) on group agency (can agent systems be collective learners?)

**Key Insight for Gaps**:
Procedural experimentalism provides powerful framework but assumes human reflective capacity. Extension to agentic markets requires specifying: (1) what counts as experimentation when agents execute procedures, (2) what learning mechanisms enable normative discovery, (3) what human oversight preserves procedural legitimacy.

### Subsection 2.2: Market Design and Procedural Features (500 words)

**Content**:

**Market Design Principles** (150 words):
- Mechanism design studies how procedural features (auction rules, information structures, matching algorithms) affect outcomes
- Normative concerns: efficiency AND fairness, transparency, stability
- Procedural features as design variables: what information is disclosed, when, to whom?
- Roth's experimental approach: market design requires iterative testing, not just theory
- **Cite**: Roth (2002) on experimental market design, Bergemann & Morris (2019) on information design

**Fairness in Markets** (150 words):
- Multiple fairness criteria often conflict: envy-freeness, proportionality, equal access
- Trade-offs between fairness and efficiency
- Fair division literature establishes normative standards for evaluating allocation procedures
- Randomization as procedural fairness mechanism
- **Cite**: Moulin (2004) OR Budish et al. (2013), Dworkin (2000) on market fairness

**Application to Agentic Markets** (200 words):
- Standard fairness criteria (e.g., envy-freeness) designed for humans—do they apply to AI agents?
- Information design becomes critical: AI agents process information differently than humans
- Transparency for whom? Agents, humans they represent, regulators?
- Strategic sophistication: AI agents may exploit procedural features in ways humans cannot
- Market pathologies: manipulation, bias amplification, herding behaviors among agents
- **Cite**: Wellman (2015) on strategic reasoning changing market dynamics, Pathak & Sonmez (2013) on procedural vulnerability to manipulation

**Key Insight for Gaps**:
Market design provides rich vocabulary for procedural features but focuses on human participants. Agentic markets create unique challenges: agents have different information processing, strategic capabilities, and representational relationships to human principals. Procedural standards need reconsideration.

### Subsection 2.3: AI Ethics and Governance Frameworks (500 words)

**Content**:

**Procedural Fairness in AI** (150 words):
- Shift from purely outcome-based fairness (statistical parity) to procedural concerns
- Transparency, explainability, accountability as procedural requirements
- "Society-in-the-loop" approach: ongoing societal participation in AI governance
- Procedural wrongs: manipulation, opacity, lack of contestability
- **Cite**: Binns (2018) on procedural fairness from political philosophy, Rahwan (2018) on society-in-the-loop, Wachter et al. (2017) on transparency/accountability distinction

**Moral Pathologies** (150 words):
- Algorithmic bias: systematic discrimination encoded in automated systems
- Manipulation: AI systems influencing decisions in hidden ways that bypass autonomy
- Epistemic injustice: systematic discounting of certain voices or perspectives
- Structural wrongs: not just individual harms but systemic oppression
- **Cite**: Barocas & Selbst (2016) on algorithmic discrimination, Susser et al. (2019) on manipulation, Fricker (2007) on epistemic injustice

**Representational Ethics** (200 words):
- When can AI agents legitimately represent human interests?
- Trust and trustworthiness: procedural safeguards that enable warranted trust
- Value alignment: technical alignment (doing what intended) vs normative alignment (doing what should be done)
- Meaningful human control: not direct control but appropriate governance structures
- Fiduciary duties: can AI agents fulfill fiduciary obligations to human principals?
- **Cite**: Gabriel (2020) on value alignment, Santoni de Sio & Van den Hoven (2018) on meaningful control, Svensson (2022) on AI as fiduciary

**Key Insight for Gaps**:
AI ethics literature addresses fairness, accountability, legitimacy in AI systems. But most work focuses on AI making decisions *about* humans (classification, prediction) rather than AI agents acting *for* humans in markets. Representational relationships in economic contexts under-explored. Procedural safeguards need specification for agent-mediated markets.

**Section 2 Summary** (Transition paragraph, ~50 words):
Three frameworks converge on procedural concerns but address different contexts. Procedural experimentalism: human institutions. Market design: human market participants. AI ethics: AI systems making decisions about humans. Agentic markets fall at intersection: AI agents representing humans in market procedures. This intersection reveals systematic gaps.

---

## Section 3: Research Gaps at the Intersection (1000 words)

**Purpose**: Identify four specific, well-defined gaps that the research project addresses

**Structure**: Four gap analyses, each establishing: (1) what's missing, (2) why it matters, (3) how project addresses it

### Gap 1: Extending Procedural Experimentalism to Non-Human Agents (250 words)

**The Gap**:
- Procedural experimentalism designed for human institutions where participants deliberate and revise values
- No existing work extends framework to systems where AI agents execute procedures on behalf of humans
- Central question unanswered: Can procedural experiments generate normative authority when experimenters are non-human?

**Why It Matters**:
- Procedural experimentalism is promising framework for normative justification
- Agentic markets are proliferating—need normative evaluation frameworks
- Traditional outcome-based evaluation insufficient: procedures matter not just results

**Evidence from Literature**:
- Himmelreich (2023) applies procedural experimentalism to AI ethics *tools* but not AI *agents* in markets
- Anderson (2006), Sabel & Zeitlin (2012) focus on human institutional experimentation
- List & Pettit (2011) discuss group agency but don't address moral learning in artificial groups

**How Project Addresses It**:
- Uses Magentic Marketplace to conduct procedural experiments with AI agents
- Investigates whether varying procedural features (information access, transparency, oversight) reveals stable fairness principles
- Tests whether agent-based systems can exhibit functional moral learning through institutional iteration

**Papers Supporting Gap**: Himmelreich (2023), Anderson (2006), List & Pettit (2011)

### Gap 2: Procedural Standards for AI Representatives in Markets (250 words)

**The Gap**:
- Market design literature assumes human participants; AI ethics assumes AI makes decisions *about* humans
- When AI agents represent human interests in markets: which procedural standards apply?
- Representational ethics under-developed for economic agents

**Why It Matters**:
- AI agents negotiate, trade, allocate resources on behalf of humans in growing domains
- Legitimacy of these systems depends on appropriate procedural safeguards
- Wrong procedural standards: either over-regulate (stifle beneficial automation) or under-regulate (enable exploitation)

**Evidence from Literature**:
- Market design fairness criteria (Moulin 2004, Budish et al. 2013) designed for human preferences
- AI ethics focuses on classification/prediction systems (Binns 2018, Barocas & Selbst 2016), not autonomous agents
- Representational duties (Svensson 2022, Santoni de Sio & Van den Hoven 2018) discussed abstractly, not applied to markets
- No integration of market design + AI governance for agentic contexts

**How Project Addresses It**:
- Experimentally evaluates procedural features specific to agentic markets: information filtering by agents, automated negotiation protocols, algorithmic oversight
- Tests whether standard fairness criteria (envy-freeness, proportionality) make sense for agents vs humans
- Develops procedural standards for legitimate AI representation in economic contexts

**Papers Supporting Gap**: Moulin (2004), Binns (2018), Svensson (2022), Gabriel (2020)

### Gap 3: Moral Pathologies in Multi-Agent Market Systems (250 words)

**The Gap**:
- AI ethics identifies pathologies in single AI systems or human-AI interaction
- Agentic markets involve *multi-agent* interaction: agents negotiate with each other, emergent dynamics
- Distinctive pathologies from multi-agent strategic interaction under-explored

**Why It Matters**:
- Multi-agent markets create emergent behaviors not present in single-agent systems
- Strategic interaction among sophisticated AI agents (LLMs) may amplify manipulation, bias, or instability
- Procedural safeguards must address multi-agent dynamics, not just individual agent behavior

**Evidence from Literature**:
- AI ethics pathologies (Barocas & Selbst 2016 bias, Susser et al. 2019 manipulation, Fricker 2007 epistemic injustice) focus on AI-human or AI-about-human cases
- Multi-agent systems literature (Wellman 2007, Rahwan et al. 2019) addresses efficiency and coordination, not normative pathologies
- Agent-based modeling (Epstein & Axtell 1996, Axelrod 1997) studies emergence but not specifically moral pathologies in markets

**How Project Addresses It**:
- Simulates multi-agent market interactions to identify emergent pathologies
- Tests whether procedural interventions (transparency requirements, algorithmic auditing) mitigate multi-agent pathologies
- Connects single-agent pathologies (bias, manipulation) to multi-agent amplification mechanisms

**Papers Supporting Gap**: Barocas & Selbst (2016), Susser et al. (2019), Wellman (2015), Rahwan et al. (2019)

### Gap 4: Simulation as Normative Experimental Methodology (250 words)

**The Gap**:
- Agent-based modeling used for empirical prediction (Epstein & Axtell 1996) or policy analysis, not normative theory
- Procedural experimentalism emphasizes real-world institutional experiments
- Methodological gap: Can simulations of agentic markets validate normative principles?

**Why It Matters**:
- Real-world market experiments limited: high stakes, irreversibility, generalizability issues
- Simulation enables controlled variation of procedural features impossible in real markets
- Need methodological framework for normative simulation experiments

**Evidence from Literature**:
- Computational social science (Macy & Willer 2002, Humphreys 2004) establishes epistemic value of simulation for explanation
- But normative uses under-theorized: validity criteria for normative conclusions unclear
- Roth (2002) emphasizes real market experimentation; simulation role in normative discovery unexplored
- Axelrod (1997) shows norms emerge in simulations but doesn't claim simulations validate norms

**How Project Addresses It**:
- Develops validity criteria for normative simulation experiments in agentic markets
- Uses robustness analysis (Wimsatt 2007): convergence across parameter variations increases confidence
- Positions simulation as complement to theory and real-world tests, not replacement

**Papers Supporting Gap**: Epstein & Axtell (1996), Roth (2002), Humphreys (2004), Wimsatt (2007)

**Section 3 Transition** (50 words):
These four gaps collectively motivate the research project. Existing frameworks address pieces but not their integration. The project synthesizes procedural experimentalism + market design + AI ethics + computational methodology to create new approach: normative evaluation of agentic markets through procedural simulation experiments.

---

## Section 4: Conclusion (450 words)

**Purpose**: Synthesize state-of-the-art and position research project's contributions

**State-of-the-Art Synthesis** (150 words):

**What Literature Establishes**:
- Procedural experimentalism: powerful framework for normative justification through institutional experimentation (Himmelreich, Anderson)
- Market design: rich tools for analyzing procedural features and their normative implications (Roth, Moulin)
- AI ethics: recognition that fairness, accountability, transparency are procedural concerns (Binns, Rahwan)
- Multi-agent systems: AI agents show increasing sophistication in strategic and representational tasks (Park et al., Wellman)

**Key Tensions**:
- Experimentalism assumes human deliberators vs AI agents as procedural executors
- Market design assumes human participants vs increasing AI representation
- AI ethics addresses AI decisions about humans vs AI representatives for humans

**Synthesis**: Convergence on procedural concerns but fragmentation by domain. Integration needed.

**Research Gaps Recap** (100 words):

Four systematic gaps identified:
1. **Theoretical**: Extending procedural experimentalism to non-human agents
2. **Normative**: Procedural standards for AI market representatives
3. **Empirical**: Multi-agent moral pathologies in markets
4. **Methodological**: Simulation for normative experimentation

Gaps share common feature: they arise at *intersections* rather than within established domains. Addressing them requires synthesis across procedural philosophy, market design, AI ethics, and computational methods.

**Project Positioning and Contributions** (150 words):

**The Research Project** fills these gaps by:

1. **Theoretical Extension**: Operationalizes procedural experimentalism for agentic markets, specifying what counts as procedural experiment when agents execute procedures

2. **Normative Framework**: Develops procedural standards for evaluating AI market representatives through controlled variation of governance structures (transparency, oversight, information access)

3. **Empirical Investigation**: Identifies and tests mitigation strategies for multi-agent moral pathologies using Magentic Marketplace simulations

4. **Methodological Innovation**: Establishes validity criteria for normative simulation experiments, combining Roth's experimental approach with computational methods

**Novel Contribution**: First work to systematically apply procedural experimentalism to agentic markets, bridging political philosophy, market design, AI ethics, and computational social science.

**Forward-Looking Conclusion** (50 words):

As AI agents increasingly mediate economic decisions, normative frameworks must evolve beyond human-only or AI-about-human contexts. This research develops new approach to evaluating AI-mediated markets through procedural experimentation, advancing both theoretical understanding and practical guidance for legitimate automation in markets.

---

## Overall Citation Strategy

**Total Papers to Cite**: 18-24 (from 87 available)

**By Domain**:
- Domain 1 (Procedural Experimentalism): 5-6 papers - **Core framework**
  - Must cite: Himmelreich (2023), Anderson (2006)
  - Supporting: Dewey (1927) OR Sabel & Zeitlin (2012), Richardson (2002), Estlund (2009), List & Pettit (2011)

- Domain 2 (Agentic Markets): 3-4 papers - **Technical context**
  - Must cite: Park et al. (2023) OR Wellman et al. (2007), Rahwan et al. (2019)
  - Supporting: Wellman (2015), one other

- Domain 3 (Market Design): 3-4 papers - **Normative standards**
  - Must cite: Roth (2002), Moulin (2004) OR Budish et al. (2013)
  - Supporting: Bergemann & Morris (2019), Pathak & Sonmez (2013) OR Dworkin (2000)

- Domain 4 (AI Ethics): 4-5 papers - **Moral pathologies**
  - Must cite: Binns (2018), Barocas & Selbst (2016), Rahwan (2018)
  - Supporting: Wachter et al. (2017), Susser et al. (2019), Fricker (2007)

- Domain 5 (Human-AI Interaction): 3-4 papers - **Representational ethics**
  - Must cite: Gabriel (2020), Santoni de Sio & Van den Hoven (2018)
  - Supporting: Svensson (2022), one other

- Domain 6 (Simulation): 3-4 papers - **Methodology**
  - Must cite: Epstein & Axtell (1996), Humphreys (2004)
  - Supporting: Roth (2002) [already counted], Wimsatt (2007), Axelrod (1997) OR Macy & Willer (2002)

**By Importance**:
- **High importance**: 16-18 papers (foundational works, recent high-impact)
- **Medium importance**: 2-4 papers (supporting context)
- **Low importance**: 0-2 papers (only if essential for specific point)

**Citation Style**:
- (Author Year) in-text
- Chicago Author-Date bibliography
- Integrate citations analytically, not list-like
- Every citation should advance an argument or establish a gap

---

## Notes for Synthesis Writer

**Integration Strategy**:
- Section 2 weaves three frameworks together, showing convergence on procedural concerns
- Transition from Section 2 to 3 emphasizes intersection gaps
- Gap analysis builds directly on framework limitations established in Section 2

**Tone and Style**:
- Analytical and focused (not encyclopedic)
- Build case for research through strategic insights
- Every paragraph connects to project's core questions
- Emphasize what's *missing* not just what exists

**Technical Concepts Needing Explanation**:
- Procedural experimentalism vs pure proceduralism (brief clarification)
- Envy-freeness and fairness criteria (one-sentence definitions)
- Value alignment (distinguish technical vs normative)
- Generative sufficiency (one sentence if used)

**Balance**:
- Give procedural experimentalism substantial treatment (core framework) but don't neglect other domains
- AI ethics and market design get equal subsection space (500 words each like experimentalism)
- Gap analysis focused: 4 gaps × 250 words each, no more

**Selective Citation Principle**:
- Cite to establish framework, identify debate, or support gap claim
- Don't cite for comprehensiveness
- If a paper doesn't advance the argument → don't include it

**Word Count Discipline**:
- Introduction: max 450 words (more = cuts into analysis space)
- Section 2: ~1500 words (500 per subsection)
- Section 3: ~1000 words (250 per gap)
- Conclusion: ~450 words
- **Total**: 3400 words ± 100

**Quality Standard**:
Would a grant reviewer be convinced that:
1. This is an important research area?
2. Existing work leaves genuine gaps?
3. The project addresses those gaps in novel way?
4. The researcher commands the literature?
