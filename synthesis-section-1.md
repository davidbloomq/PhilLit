## Introduction

Algorithmic trading systems now execute the majority of financial transactions, autonomous procurement agents negotiate supply chain contracts worth billions of dollars, and AI-powered energy management systems coordinate grid resources across regional markets. These **agentic markets**—economic environments where artificial intelligence agents transact, negotiate, and allocate resources on behalf of humans—represent a fundamental shift in how markets operate. Unlike traditional automated systems that merely execute predefined rules, contemporary AI agents exhibit strategic reasoning, adaptive learning, and sophisticated negotiation capabilities (Park et al. 2023; Rahwan et al. 2019). The rise of large language model-based agents has dramatically accelerated this trend, with AI systems now capable of representing human interests in complex multi-party negotiations and resource allocation decisions (Wellman 2007). This transformation raises a central normative question: How should we evaluate these systems when the decision-makers are non-human artificial agents?

This question emerges from the convergence of three distinct intellectual developments. First, political philosophy has recently developed **procedural experimentalism**, a framework arguing that certain decision-making procedures involving experimentation can themselves justify mid-level normative principles through moral learning (Himmelreich 2023; Anderson 2006). Unlike pure proceduralism, which justifies outcomes solely by procedure correctness, or outcome-based approaches that judge procedures instrumentally, procedural experimentalism holds that experimental iterations within institutional contexts can reveal which principles are action-guiding and reflectively stable. This framework was developed for human institutions making collective decisions—but what happens when the institutions are populated by AI agents?

Second, the field of AI ethics and governance has increasingly emphasized **procedural fairness** over purely outcome-based approaches to evaluating automated systems. Binns (2018) demonstrates that algorithmic fairness requires drawing on political philosophy's procedural traditions rather than relying solely on statistical definitions of fairness. Work by Barocas and Selbst (2016) on algorithmic discrimination, Susser et al. (2019) on digital manipulation, and Rahwan's (2018) "society-in-the-loop" framework all recognize that how AI systems make decisions—their procedural features like transparency, accountability, and contestability—matters as much as what decisions they reach. Yet most AI ethics work addresses systems that make decisions *about* humans (classification, prediction, recommendation) rather than AI agents acting *for* humans as representatives in economic contexts.

Third, market design theory provides sophisticated tools for analyzing how procedural features of markets—auction rules, information structures, matching mechanisms—affect both efficiency and fairness (Roth 2002; Moulin 2004). Recent work has shown that seemingly minor procedural variations can have dramatic implications for who benefits and whether manipulation is possible (Pathak and Sönmez 2013). However, market design literature overwhelmingly assumes human participants. The normative implications of AI agents as market participants, particularly when they represent human principals, remain largely unexplored.

These three developments converge on the importance of procedures but fragment by domain. Procedural experimentalism addresses human institutions. Market design addresses human market participants. AI ethics addresses AI systems making decisions about humans. Agentic markets fall at the intersection: AI agents representing human interests within market procedures. This intersection reveals systematic gaps in our normative frameworks.

This review proceeds in three sections. Section 2 examines the three theoretical frameworks in detail, showing how each addresses procedural evaluation but leaves key questions unanswered when extended to agentic markets. Section 3 identifies four specific research gaps that emerge at the intersection of these frameworks. The conclusion synthesizes the state-of-the-art and positions the research project's contributions to filling these gaps. The central finding is that existing frameworks, while sophisticated within their domains, do not integrate to provide normative guidance for AI-mediated markets where agents represent human interests. The proposed research addresses this gap by extending procedural experimentalism to agentic markets through controlled simulation experiments.
