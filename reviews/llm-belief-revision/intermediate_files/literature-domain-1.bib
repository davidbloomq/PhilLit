@comment{
====================================================================
DOMAIN: Classical Belief Revision Theory (AGM and Extensions)
SEARCH_DATE: 2026-01-15
PAPERS_FOUND: 18 total (High: 6, Medium: 9, Low: 3)
SEARCH_SOURCES: SEP, PhilPapers, Semantic Scholar, OpenAlex
====================================================================

DOMAIN_OVERVIEW:

Classical belief revision theory, inaugurated by Alchourron, Gardenfors,
and Makinson's 1985 AGM framework, establishes normative constraints on
how rational agents should modify their beliefs when confronted with new
information. The field centers on three fundamental operations: expansion
(adding new beliefs), contraction (removing beliefs), and revision
(incorporating potentially contradictory information). The AGM postulates
require that belief change satisfy minimal mutilation (change as little
as possible) while maintaining logical consistency.

Key theoretical developments include: (1) Epistemic entrenchment,
introduced by Gardenfors and Makinson (1988), which ranks beliefs by their
relative importance or resistance to change; (2) Grove's sphere models
(1988), providing geometric representation of belief states via systems
of nested spheres representing similarity orderings over possible worlds;
(3) Spohn's ranking theory (1988), offering a numerical alternative to
AGM's qualitative approach through ordinal conditional functions; and
(4) The Darwiche-Pearl postulates (1997) for iterated belief revision,
addressing AGM's limitation to single-step revision.

Major critiques focus on the Recovery postulate (if you contract by p
then revise by p, you return to your original beliefs), which generates
counterexamples in realistic scenarios. The impossibility results
surrounding the Ramsey test for conditionals reveal deep tensions between
belief revision and conditional logic. Recent work identifies fundamental
conflicts between iteration (Darwiche-Pearl postulates) and relevance
(Parikh's axiom), suggesting these two aspects of rational belief change
may be incompatible.

RELEVANCE_TO_PROJECT:

This domain provides the normative framework against which LLM belief
revision must be evaluated. If LLMs are to function as rational agents
that update beliefs in response to new information, their revision
behavior should ideally satisfy AGM rationality postulates. The theory
offers formal tools (epistemic entrenchment, sphere models, ranking
functions) that could model or explain LLM belief states, and identifies
key challenges (iteration, relevance-sensitivity, recovery) that any
belief revision system—including neural networks—must address.

NOTABLE_GAPS:

The classical AGM framework assumes logically omniscient agents with
perfect computational resources and explicitly represented beliefs.
Resource-bounded revision and belief base (non-closed) approaches exist
but remain less developed. The tension between iterated revision and
relevance-sensitivity suggests the AGM tradition may need fundamental
reconceptualization for realistic agents. Application to non-symbolic
systems like neural networks is almost entirely unexplored.

SYNTHESIS_GUIDANCE:

Synthesis should establish AGM as the canonical normative framework while
acknowledging its limitations. Trace the development from basic AGM
(1985) through epistemic entrenchment/Grove spheres (1988) to iterated
revision (1997+) and recent critiques (2017-2025). Emphasize the shift
from postulates (syntactic constraints) to semantic characterizations
(sphere models, ranking functions). Highlight unresolved tensions
(iteration vs relevance) as opportunities for LLM research to contribute
new perspectives on rational belief change.

KEY_POSITIONS:
- AGM orthodoxy (6 papers): Foundational framework with expansion,
  contraction, revision operations and rationality postulates
- Semantic characterizations (5 papers): Grove spheres, ranking theory,
  epistemic entrenchment as representations of belief states
- Iterated revision (4 papers): Darwiche-Pearl postulates and extensions
  for sequential belief change
- Critical perspectives (3 papers): Recovery postulate objections,
  iteration-relevance conflicts, computational complexity

====================================================================
}

@article{alchourron1985logic,
  author = {Alchourr{\'o}n, Carlos E. and G{\"a}rdenfors, Peter and Makinson, David},
  title = {On the logic of theory change: Partial meet contraction and revision functions},
  journal = {Journal of Symbolic Logic},
  year = {1985},
  volume = {50},
  number = {2},
  pages = {510--530},
  doi = {10.2307/2274239},
  note = {
  CORE ARGUMENT: Introduces the AGM framework for belief revision, establishing rationality postulates for three operations—expansion (adding beliefs), contraction (removing beliefs), and revision (accommodating contradictory information). The paper proves that partial meet contraction and revision functions (selecting maximally consistent subsets) satisfy these postulates, and provides representation theorems connecting syntactic postulates to semantic selection functions. This creates a general, versatile formal framework that supersedes earlier, more restrictive approaches to theory change.

  RELEVANCE: This is the foundational paper establishing the normative framework for rational belief change. For evaluating LLM belief revision, AGM postulates provide the canonical rationality constraints: does the LLM's revised belief state satisfy closure, success, consistency, minimal change, and other AGM requirements? The paper's formalization of "minimal mutilation" directly addresses how LLMs should prioritize which beliefs to retain versus abandon when incorporating conflicting information. AGM's limitation to single-step revision leaves open how iterated LLM belief updates should be modeled.

  POSITION: Foundational AGM framework—establishes the orthodox approach to rational belief revision through axiomatic postulates and representation theorems.
  },
  keywords = {AGM-theory, belief-revision, foundational, High}
}

@article{gardenfors1988revisions,
  author = {G{\"a}rdenfors, Peter and Makinson, David},
  title = {Revisions of Knowledge Systems Using Epistemic Entrenchment},
  journal = {Theoretical Aspects of Rationality and Knowledge},
  year = {1988},
  pages = {83--95},
  note = {
  CORE ARGUMENT: Extends AGM by introducing epistemic entrenchment—a binary relation ranking beliefs by relative firmness or resistance to change. The paper proves that every AGM-rational contraction function corresponds to an epistemic entrenchment ordering satisfying five postulates (transitivity, dominance, conjunctiveness, minimality, maximality), and vice versa. This provides a semantic grounding for AGM's syntactic postulates: belief change preserves more entrenched beliefs while sacrificing less entrenched ones when forced to choose.

  RELEVANCE: Epistemic entrenchment offers a concrete mechanism for implementing minimal change in belief revision: rank beliefs by importance, retain the most entrenched. For LLMs, this raises the question of whether neural representations implicitly encode entrenchment orderings—do transformer attention weights, layer activations, or gradient magnitudes correspond to epistemic importance? If LLM belief revision violates entrenchment-based contraction, does this indicate irrational belief change or limitations of the entrenchment framework for distributed representations?

  POSITION: Semantic characterization—provides epistemic entrenchment as the canonical ordering structure underlying AGM-rational contraction.
  },
  keywords = {epistemic-entrenchment, AGM-theory, semantic-characterization, High}
}

@article{darwiche1997logic,
  author = {Darwiche, Adnan and Pearl, Judea},
  title = {On the logic of iterated belief revision},
  journal = {Artificial Intelligence},
  year = {1997},
  volume = {89},
  number = {1-2},
  pages = {1--29},
  doi = {10.1016/s0004-3702(96)00038-0},
  note = {
  CORE ARGUMENT: Addresses AGM's failure to regulate iterated revision by proposing four additional postulates (C1-C4) governing how epistemic states—not just belief sets—should change under sequences of revisions. The postulates require that: (C1) if new information is consistent with current beliefs, simply add it; (C2) if new information contradicts current beliefs, the revision depends on the epistemic state's ordering; (C3) revising by A then B should preserve conditional beliefs about B given A; (C4) revising by A then ¬B should not depend on beliefs about B in the A-revised state. The paper proves these postulates correspond to specific transformations of total preorders over possible worlds.

  RELEVANCE: LLMs undergo iterated belief revision through sequential prompts, fine-tuning, and in-context learning. Do LLM belief updates satisfy Darwiche-Pearl postulates? For instance, does prompting an LLM with A then B preserve the relationship between A and B established in the first prompt (C3)? Or does context-dependence violate these rationality constraints? The DP framework provides testable predictions about how LLM belief states should evolve through interaction sequences, making violations empirically detectable.

  POSITION: Iterated revision orthodoxy—extends AGM to sequential belief change through four additional postulates constraining epistemic state transformations.
  },
  keywords = {iterated-revision, Darwiche-Pearl, AGM-extension, High}
}

@article{spohn2012laws,
  author = {Spohn, Wolfgang},
  title = {The Laws of Belief: Ranking Theory and Its Philosophical Applications},
  journal = {Oxford University Press},
  year = {2012},
  pages = {I--XV, 1--598},
  doi = {10.1093/acprof:oso/9780199697502.001.0001},
  note = {
  CORE ARGUMENT: Develops ranking theory (ordinal conditional functions) as a comprehensive alternative to probabilistic and AGM approaches to belief. Ranking functions assign each possible world a non-negative integer rank representing degrees of disbelief; belief corresponds to rank 0. Conditionalization (revising ranks given new information) satisfies AGM postulates while providing richer structure for iterated revision, conditional reasoning, and non-monotonic inference. The book demonstrates ranking theory resolves problems in causation, decision theory, and philosophy of language that remain intractable for probability or qualitative AGM.

  RELEVANCE: Ranking theory offers a natural bridge between AGM's qualitative framework and LLMs' continuous representations. Could neural network activations or logit distributions be interpreted as ranking functions, mapping possible worlds (or propositions) to degrees of disbelief? Spohn's conditionalization provides a formal account of how rankings should update—does LLM belief revision approximate this process? Unlike binary AGM belief sets, ranking functions capture graded confidence, making them potentially better suited to modeling LLM uncertainty and partial belief.

  POSITION: Ranking theory alternative—provides numerical framework generalizing AGM through ordinal conditional functions representing degrees of disbelief.
  },
  keywords = {ranking-theory, Spohn, AGM-alternative, High}
}

@article{huber2013agm,
  author = {Huber, Franz},
  title = {Belief Revision I: The AGM Theory},
  journal = {Philosophy Compass},
  year = {2013},
  volume = {8},
  number = {7},
  pages = {604--612},
  doi = {10.1111/PHC3.12048},
  note = {
  CORE ARGUMENT: Provides a comprehensive introduction to AGM belief revision theory, explaining the motivation for each AGM postulate and the key representation theorems. The paper clarifies how expansion, contraction, and revision interrelate through the Levi and Harper identities (revision = contraction then expansion; contraction = revision by negation). It explains how epistemic entrenchment and Grove sphere models provide semantic characterizations of AGM-rational revision, making abstract postulates concrete through preference orderings over possible worlds.

  RELEVANCE: This expository article is essential for understanding what AGM rationality demands of belief-revising agents like LLMs. It clarifies the minimal mutilation principle—change as little as possible while accommodating new information—which should constrain how LLMs update beliefs when fine-tuned or prompted with conflicting information. The explanation of Levi/Harper identities reveals that AGM operations are interdefinable, suggesting that testing LLM contraction behavior can reveal whether revision is AGM-rational, and vice versa.

  POSITION: AGM orthodoxy—expository presentation of the canonical AGM framework and its semantic characterizations.
  },
  keywords = {AGM-theory, expository, semantic-characterization, High}
}

@article{booth2022elementary,
  author = {Chandler, Jake and Booth, Richard},
  title = {Elementary Belief Revision Operators},
  journal = {Journal of Philosophical Logic},
  year = {2022},
  volume = {52},
  pages = {267--311},
  doi = {10.1007/s10992-022-09672-6},
  note = {
  CORE ARGUMENT: Investigates what distinguishes the three "canonical" iterated revision operators—natural, restrained, and lexicographic revision—from the infinite space of operators satisfying AGM and Darwiche-Pearl postulates. The paper proves these operators are uniquely characterized by satisfying an Independence of Irrelevant Alternatives (IIA) principle borrowed from social choice theory: the relative preference between two worlds should not depend on properties of other worlds. This IIA condition explains why these three operators are "elementary" or foundational, whereas other DP-consistent operators involve more complex, context-sensitive preference transformations.

  RELEVANCE: If LLM belief revision exhibits elementary operator structure (satisfying IIA), this suggests LLMs implement simple, context-independent preference orderings during belief change. If LLMs violate IIA, their revision behavior depends on irrelevant alternatives in complex ways, potentially indicating non-compositional belief representations. Testing whether LLMs satisfy IIA provides insight into whether their belief revision is structured like canonical AGM operators or follows fundamentally different principles incompatible with classical frameworks.

  POSITION: Iterated revision refinement—characterizes elementary iterated revision operators through Independence of Irrelevant Alternatives principle.
  },
  keywords = {iterated-revision, elementary-operators, IIA, High}
}

@article{rott1992preferential,
  author = {Rott, Hans},
  title = {Preferential belief change using generalized epistemic entrenchment},
  journal = {Journal of Logic, Language and Information},
  year = {1992},
  volume = {1},
  pages = {45--78},
  doi = {10.1007/BF00203386},
  note = {
  CORE ARGUMENT: Generalizes Gardenfors-Makinson epistemic entrenchment by weakening transitivity requirements, allowing non-transitive "incomparabilities" where neither of two beliefs is more entrenched than the other. The paper proves that generalized entrenchment orderings correspond to a broader class of AGM-rational contraction functions than standard entrenchment, and that allowing incomparabilities better models realistic belief change where not all beliefs admit pairwise epistemic comparison. This extension preserves AGM postulates while permitting richer, more flexible entrenchment structures.

  RELEVANCE: Generalized entrenchment may better capture LLM belief structures, which need not exhibit complete transitive entrenchment orderings. If LLM representations encode incomparable beliefs—propositions whose relative importance cannot be definitively ranked—then standard epistemic entrenchment is too restrictive. Testing whether LLM belief revision respects generalized entrenchment (rather than total orderings) reveals whether neural belief representations admit partial, non-transitive structure incompatible with classical AGM semantics.

  POSITION: Semantic characterization refinement—extends epistemic entrenchment to partial orderings with incomparabilities while preserving AGM rationality.
  },
  keywords = {epistemic-entrenchment, generalized-entrenchment, partial-orders, Medium}
}

@article{lindstrom1989epistemic,
  author = {Lindstr{\"o}m, Sten and Rabinowicz, Wlodek},
  title = {Epistemic entrenchment with incomparabilities and relational belief revision},
  journal = {Logic of Theory Change},
  year = {1989},
  pages = {93--126},
  doi = {10.1007/BFb0018418},
  note = {
  CORE ARGUMENT: Proposes relational belief revision as a generalization of AGM that accommodates epistemic entrenchment orderings with incomparabilities (some beliefs are neither more nor less entrenched than others). The paper introduces relational partial meet contraction, where multiple incomparable maximally consistent subsets may exist, and proves representation theorems connecting these syntactic operations to partial epistemic entrenchment orderings. This framework permits more realistic belief structures where not all beliefs admit definitive relative entrenchment rankings.

  RELEVANCE: Relational belief revision may more accurately model LLM belief change if neural representations inherently involve incomparabilities—propositions whose relative importance cannot be definitively ranked due to distributed encoding or context-dependence. If LLM belief states correspond to partial orderings rather than total preorders, classical AGM semantics (which assume complete comparability) are too strong. Testing whether LLM revisions respect relational rather than total entrenchment reveals whether incomparabilities are fundamental to neural belief representation.

  POSITION: Semantic characterization alternative—extends AGM to partial epistemic entrenchment orderings with incomparabilities through relational revision.
  },
  keywords = {epistemic-entrenchment, relational-revision, incomparabilities, Medium}
}

@article{segerberg1995belief,
  author = {Segerberg, Krister},
  title = {Belief Revision From the Point of View of Doxastic Logic},
  journal = {Logic Journal of the IGPL},
  year = {1995},
  volume = {3},
  number = {4},
  pages = {535--553},
  doi = {10.1093/jigpal/3.4.535},
  note = {
  CORE ARGUMENT: Reformulates belief revision as dynamic doxastic logic, treating revision as an operation on doxastic alternatives (possible epistemic states) rather than merely on belief sets. The paper introduces modal operators for belief and revision, proving completeness theorems for dynamic belief revision systems. This logical framework makes explicit the dynamic nature of belief change: revision operations are actions transforming epistemic states, and belief operators range over these transformations. The approach unifies belief revision with dynamic epistemic logic and modal logic traditions.

  RELEVANCE: Doxastic logic provides a modal framework for reasoning about LLM belief revision dynamics. If LLMs have epistemic states (doxastic alternatives representing possible belief configurations), then prompting or fine-tuning constitutes a dynamic operation transforming these alternatives. Does LLM belief revision satisfy the modal axioms Segerberg derives for rational belief change? Violations would indicate that LLM belief dynamics differ structurally from AGM-rational revision, suggesting neural belief states are not adequately modeled by doxastic alternatives and modal operators.

  POSITION: Logical reformulation—reframes belief revision as dynamic doxastic modal logic operating on epistemic states rather than belief sets.
  },
  keywords = {doxastic-logic, dynamic-logic, modal-framework, Medium}
}

@article{aravanis2020incompatibilities,
  author = {Aravanis, Theofanis I. and Peppas, Pavlos and Williams, Mary-Anne},
  title = {Incompatibilities Between Iterated and Relevance-Sensitive Belief Revision},
  journal = {Journal of Artificial Intelligence Research},
  year = {2020},
  volume = {69},
  pages = {85--108},
  doi = {10.1613/jair.1.11871},
  note = {
  CORE ARGUMENT: Proves that Darwiche-Pearl postulates for iterated revision are fundamentally inconsistent with Parikh's relevance-sensitive axiom (P), which requires belief change to ignore logically irrelevant information. The paper demonstrates this incompatibility extends to Dalal's operator and Spohn's conditionalization, implying that iteration and relevance are in "deep conflict" within the AGM paradigm. This impossibility result suggests no single belief revision operator can simultaneously satisfy both DP postulates (regulating sequential revisions) and Parikh's axiom (respecting logical independence), indicating a fundamental tension in rational belief change.

  RELEVANCE: This conflict is directly relevant to LLM belief revision because LLMs undergo iterated belief updates (through sequential prompts or fine-tuning) while also exhibiting context-sensitivity (attending to relevant vs irrelevant information). If iteration and relevance are incompatible, LLMs cannot simultaneously satisfy both DP postulates and Parikh's axiom—any LLM revision behavior will violate one or the other. The paper thus predicts inevitable deviations from classical rationality constraints, and suggests LLM behavior may reveal which constraint (iteration or relevance) is more fundamental to rational belief change.

  POSITION: Critical perspective—demonstrates fundamental incompatibility between iterated revision (DP postulates) and relevance-sensitivity (Parikh's axiom).
  },
  keywords = {iterated-revision, relevance, impossibility-result, High}
}

@article{schwind2022representation,
  author = {Schwind, Nicolas and Konieczny, S{\'e}bastien and P{\'e}rez, Ram{\'o}n},
  title = {On the Representation of Darwiche and Pearl's Epistemic States for Iterated Belief Revision},
  journal = {Proceedings of the Nineteenth International Conference on Principles of Knowledge Representation and Reasoning},
  year = {2022},
  doi = {10.24963/kr.2022/32},
  note = {
  CORE ARGUMENT: Investigates whether total preorders over possible worlds suffice to represent Darwiche-Pearl epistemic states for iterated revision. The paper proves negative results: some DP-consistent operators cannot be represented by total preorders on countable spaces, and even on finite spaces, total preorders are insufficiently expressive. However, under reasonable assumptions, Ordinal Conditional Functions (OCFs/ranking functions) provide a canonical representation—every DP-consistent operator corresponds to an OCF-based epistemic state. This establishes ranking theory as the proper semantic foundation for iterated belief revision.

  RELEVANCE: If DP epistemic states require OCFs rather than total preorders, then modeling LLM belief revision demands richer structure than simple preference orderings. Neural network activations might naturally correspond to OCFs (numerical degrees of disbelief) rather than binary orderings. The paper's negative results suggest that if LLMs satisfy DP postulates, their internal representations must be at least as expressive as OCFs. Testing whether LLM belief states admit OCF representations reveals whether neural architectures implicitly encode the graded belief structure required for rational iterated revision.

  POSITION: Iterated revision semantics—establishes OCFs as canonical representation for Darwiche-Pearl epistemic states, showing total preorders are insufficient.
  },
  keywords = {iterated-revision, OCF, representation-theorem, Medium}
}

@article{stalnaker2009iterated,
  author = {Stalnaker, Robert},
  title = {Iterated Belief Revision},
  journal = {Erkenntnis},
  year = {2009},
  volume = {70},
  pages = {189--209},
  doi = {10.1007/S10670-008-9147-5},
  note = {
  CORE ARGUMENT: Critiques existing approaches to iterated belief revision, arguing that little of substance can be said about iteration constraints at high levels of abstraction lacking explicit representation of meta-information (information about sources of information). The paper challenges specific Darwiche-Pearl postulates through counterexamples, and argues that rational iterated revision depends critically on how agents track the reliability and relationships among information sources. Without meta-information, putative constraints on iteration are either too permissive or implausibly restrictive, making general postulates for iterated revision untenable.

  RELEVANCE: Stalnaker's critique raises fundamental questions about whether LLM belief revision can be evaluated via abstract postulates like DP, independent of how LLMs represent information sources. If iterated revision rationality depends on meta-information (e.g., "this fact came from a reliable source"), then assessing LLM belief change requires understanding how transformers track source reliability across prompts or training data. If LLMs lack explicit meta-information representations, DP postulates may be inapplicable, suggesting alternative frameworks are needed for neural belief revision.

  POSITION: Critical perspective—challenges abstract iterated revision postulates, arguing meta-information about sources is necessary for rational iteration.
  },
  keywords = {iterated-revision, critique, meta-information, Medium}
}

@article{kern-isberner2017strong,
  author = {Kern-Isberner, Gabriele and Brewka, Gerhard},
  title = {Strong Syntax Splitting for Iterated Belief Revision},
  journal = {International Joint Conference on Artificial Intelligence},
  year = {2017},
  pages = {1131--1137},
  doi = {10.24963/ijcai.2017/157},
  note = {
  CORE ARGUMENT: Introduces strong syntax splitting for iterated belief revision, extending the principle that independent sublanguages should revise independently. The paper proves that strong syntax splitting provides additional constraints on iterated revision beyond Darwiche-Pearl postulates, and that conditional preservation (beliefs about conditionals should be preserved when possible during revision) is closely related to syntax splitting. These principles jointly constrain how rational agents should partition belief space during sequential revisions, ensuring modularity and avoiding spurious interdependencies between logically independent domains.

  RELEVANCE: Strong syntax splitting is directly relevant to LLMs because neural networks process factual domains (e.g., history, physics, mathematics) that should exhibit independent revision dynamics—updating beliefs about physics should not affect beliefs about history unless logically connected. If LLMs violate syntax splitting, revisions in one domain spuriously propagate to unrelated domains, indicating non-compositional belief representation. Testing whether LLM belief revision respects modularity constraints reveals whether neural representations encode logical independence structure required for rational belief change.

  POSITION: Iterated revision refinement—extends DP postulates with syntax splitting principle ensuring modularity and independence in belief revision.
  },
  keywords = {iterated-revision, syntax-splitting, modularity, Medium}
}

@article{parikh1999beliefs,
  author = {Parikh, Rohit},
  title = {Beliefs, belief revision, and splitting languages},
  journal = {Logic, Language, and Computation},
  year = {1999},
  pages = {266--278},
  note = {
  CORE ARGUMENT: Introduces the relevance-sensitive axiom (P) for belief revision, requiring that revising by information about domain A should not affect beliefs about logically independent domain B. The paper argues classical AGM revision violates this intuitive principle because it permits arbitrary redistribution of belief across unrelated domains when accommodating new information. Parikh proposes syntactic independence (language splitting) as a constraint on rational revision: belief change should respect the logical independence structure of the language, changing only beliefs directly relevant to new information.

  RELEVANCE: Parikh's relevance principle is critical for evaluating LLM belief revision because neural networks should respect domain independence—e.g., learning new physics facts should not alter beliefs about literature unless logically connected. If LLMs violate axiom (P), they exhibit spurious cross-domain belief propagation during fine-tuning or prompting, indicating problematic non-compositionality. However, Aravanis et al. (2020) prove axiom (P) conflicts with Darwiche-Pearl postulates, suggesting LLMs face an inevitable tradeoff: satisfy iteration constraints or relevance constraints, but not both.

  POSITION: Relevance-sensitive alternative—introduces axiom (P) requiring belief revision respect logical independence and domain splitting.
  },
  keywords = {relevance-sensitive, Parikh-axiom, domain-independence, Medium}
}

@article{dubois1991epistemic,
  author = {Dubois, Didier and Prade, Henri},
  title = {Epistemic Entrenchment and Possibilistic Logic},
  journal = {Artificial Intelligence},
  year = {1991},
  volume = {50},
  pages = {223--239},
  doi = {10.1016/0004-3702(91)90101-O},
  note = {
  CORE ARGUMENT: Establishes formal connections between epistemic entrenchment (from AGM theory) and possibilistic logic, proving that entrenchment orderings correspond to necessity measures in possibility theory. The paper demonstrates that possibilistic logic provides a numerical framework for epistemic entrenchment: each belief receives a necessity degree representing its entrenchment level, and possibilistic conditioning implements AGM-rational belief revision. This unifies AGM's qualitative orderings with a quantitative uncertainty framework distinct from probability theory, offering computational advantages for knowledge representation systems.

  RELEVANCE: Possibilistic logic offers a bridge between AGM's ordinal entrenchment and LLMs' continuous probability distributions. If epistemic entrenchment can be numerically represented via necessity measures, then LLM confidence scores (logits, softmax probabilities) might directly encode entrenchment orderings. The paper's computational focus suggests practical methods for implementing AGM-rational revision in neural systems: condition possibility distributions rather than manipulating symbolic belief sets. This could enable testing whether LLM belief updates approximate possibilistic conditioning and thus respect AGM rationality constraints.

  POSITION: Semantic characterization alternative—connects epistemic entrenchment to possibilistic logic via necessity measures, providing numerical framework.
  },
  keywords = {epistemic-entrenchment, possibilistic-logic, uncertainty, Medium}
}

@article{nayak1994iterated,
  author = {Nayak, Abhaya C.},
  title = {Iterated belief change based on epistemic entrenchment},
  journal = {Erkenntnis},
  year = {1994},
  volume = {41},
  pages = {353--390},
  doi = {10.1007/BF01130759},
  note = {
  CORE ARGUMENT: Proposes a framework for iterated belief revision based on dynamic epistemic entrenchment: both beliefs and their entrenchment orderings change during revision. The paper argues that static entrenchment (where orderings remain fixed across revisions) cannot adequately handle iteration, and introduces principles for how entrenchment relations themselves should be revised when beliefs change. The approach proves that certain natural transformations of entrenchment orderings yield iterated revision operators satisfying desirable properties, though the paper predates Darwiche-Pearl postulates and thus does not address their compatibility with dynamic entrenchment.

  RELEVANCE: Dynamic epistemic entrenchment directly applies to LLMs because fine-tuning and in-context learning alter not just beliefs but also their relative importance—retraining on new data changes which beliefs are resistant to further revision. If LLM entrenchment orderings (assuming they exist) are static, the model cannot adequately handle iterated belief change. Testing whether LLM belief importance rankings shift during sequential updates reveals whether neural systems implement dynamic entrenchment or rely on fixed orderings incompatible with realistic iterated revision.

  POSITION: Iterated revision via entrenchment—proposes dynamic epistemic entrenchment framework where both beliefs and orderings change during revision.
  },
  keywords = {iterated-revision, epistemic-entrenchment, dynamic-entrenchment, Medium}
}

@article{kelly1999iterated,
  author = {Kelly, Kevin T.},
  title = {Iterated Belief Revision, Reliability, and Inductive Amnesia},
  journal = {Erkenntnis},
  year = {1999},
  volume = {50},
  pages = {7--53},
  doi = {10.1023/A:1005444112348},
  note = {
  CORE ARGUMENT: Critiques standard iterated belief revision for inducing "inductive amnesia"—rational agents following AGM/DP postulates can fail to converge to true theories even when the environment is deterministic and evidence is reliable. The paper proves that minimal change principles, while intuitively rational, prevent agents from learning efficiently because they resist abandoning current theories in favor of alternatives requiring more extensive belief reorganization. Kelly argues belief revision should prioritize long-run reliability (convergence to truth) over short-run conservatism (minimal change), suggesting AGM principles may be epistemically suboptimal for inductive learning.

  RELEVANCE: Kelly's critique is directly relevant to LLMs trained via iterated updates (fine-tuning, continual learning). If AGM-style minimal change induces inductive amnesia, then LLMs satisfying AGM postulates may fail to converge to accurate beliefs when learning from sequential data—exactly the problem observed in catastrophic forgetting and continual learning failures. This suggests tension between AGM rationality (preserve beliefs unless forced to change) and inductive rationality (update beliefs to maximize long-run accuracy). LLM belief revision may need to violate AGM postulates to achieve reliable learning.

  POSITION: Critical perspective—argues AGM iterated revision induces inductive amnesia, preventing convergence to truth in learning scenarios.
  },
  keywords = {iterated-revision, critique, inductive-amnesia, Medium}
}

@article{aucher2004combined,
  author = {Aucher, Guillaume},
  title = {A Combined System for Update Logic and Belief Revision},
  journal = {PRIMA},
  year = {2004},
  pages = {1--17},
  doi = {10.1007/978-3-540-32128-6_1},
  note = {
  CORE ARGUMENT: Unifies belief revision (changing beliefs about a static world) and update logic (changing beliefs about a changing world) within a single formal framework. The paper argues that AGM revision and Katsuno-Mendelzon update represent different epistemic attitudes toward new information, and develops a combined system allowing both operations. The framework uses dynamic epistemic logic to distinguish ontic change (world changes) from epistemic change (beliefs change about a static world), proving that revision and update correspond to different accessibility relations in modal models.

  RELEVANCE: Distinguishing revision from update is critical for LLMs because they receive both kinds of information: belief revision (e.g., "Actually, Paris is the capital of France, not Lyon") and world updates (e.g., "The president resigned today"). If LLMs conflate these operations, they will mishandle temporal information and counterfactuals. Testing whether LLMs differentiate revision from update—maintaining separate representations for static facts vs dynamic events—reveals whether neural belief change respects the ontic/epistemic distinction fundamental to rational belief dynamics.

  POSITION: Revision-update unification—combines AGM belief revision and KM update logic, distinguishing epistemic change from ontic change.
  },
  keywords = {belief-revision, update-logic, dynamic-epistemic-logic, Low}
}

@article{giordano2002iterated,
  author = {Giordano, Laura and Gliozzi, Valentina and Olivetti, Nicola},
  title = {Iterated Belief Revision and Conditional Logic},
  journal = {Studia Logica},
  year = {2002},
  volume = {70},
  pages = {23--47},
  doi = {10.1023/A:1014602224874},
  note = {
  CORE ARGUMENT: Proposes a conditional logic IBC for representing iterated belief revision systems, providing semantic models via selection function frameworks and proving completeness theorems. The paper introduces postulates for iterated revision that slightly modify Darwiche-Pearl's approach, and demonstrates that conditional logic provides a natural representation of epistemic states where conditionals encode conditional beliefs preserved or modified during revision. The IBC logic unifies AGM revision with conditional reasoning, making explicit the connections between belief change and conditional semantics.

  RELEVANCE: Conditional logic offers a framework for evaluating LLM reasoning about conditionals under belief revision. If LLMs represent conditional beliefs ("if A then B") that should be preserved or modified during iterated revision, testing whether LLM conditional reasoning satisfies IBC axioms reveals whether neural belief dynamics respect the logical structure linking conditionals to belief change. Violations indicate LLMs handle conditionals non-compositionally, failing to maintain the systematic relationships between conditional beliefs and belief revision that characterize rational epistemic states.

  POSITION: Iterated revision via conditional logic—develops IBC logic for representing iterated belief revision through conditional semantics and selection functions.
  },
  keywords = {iterated-revision, conditional-logic, selection-functions, Low}
}
