{
  "status": "success",
  "source": "openalex",
  "query": "out-of-distribution generalization language models",
  "results": [
    {
      "openalex_id": "W4385572001",
      "doi": "10.18653/v1/2023.findings-acl.806",
      "title": "GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-Distribution Generalization Perspective",
      "authors": [
        {
          "name": "Linyi Yang",
          "openalex_id": "A5035082722",
          "orcid": "https://orcid.org/0000-0003-0667-7349",
          "institutions": [
            "Institute for Advanced Study",
            "Westlake University"
          ]
        },
        {
          "name": "Shuibai Zhang",
          "openalex_id": "A5021587333",
          "institutions": [
            "Westlake University",
            "University of Electronic Science and Technology of China"
          ]
        },
        {
          "name": "Libo Qin",
          "openalex_id": "A5029082837",
          "orcid": "https://orcid.org/0000-0002-3619-675X",
          "institutions": [
            "Central South University"
          ]
        },
        {
          "name": "Yafu Li",
          "openalex_id": "A5032649444",
          "orcid": "https://orcid.org/0000-0002-7895-9997",
          "institutions": [
            "Westlake University"
          ]
        },
        {
          "name": "Yidong Wang",
          "openalex_id": "A5100685716",
          "orcid": "https://orcid.org/0009-0007-9969-8259",
          "institutions": [
            "Westlake University"
          ]
        },
        {
          "name": "Hanmeng Liu",
          "openalex_id": "A5081383763",
          "orcid": "https://orcid.org/0009-0007-1060-6064",
          "institutions": [
            "Westlake University"
          ]
        },
        {
          "name": "Jindong Wang",
          "openalex_id": "A5100700956",
          "orcid": "https://orcid.org/0000-0002-4833-0880",
          "institutions": [
            "Microsoft Research Asia (China)"
          ]
        },
        {
          "name": "Xing Xie",
          "openalex_id": "A5100723568",
          "orcid": "https://orcid.org/0000-0002-1636-4816",
          "institutions": [
            "Microsoft Research Asia (China)"
          ]
        },
        {
          "name": "Yue Zhang",
          "openalex_id": "A5100333738",
          "orcid": "https://orcid.org/0000-0002-6327-5023",
          "institutions": [
            "Westlake University",
            "Institute for Advanced Study"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named GLUE-X for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.",
      "cited_by_count": 19,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2023.findings-acl.806.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 85,
      "url": "https://openalex.org/W4385572001"
    },
    {
      "openalex_id": "W4391767066",
      "doi": "10.48550/arxiv.2402.06599",
      "title": "On the Out-Of-Distribution Generalization of Multimodal Large Language Models",
      "authors": [
        {
          "name": "Xingxuan Zhang",
          "openalex_id": "A5003566728"
        },
        {
          "name": "Jiansheng Li",
          "openalex_id": "A5100631198",
          "orcid": "https://orcid.org/0000-0002-3541-3927"
        },
        {
          "name": "Wenjing Chu",
          "openalex_id": "A5112610378"
        },
        {
          "name": "Junjia Hai",
          "openalex_id": "A5073872544"
        },
        {
          "name": "Renzhe Xu",
          "openalex_id": "A5061888153",
          "orcid": "https://orcid.org/0000-0001-8418-0034"
        },
        {
          "name": "Yuqing Yang",
          "openalex_id": "A5101421201",
          "orcid": "https://orcid.org/0000-0003-3518-5212"
        },
        {
          "name": "Shikai Guan",
          "openalex_id": "A5029958518",
          "orcid": "https://orcid.org/0000-0001-7133-9149"
        },
        {
          "name": "Jiazheng Xu",
          "openalex_id": "A5042981778"
        },
        {
          "name": "Peng Cui",
          "openalex_id": "A5102763494",
          "orcid": "https://orcid.org/0000-0003-0167-7964"
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-02-09",
      "abstract": "We investigate the generalization boundaries of current Multimodal Large Language Models (MLLMs) via comprehensive evaluation under out-of-distribution scenarios and domain-specific tasks. We evaluate their zero-shot generalization across synthetic images, real-world distributional shifts, and specialized datasets like medical and molecular imagery. Empirical results indicate that MLLMs struggle with generalization beyond common training domains, limiting their direct application without adaptation. To understand the cause of unreliable performance, we analyze three hypotheses: semantic misinterpretation, visual feature extraction insufficiency, and mapping deficiency. Results identify mapping deficiency as the primary hurdle. To address this problem, we show that in-context learning (ICL) can significantly enhance MLLMs' generalization, opening new avenues for overcoming generalization barriers. We further explore the robustness of ICL under distribution shifts and show its vulnerability to domain shifts, label shifts, and spurious correlation shifts between in-context examples and test data.",
      "cited_by_count": 6,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2402.06599"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4391767066"
    },
    {
      "openalex_id": "W4309208603",
      "doi": "10.48550/arxiv.2211.08073",
      "title": "GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective",
      "authors": [
        {
          "name": "Linyi Yang",
          "openalex_id": "A5035082722",
          "orcid": "https://orcid.org/0000-0003-0667-7349"
        },
        {
          "name": "Shuibai Zhang",
          "openalex_id": "A5021587333"
        },
        {
          "name": "Libo Qin",
          "openalex_id": "A5029082837",
          "orcid": "https://orcid.org/0000-0002-3619-675X"
        },
        {
          "name": "Yafu Li",
          "openalex_id": "A5032649444",
          "orcid": "https://orcid.org/0000-0002-7895-9997"
        },
        {
          "name": "Yidong Wang",
          "openalex_id": "A5100685716",
          "orcid": "https://orcid.org/0009-0007-9969-8259"
        },
        {
          "name": "Hanmeng Liu",
          "openalex_id": "A5081383763",
          "orcid": "https://orcid.org/0009-0007-1060-6064"
        },
        {
          "name": "Jindong Wang",
          "openalex_id": "A5100700956",
          "orcid": "https://orcid.org/0000-0002-4833-0880"
        },
        {
          "name": "Xing Xie",
          "openalex_id": "A5100723568",
          "orcid": "https://orcid.org/0000-0002-1636-4816"
        },
        {
          "name": "Yue Zhang",
          "openalex_id": "A5100333729",
          "orcid": "https://orcid.org/0000-0002-5214-2268"
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-11-15",
      "abstract": "Pre-trained language models (PLMs) are known to improve the generalization performance of natural language understanding models by leveraging large amounts of data during the pre-training phase. However, the out-of-distribution (OOD) generalization problem remains a challenge in many NLP tasks, limiting the real-world deployment of these methods. This paper presents the first attempt at creating a unified benchmark named GLUE-X for evaluating OOD robustness in NLP models, highlighting the importance of OOD robustness and providing insights on how to measure the robustness of a model and how to improve it. The benchmark includes 13 publicly available datasets for OOD testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly used PLMs, including GPT-3 and GPT-3.5. Our findings confirm the need for improved OOD accuracy in NLP tasks, as significant performance degradation was observed in all settings compared to in-distribution (ID) accuracy.",
      "cited_by_count": 10,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2211.08073"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4309208603"
    },
    {
      "openalex_id": "W4289639938",
      "doi": "10.1109/tpami.2022.3195549",
      "title": "Domain Generalization: A Survey",
      "authors": [
        {
          "name": "Kaiyang Zhou",
          "openalex_id": "A5030812622",
          "orcid": "https://orcid.org/0000-0002-8153-3903",
          "institutions": [
            "Nanyang Technological University"
          ]
        },
        {
          "name": "Ziwei Liu",
          "openalex_id": "A5100406050",
          "orcid": "https://orcid.org/0000-0002-4220-5958",
          "institutions": [
            "Nanyang Technological University"
          ]
        },
        {
          "name": "Yu Qiao",
          "openalex_id": "A5100748135",
          "orcid": "https://orcid.org/0000-0002-1889-2567",
          "institutions": [
            "Shanghai Artificial Intelligence Laboratory",
            "Chinese Academy of Sciences",
            "Shenzhen Institutes of Advanced Technology"
          ]
        },
        {
          "name": "Tao Xiang",
          "openalex_id": "A5014436524",
          "orcid": "https://orcid.org/0000-0002-2530-1059",
          "institutions": [
            "University of Surrey"
          ]
        },
        {
          "name": "Chen Change Loy",
          "openalex_id": "A5005626854",
          "orcid": "https://orcid.org/0000-0001-5345-1591",
          "institutions": [
            "Nanyang Technological University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": "Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d. assumption on source/target data, which is often violated in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Over the last ten years, research in DG has made great progress, leading to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, to name a few; DG has also been studied in various application areas including computer vision, speech recognition, natural language processing, medical imaging, and reinforcement learning. In this paper, for the first time a comprehensive literature review in DG is provided to summarize the developments over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other relevant fields like domain adaptation and transfer learning. Then, we conduct a thorough review into existing methods and theories. Finally, we conclude this survey with insights and discussions on future research directions.",
      "cited_by_count": 954,
      "type": "article",
      "source": {
        "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "type": "journal",
        "issn": [
          "0162-8828",
          "1939-3539",
          "2160-9292"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Domain Adaptation and Few-Shot Learning",
        "COVID-19 diagnosis using AI",
        "Anomaly Detection Techniques and Applications"
      ],
      "referenced_works_count": 310,
      "url": "https://openalex.org/W4289639938"
    },
    {
      "openalex_id": "W4389163154",
      "doi": "10.1145/3611643.3616244",
      "title": "On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code",
      "authors": [
        {
          "name": "Martin Weyssow",
          "openalex_id": "A5107246651",
          "orcid": "https://orcid.org/0000-0002-5987-850X",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al"
          ]
        },
        {
          "name": "Xin Zhou",
          "openalex_id": "A5100424233",
          "orcid": "https://orcid.org/0000-0002-4558-0622",
          "institutions": [
            "Singapore Management University"
          ]
        },
        {
          "name": "Kisub Kim",
          "openalex_id": "A5074029092",
          "orcid": "https://orcid.org/0000-0002-4462-6916",
          "institutions": [
            "Singapore Management University"
          ]
        },
        {
          "name": "David Lo",
          "openalex_id": "A5081036622",
          "orcid": "https://orcid.org/0000-0002-4367-7201",
          "institutions": [
            "Singapore Management University"
          ]
        },
        {
          "name": "Houari Sahraoui",
          "openalex_id": "A5009574640",
          "orcid": "https://orcid.org/0000-0001-6304-9926",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-11-30",
      "abstract": "Pre-trained language models (PLMs) have become a prevalent technique in deep learning for code, utilizing a two-stage pre-training and fine-tuning procedure to acquire general knowledge about code and specialize in a variety of downstream tasks. However, the dynamic nature of software codebases poses a challenge to the effectiveness and robustness of PLMs. In particular, world-realistic scenarios potentially lead to significant differences between the distribution of the pre-training and test data, i.e., distribution shift, resulting in a degradation of the PLM's performance on downstream tasks. In this paper, we stress the need for adapting PLMs of code to software data whose distribution changes over time, a crucial problem that has been overlooked in previous works. The motivation of this work is to consider the PLM in a non-stationary environment, where fine-tuning data evolves over time according to a software evolution scenario. Specifically, we design a scenario where the model needs to learn from a stream of programs containing new, unseen APIs over time. We study two widely used PLM architectures, i.e., a GPT2 decoder and a RoBERTa encoder, on two downstream tasks, API call and API usage prediction. We demonstrate that the most commonly used fine-tuning technique from prior work is not robust enough to handle the dynamic nature of APIs, leading to the loss of previously acquired knowledge i.e., catastrophic forgetting. To address these issues, we implement five continual learning approaches, including replay-based and regularization-based methods. Our findings demonstrate that utilizing these straightforward methods effectively mitigates catastrophic forgetting in PLMs across both downstream tasks while achieving comparable or superior performance.",
      "cited_by_count": 9,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Domain Adaptation and Few-Shot Learning",
        "Topic Modeling",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 40,
      "url": "https://openalex.org/W4389163154"
    },
    {
      "openalex_id": "W4372272424",
      "doi": "10.1109/icassp49357.2023.10095209",
      "title": "Improving the out-of-Distribution Generalization Capability of Language Models: Counterfactually-Augmented Data is not Enough",
      "authors": [
        {
          "name": "Caoyun Fan",
          "openalex_id": "A5006419976",
          "orcid": "https://orcid.org/0000-0001-7360-3468",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Wenqing Chen",
          "openalex_id": "A5100628705",
          "orcid": "https://orcid.org/0000-0002-8739-2216",
          "institutions": [
            "Sun Yat-sen University"
          ]
        },
        {
          "name": "Jidong Tian",
          "openalex_id": "A5110766031",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Yitian Li",
          "openalex_id": "A5101479911",
          "orcid": "https://orcid.org/0000-0001-9714-1368",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Hao He",
          "openalex_id": "A5025662871",
          "orcid": "https://orcid.org/0000-0002-5385-8022",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Yaohui Jin",
          "openalex_id": "A5085787425",
          "orcid": "https://orcid.org/0000-0001-6158-6277",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-05-05",
      "abstract": "Counterfactually-Augmented Data (CAD) has the potential to improve language models' Out-Of-Distribution (OOD) generalization capability, as CAD induces language models to exploit causal features and exclude spurious correlations. However, the empirical results of OOD generalization on CAD are not as efficient as expected. In this paper, we attribute the inefficiency to Myopia Phenomenon caused by CAD: language models only focus on causal features that are edited in the augmentation and exclude other non-edited causal features. As a result, the potential of CAD is not fully exploited. Based on the structural properties of CAD, we design two additional constraints to help language models extract more complete causal features contained in CAD, thus improving the OOD generalization capability. We evaluate our method on two tasks: Sentiment Analysis and Natural Language Inference, and the experimental results demonstrate that our method could unlock CAD's potential and improve language models' OOD generalization capability.",
      "cited_by_count": 5,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "referenced_works_count": 37,
      "url": "https://openalex.org/W4372272424"
    },
    {
      "openalex_id": "W4292198371",
      "doi": "10.1561/116.00000192",
      "title": "Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives",
      "authors": [
        {
          "name": "Xiaofeng Liu",
          "openalex_id": "A5100359288",
          "orcid": "https://orcid.org/0000-0002-4514-2016",
          "institutions": [
            "Gordon Center for Medical Imaging",
            "Massachusetts General Hospital",
            "Harvard University"
          ]
        },
        {
          "name": "Chaehwa Yoo",
          "openalex_id": "A5065116222",
          "orcid": "https://orcid.org/0000-0001-9880-2850",
          "institutions": [
            "Ewha Womans University"
          ]
        },
        {
          "name": "Fangxu Xing",
          "openalex_id": "A5007259734",
          "orcid": "https://orcid.org/0000-0002-0517-0952",
          "institutions": [
            "Massachusetts General Hospital",
            "Gordon Center for Medical Imaging",
            "Harvard University"
          ]
        },
        {
          "name": "Hyejin Oh",
          "openalex_id": "A5102493562",
          "institutions": [
            "Ewha Womans University"
          ]
        },
        {
          "name": "Georges El Fakhri",
          "openalex_id": "A5053436378",
          "orcid": "https://orcid.org/0000-0002-9005-6993",
          "institutions": [
            "Gordon Center for Medical Imaging",
            "Massachusetts General Hospital",
            "Harvard University"
          ]
        },
        {
          "name": "Je\u2010Won Kang",
          "openalex_id": "A5039192390",
          "orcid": "https://orcid.org/0000-0002-1637-9479",
          "institutions": [
            "Ewha Womans University"
          ]
        },
        {
          "name": "Jonghye Woo",
          "openalex_id": "A5101491780",
          "orcid": "https://orcid.org/0000-0002-5621-9218",
          "institutions": [
            "Gordon Center for Medical Imaging",
            "Massachusetts General Hospital",
            "Harvard University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-08-16",
      "abstract": "Deep learning has become the method of choice to tackle real-world problems in different domains, partly because of its ability to learn from data and achieve impressive performance on a wide range of applications. However, its success usually relies on two assumptions: (i) vast troves of labeled datasets are required for accurate model fitting, and (ii) training and testing data are independent and identically distributed. Its performance on unseen target domains, thus, is not guaranteed, especially when encountering out-of-distribution data at the adaptation stage. The performance drop on data in a target domain is a critical problem in deploying deep neural networks that are successfully trained on data in a source domain. Unsupervised domain adaptation (UDA) is proposed to counter this, by leveraging both labeled source domain data and unlabeled target domain data to carry out various tasks in the target domain. UDA has yielded promising results on natural image processing, video analysis, natural language processing, time-series data analysis, medical image analysis, etc. In this review, as a rapidly evolving topic, we provide a systematic comparison of its methods and applications. In addition, the connection of UDA with its closely related tasks, e.g., domain generalization and out-of-distribution detection, has also been discussed. Furthermore, deficiencies in current methods and possible promising directions are highlighted.",
      "cited_by_count": 247,
      "type": "review",
      "source": {
        "name": "APSIPA Transactions on Signal and Information Processing",
        "type": "journal",
        "issn": [
          "2048-7703"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.1561/116.00000192"
      },
      "topics": [
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4292198371"
    },
    {
      "openalex_id": "W3035032873",
      "doi": "10.48550/arxiv.2002.04108",
      "title": "Adversarial Filters of Dataset Biases",
      "authors": [
        {
          "name": "Ronan Le Bras",
          "openalex_id": "A5024879161",
          "orcid": "https://orcid.org/0000-0003-2439-6938",
          "institutions": [
            "Allen Institute"
          ]
        },
        {
          "name": "Swabha Swayamdipta",
          "openalex_id": "A5076880940",
          "orcid": "https://orcid.org/0000-0002-5851-8254",
          "institutions": [
            "Allen Institute"
          ]
        },
        {
          "name": "Chandra Bhagavatula",
          "openalex_id": "A5044250030",
          "orcid": "https://orcid.org/0000-0001-6264-0378"
        },
        {
          "name": "Rowan Zellers",
          "openalex_id": "A5030637764",
          "orcid": "https://orcid.org/0000-0003-1361-9868",
          "institutions": [
            "University of Washington"
          ]
        },
        {
          "name": "Matthew E. Peters",
          "openalex_id": "A5101509445",
          "orcid": "https://orcid.org/0000-0002-2105-2585",
          "institutions": [
            "Allen Institute for Artificial Intelligence"
          ]
        },
        {
          "name": "Ashish Sabharwal",
          "openalex_id": "A5077726785",
          "institutions": [
            "Allen Institute"
          ]
        },
        {
          "name": "Yejin Choi",
          "openalex_id": "A5102992157",
          "orcid": "https://orcid.org/0000-0003-3032-5378",
          "institutions": [
            "University of Washington"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-10",
      "abstract": "Large neural models have demonstrated human-level performance on language and vision benchmarks, while their performance degrades considerably on adversarial or out-of-distribution samples. This raises the question of whether these models have learned to solve a dataset rather than the underlying task by overfitting to spurious dataset biases. We investigate one recently proposed approach, AFLite, which adversarially filters such dataset biases, as a means to mitigate the prevalent overestimation of machine performance. We provide a theoretical understanding for AFLite, by situating it in the generalized framework for optimum bias reduction. We present extensive supporting evidence that AFLite is broadly applicable for reduction of measurable dataset biases, and that models trained on the filtered datasets yield better generalization to out-of-distribution tasks. Finally, filtering results in a large drop in model performance (e.g., from 92% to 62% for SNLI), while human performance still remains high. Our work thus shows that such filtered datasets can pose new research challenges for robust generalization by serving as upgraded benchmarks.",
      "cited_by_count": 125,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2002.04108"
      },
      "topics": [
        "Adversarial Robustness in Machine Learning"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W3035032873"
    },
    {
      "openalex_id": "W4375957737",
      "doi": "10.48550/arxiv.2305.04106",
      "title": "On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code",
      "authors": [
        {
          "name": "Martin Weyssow",
          "openalex_id": "A5107246651",
          "orcid": "https://orcid.org/0000-0002-5987-850X",
          "institutions": [
            "Singapore Management University",
            "Universit\u00e9 de Montr\u00e9al"
          ]
        },
        {
          "name": "Xin Zhou",
          "openalex_id": "A5100424233",
          "orcid": "https://orcid.org/0000-0002-4558-0622",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al",
            "Singapore Management University"
          ]
        },
        {
          "name": "Kisub Kim",
          "openalex_id": "A5074029092",
          "orcid": "https://orcid.org/0000-0002-4462-6916",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al",
            "Singapore Management University"
          ]
        },
        {
          "name": "David Lo",
          "openalex_id": "A5081036622",
          "orcid": "https://orcid.org/0000-0002-4367-7201",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al",
            "Singapore Management University"
          ]
        },
        {
          "name": "Houari Sahraoui",
          "openalex_id": "A5009574640",
          "orcid": "https://orcid.org/0000-0001-6304-9926",
          "institutions": [
            "Singapore Management University",
            "Universit\u00e9 de Montr\u00e9al"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-05-06",
      "abstract": "Pre-trained language models (PLMs) have become a prevalent technique in deep learning for code, utilizing a two-stage pre-training and fine-tuning procedure to acquire general knowledge about code and specialize in a variety of downstream tasks. However, the dynamic nature of software codebases poses a challenge to the effectiveness and robustness of PLMs. In particular, world-realistic scenarios potentially lead to significant differences between the distribution of the pre-training and test data, i.e., distribution shift, resulting in a degradation of the PLM's performance on downstream tasks. In this paper, we stress the need for adapting PLMs of code to software data whose distribution changes over time, a crucial problem that has been overlooked in previous works. The motivation of this work is to consider the PLM in a non-stationary environment, where fine-tuning data evolves over time according to a software evolution scenario. Specifically, we design a scenario where the model needs to learn from a stream of programs containing new, unseen APIs over time. We study two widely used PLM architectures, i.e., a GPT2 decoder and a RoBERTa encoder, on two downstream tasks, API call and API usage prediction. We demonstrate that the most commonly used fine-tuning technique from prior work is not robust enough to handle the dynamic nature of APIs, leading to the loss of previously acquired knowledge i.e., catastrophic forgetting. To address these issues, we implement five continual learning approaches, including replay-based and regularization-based methods. Our findings demonstrate that utilizing these straightforward methods effectively mitigates catastrophic forgetting in PLMs across both downstream tasks while achieving comparable or superior performance.",
      "cited_by_count": 1,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2305.04106"
      },
      "topics": [
        "Domain Adaptation and Few-Shot Learning",
        "Topic Modeling",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 71,
      "url": "https://openalex.org/W4375957737"
    },
    {
      "openalex_id": "W4320087317",
      "doi": "10.48550/arxiv.2207.04901",
      "title": "Exploring Length Generalization in Large Language Models",
      "authors": [
        {
          "name": "Cem Anil",
          "openalex_id": "A5113854698"
        },
        {
          "name": "Yuhuai Wu",
          "openalex_id": "A5024901763"
        },
        {
          "name": "Anders Andreassen",
          "openalex_id": "A5052645158",
          "orcid": "https://orcid.org/0000-0003-3504-3919"
        },
        {
          "name": "Aitor Lewkowycz",
          "openalex_id": "A5019210292"
        },
        {
          "name": "Vedant Misra",
          "openalex_id": "A5030441349"
        },
        {
          "name": "Vinay Ramasesh",
          "openalex_id": "A5059753414",
          "orcid": "https://orcid.org/0000-0003-0625-3327"
        },
        {
          "name": "Ambrose Slone",
          "openalex_id": "A5050581734"
        },
        {
          "name": "Guy Gur-Ari",
          "openalex_id": "A5018113047"
        },
        {
          "name": "Ethan Dyer",
          "openalex_id": "A5010086803",
          "orcid": "https://orcid.org/0000-0001-5391-3100"
        },
        {
          "name": "Behnam Neyshabur",
          "openalex_id": "A5035369215"
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-07-11",
      "abstract": "The ability to extrapolate from short problem instances to longer ones is an important form of out-of-distribution generalization in reasoning tasks, and is crucial when learning from datasets where longer problem instances are rare. These include theorem proving, solving quantitative mathematics problems, and reading/summarizing novels. In this paper, we run careful empirical studies exploring the length generalization capabilities of transformer-based language models. We first establish that naively finetuning transformers on length generalization tasks shows significant generalization deficiencies independent of model scale. We then show that combining pretrained large language models' in-context learning abilities with scratchpad prompting (asking the model to output solution steps before producing an answer) results in a dramatic improvement in length generalization. We run careful failure analyses on each of the learning modalities and identify common sources of mistakes that highlight opportunities in equipping language models with the ability to generalize to longer problems.",
      "cited_by_count": 45,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2207.04901"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Text Readability and Simplification"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4320087317"
    },
    {
      "openalex_id": "W2997616454",
      "doi": null,
      "title": "Adversarial Filters of Dataset Biases",
      "authors": [
        {
          "name": "Ronan Le Bras",
          "openalex_id": "A5024879161",
          "orcid": "https://orcid.org/0000-0003-2439-6938",
          "institutions": [
            "Allen Institute"
          ]
        },
        {
          "name": "Swabha Swayamdipta",
          "openalex_id": "A5076880940",
          "orcid": "https://orcid.org/0000-0002-5851-8254",
          "institutions": [
            "Allen Institute"
          ]
        },
        {
          "name": "Chandra Bhagavatula",
          "openalex_id": "A5044250030",
          "orcid": "https://orcid.org/0000-0001-6264-0378"
        },
        {
          "name": "Rowan Zellers",
          "openalex_id": "A5030637764",
          "orcid": "https://orcid.org/0000-0003-1361-9868",
          "institutions": [
            "University of Washington"
          ]
        },
        {
          "name": "Matthew E. Peters",
          "openalex_id": "A5101509445",
          "orcid": "https://orcid.org/0000-0002-2105-2585",
          "institutions": [
            "Allen Institute for Artificial Intelligence"
          ]
        },
        {
          "name": "Ashish Sabharwal",
          "openalex_id": "A5077726785",
          "institutions": [
            "Allen Institute"
          ]
        },
        {
          "name": "Yejin Choi",
          "openalex_id": "A5102992157",
          "orcid": "https://orcid.org/0000-0003-3032-5378",
          "institutions": [
            "University of Washington"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-10",
      "abstract": "Large neural models have demonstrated human-level performance on language and vision benchmarks, while their performance degrades considerably on adversarial or out-of-distribution samples. This raises the question of whether these models have learned to solve a dataset rather than the underlying task by overfitting to spurious dataset biases. We investigate one recently proposed approach, AFLite, which adversarially filters such dataset biases, as a means to mitigate the prevalent overestimation of machine performance. We provide a theoretical understanding for AFLite, by situating it in the generalized framework for optimum bias reduction. We present extensive supporting evidence that AFLite is broadly applicable for reduction of measurable dataset biases, and that models trained on the filtered datasets yield better generalization to out-of-distribution tasks. Finally, filtering results in a large drop in model performance (e.g., from 92% to 62% for SNLI), while human performance still remains high. Our work thus shows that such filtered datasets can pose new research challenges for robust generalization by serving as upgraded benchmarks.",
      "cited_by_count": 54,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2002.04108.pdf"
      },
      "topics": [
        "Adversarial Robustness in Machine Learning",
        "Multimodal Machine Learning Applications",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 53,
      "url": "https://openalex.org/W2997616454"
    },
    {
      "openalex_id": "W3154669786",
      "doi": "10.48550/arxiv.2104.07478",
      "title": "Unlocking Compositional Generalization in Pre-trained Models Using Intermediate Representations",
      "authors": [
        {
          "name": "Jonathan Herzig",
          "openalex_id": "A5071893787",
          "orcid": "https://orcid.org/0009-0000-7227-6557"
        },
        {
          "name": "Peter Shaw",
          "openalex_id": "A5038781104",
          "orcid": "https://orcid.org/0000-0002-3187-8938"
        },
        {
          "name": "Ming\u2010Wei Chang",
          "openalex_id": "A5076904467",
          "orcid": "https://orcid.org/0000-0002-0137-8895"
        },
        {
          "name": "Kelvin Guu",
          "openalex_id": "A5076669462"
        },
        {
          "name": "Panupong Pasupat",
          "openalex_id": "A5035867340"
        },
        {
          "name": "Yuan Zhang",
          "openalex_id": "A5100368682",
          "orcid": "https://orcid.org/0000-0002-0789-1796"
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-04-15",
      "abstract": "Sequence-to-sequence (seq2seq) models are prevalent in semantic parsing, but have been found to struggle at out-of-distribution compositional generalization. While specialized model architectures and pre-training of seq2seq models have been proposed to address this issue, the former often comes at the cost of generality and the latter only shows limited success. In this paper, we study the impact of intermediate representations on compositional generalization in pre-trained seq2seq models, without changing the model architecture at all, and identify key aspects for designing effective representations. Instead of training to directly map natural language to an executable form, we map to a reversible or lossy intermediate representation that has stronger structural correspondence with natural language. The combination of our proposed intermediate representations and pre-trained models is surprisingly effective, where the best combinations obtain a new state-of-the-art on CFQ (+14.8 accuracy points) and on the template-splits of three text-to-SQL datasets (+15.0 to +19.4 accuracy points). This work highlights that intermediate representations provide an important and potentially overlooked degree of freedom for improving the compositional generalization abilities of pre-trained seq2seq models.",
      "cited_by_count": 51,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2104.07478"
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Genomics and Phylogenetic Studies"
      ],
      "referenced_works_count": 46,
      "url": "https://openalex.org/W3154669786"
    },
    {
      "openalex_id": "W3007295596",
      "doi": "10.48550/arxiv.2002.09253",
      "title": "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven Exploration",
      "authors": [
        {
          "name": "C\u00e9dric Colas",
          "openalex_id": "A5048471111",
          "orcid": "https://orcid.org/0000-0003-0212-427X"
        },
        {
          "name": "Tristan Karch",
          "openalex_id": "A5019224674",
          "orcid": "https://orcid.org/0000-0002-9931-1524"
        },
        {
          "name": "Nicolas Lair",
          "openalex_id": "A5037265152",
          "orcid": "https://orcid.org/0000-0002-0608-0297",
          "institutions": [
            "Temple College"
          ]
        },
        {
          "name": "Jean-Michel Dussoux",
          "openalex_id": "A5047724805",
          "institutions": [
            "Temple College"
          ]
        },
        {
          "name": "Cl\u00e9ment Moulin-Frier",
          "openalex_id": "A5018010486",
          "orcid": "https://orcid.org/0000-0002-7258-7256"
        },
        {
          "name": "Peter Ford Dominey",
          "openalex_id": "A5061623438",
          "orcid": "https://orcid.org/0000-0002-9318-179X",
          "institutions": [
            "Institut National de Recherche en Sant\u00e9 Publique"
          ]
        },
        {
          "name": "Pierre-Yves Oudeyer",
          "openalex_id": "A5085903884",
          "orcid": "https://orcid.org/0000-0002-1277-130X",
          "institutions": [
            "\u00c9cole Nationale Sup\u00e9rieure de Techniques Avanc\u00e9es",
            "Universit\u00e9 de Bordeaux"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-21",
      "abstract": "Developmental machine learning studies how artificial agents can model the way children learn open-ended repertoires of skills. Such agents need to create and represent goals, select which ones to pursue and learn to achieve them. Recent approaches have considered goal spaces that were either fixed and hand-defined or learned using generative models of states. This limited agents to sample goals within the distribution of known effects. We argue that the ability to imagine out-of-distribution goals is key to enable creative discoveries and open-ended learning. Children do so by leveraging the compositionality of language as a tool to imagine descriptions of outcomes they never experienced before, targeting them as goals during play. We introduce IMAGINE, an intrinsically motivated deep reinforcement learning architecture that models this ability. Such imaginative agents, like children, benefit from the guidance of a social peer who provides language descriptions. To take advantage of goal imagination, agents must be able to leverage these descriptions to interpret their imagined out-of-distribution goals. This generalization is made possible by modularity: a decomposition between learned goal-achievement reward function and policy relying on deep sets, gated attention and object-centered representations. We introduce the Playground environment and study how this form of goal imagination improves generalization and exploration over agents lacking this capacity. In addition, we identify the properties of goal imagination that enable these results and study the impacts of modularity and social interactions.",
      "cited_by_count": 56,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2002.09253"
      },
      "topics": [
        "Child and Animal Learning Development",
        "Language and cultural evolution",
        "Reinforcement Learning in Robotics"
      ],
      "referenced_works_count": 77,
      "url": "https://openalex.org/W3007295596"
    },
    {
      "openalex_id": "W3177575812",
      "doi": "10.18653/v1/2022.acl-long.256",
      "title": "An Investigation of the (In)effectiveness of Counterfactually Augmented Data",
      "authors": [
        {
          "name": "Nitish Joshi",
          "openalex_id": "A5008353163",
          "institutions": [
            "New York University"
          ]
        },
        {
          "name": "He He",
          "openalex_id": "A5100775952",
          "orcid": "https://orcid.org/0000-0002-9118-2449",
          "institutions": [
            "New York University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": "While pretrained language models achieve excellent performance on natural language understanding benchmarks, they tend to rely on spurious correlations and generalize poorly to out-of-distribution (OOD) data. Recent work has explored using counterfactually-augmented data (CAD)\u2014data generated by minimally perturbing examples to flip the ground-truth label\u2014to identify robust features that are invariant under distribution shift. However, empirical results using CAD during training for OOD generalization have been mixed. To explain this discrepancy, through a toy theoretical example and empirical analysis on two crowdsourced CAD datasets, we show that: (a) while features perturbed in CAD are indeed robust features, it may prevent the model from learning unperturbed robust features; and (b) CAD may exacerbate existing spurious correlations in the data. Our results thus show that the lack of perturbation diversity limits CAD's effectiveness on OOD generalization, calling for innovative crowdsourcing procedures to elicit diverse perturbation of examples.",
      "cited_by_count": 32,
      "type": "article",
      "source": {
        "name": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "type": "conference",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://aclanthology.org/2022.acl-long.256.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 49,
      "url": "https://openalex.org/W3177575812"
    },
    {
      "openalex_id": "W4308939312",
      "doi": "10.3233/sw-223228",
      "title": "Is neuro-symbolic AI meeting its promises in natural language processing? A\u00a0structured review",
      "authors": [
        {
          "name": "Kyle Hamilton",
          "openalex_id": "A5010412546",
          "orcid": "https://orcid.org/0000-0003-0809-0664",
          "institutions": [
            "Technological University Dublin"
          ]
        },
        {
          "name": "Aparna Nayak",
          "openalex_id": "A5026378728",
          "orcid": "https://orcid.org/0000-0002-8135-3515",
          "institutions": [
            "Technological University Dublin"
          ]
        },
        {
          "name": "Bojan Bo\u017ei\u0107",
          "openalex_id": "A5088807073",
          "orcid": "https://orcid.org/0000-0002-4420-1029",
          "institutions": [
            "Technological University Dublin"
          ]
        },
        {
          "name": "Luca Longo",
          "openalex_id": "A5024458365",
          "orcid": "https://orcid.org/0000-0002-2718-5426",
          "institutions": [
            "Technological University Dublin"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-11-11",
      "abstract": "Advocates for Neuro-Symbolic Artificial Intelligence (NeSy) assert that combining deep learning with symbolic reasoning will lead to stronger AI than either paradigm on its own. As successful as deep learning has been, it is generally accepted that even our best deep learning systems are not very good at abstract reasoning. And since reasoning is inextricably linked to language, it makes intuitive sense that Natural Language Processing (NLP), would be a particularly well-suited candidate for NeSy. We conduct a structured review of studies implementing NeSy for NLP, with the aim of answering the question of whether NeSy is indeed meeting its promises: reasoning, out-of-distribution generalization, interpretability, learning and reasoning from small data, and transferability to new domains. We examine the impact of knowledge representation, such as rules and semantic networks, language structure and relational structure, and whether implicit or explicit reasoning contributes to higher promise scores. We find that systems where logic is compiled into the neural network lead to the most NeSy goals being satisfied, while other factors such as knowledge representation, or type of neural architecture do not exhibit a clear correlation with goals being met. We find many discrepancies in how reasoning is defined, specifically in relation to human level reasoning, which impact decisions about model architectures and drive conclusions which are not always consistent across studies. Hence we advocate for a more methodical approach to the application of theories of human reasoning as well as the development of appropriate benchmarks, which we hope can lead to a better understanding of progress in the field. We make our data and code available on github for further analysis.11 https://github.com/kyleiwaniec/neuro-symbolic-ai-systematic-review",
      "cited_by_count": 67,
      "type": "review",
      "source": {
        "name": "Semantic Web",
        "type": "journal",
        "issn": [
          "1570-0844",
          "2210-4968"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://content.iospress.com:443/download/semantic-web/sw223228?id=semantic-web%2Fsw223228"
      },
      "topics": [
        "Topic Modeling",
        "Explainable Artificial Intelligence (XAI)",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 138,
      "url": "https://openalex.org/W4308939312"
    },
    {
      "openalex_id": "W4284701759",
      "doi": "10.48550/arxiv.2207.02098",
      "title": "Neural Networks and the Chomsky Hierarchy",
      "authors": [
        {
          "name": "Gr\u00e9goire Del\u00e9tang",
          "openalex_id": "A5059962909"
        },
        {
          "name": "Anian Ruoss",
          "openalex_id": "A5077124139",
          "orcid": "https://orcid.org/0000-0002-8616-2558"
        },
        {
          "name": "Jordi Grau-Moya",
          "openalex_id": "A5026686188"
        },
        {
          "name": "Tim Genewein",
          "openalex_id": "A5013602545",
          "orcid": "https://orcid.org/0000-0001-8039-4027"
        },
        {
          "name": "Li Kevin Wenliang",
          "openalex_id": "A5017305728",
          "orcid": "https://orcid.org/0000-0001-7090-3078"
        },
        {
          "name": "Elliot Catt",
          "openalex_id": "A5020795308",
          "orcid": "https://orcid.org/0000-0001-9411-927X"
        },
        {
          "name": "Marcus H\u00fctter",
          "openalex_id": "A5073944062",
          "orcid": "https://orcid.org/0000-0002-3263-4097"
        },
        {
          "name": "Shane Legg",
          "openalex_id": "A5008987732"
        },
        {
          "name": "Pedro A. Ortega",
          "openalex_id": "A5111830874"
        },
        {
          "name": "Veness, Joel",
          "openalex_id": ""
        },
        {
          "name": "Ortega, Pedro A.",
          "openalex_id": ""
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-07-05",
      "abstract": "Reliable generalization lies at the heart of safe ML and AI. However, understanding when and how neural networks generalize remains one of the most important unsolved problems in the field. In this work, we conduct an extensive empirical study (20'910 models, 15 tasks) to investigate whether insights from the theory of computation can predict the limits of neural network generalization in practice. We demonstrate that grouping tasks according to the Chomsky hierarchy allows us to forecast whether certain architectures will be able to generalize to out-of-distribution inputs. This includes negative results where even extensive amounts of data and training time never lead to any non-trivial generalization, despite models having sufficient capacity to fit the training data perfectly. Our results show that, for our subset of tasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can solve regular and counter-language tasks, and only networks augmented with structured memory (such as a stack or memory tape) can successfully generalize on context-free and context-sensitive tasks.",
      "cited_by_count": 45,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2207.02098"
      },
      "topics": [
        "Ferroelectric and Negative Capacitance Devices",
        "Topic Modeling",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4284701759"
    },
    {
      "openalex_id": "W3140854437",
      "doi": "10.1186/s40537-021-00444-8",
      "title": "Review of deep learning: concepts, CNN architectures, challenges, applications, future directions",
      "authors": [
        {
          "name": "Laith Alzubaidi",
          "openalex_id": "A5102889969",
          "orcid": "https://orcid.org/0000-0002-7296-5413",
          "institutions": [
            "Queensland University of Technology"
          ]
        },
        {
          "name": "Jinglan Zhang",
          "openalex_id": "A5101979224",
          "orcid": "https://orcid.org/0000-0001-6459-2963",
          "institutions": [
            "Queensland University of Technology"
          ]
        },
        {
          "name": "Amjad J. Humaidi",
          "openalex_id": "A5016153721",
          "orcid": "https://orcid.org/0000-0002-9071-1329",
          "institutions": [
            "University of Technology - Iraq"
          ]
        },
        {
          "name": "Ayad Q. Al-Dujaili",
          "openalex_id": "A5052471696",
          "orcid": "https://orcid.org/0000-0002-1126-3290",
          "institutions": [
            "Middle Technical University"
          ]
        },
        {
          "name": "Ye Duan",
          "openalex_id": "A5101430356",
          "orcid": "https://orcid.org/0000-0002-1166-7703",
          "institutions": [
            "University of Missouri"
          ]
        },
        {
          "name": "Omran Al-Shamma",
          "openalex_id": "A5008534489",
          "orcid": "https://orcid.org/0000-0001-5930-6176",
          "institutions": [
            "University of Information Technology and Communications"
          ]
        },
        {
          "name": "Jos\u00e9 Santamar\u00eda",
          "openalex_id": "A5010765865",
          "orcid": "https://orcid.org/0000-0002-2022-6838",
          "institutions": [
            "Universidad de Ja\u00e9n"
          ]
        },
        {
          "name": "Mohammed A. Fadhel",
          "openalex_id": "A5090966997",
          "orcid": "https://orcid.org/0000-0001-9877-049X",
          "institutions": [
            "Thi Qar University"
          ]
        },
        {
          "name": "Muthana Al\u2010Amidie",
          "openalex_id": "A5036536042",
          "orcid": "https://orcid.org/0000-0002-8116-1871",
          "institutions": [
            "University of Missouri"
          ]
        },
        {
          "name": "Laith Farhan",
          "openalex_id": "A5059266881",
          "orcid": "https://orcid.org/0000-0001-8256-7323",
          "institutions": [
            "Manchester Metropolitan University"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-03-31",
      "abstract": null,
      "cited_by_count": 6768,
      "type": "article",
      "source": {
        "name": "Journal Of Big Data",
        "type": "journal",
        "issn": [
          "2196-1115"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-021-00444-8"
      },
      "topics": [
        "Advanced Neural Network Applications",
        "COVID-19 diagnosis using AI",
        "Anomaly Detection Techniques and Applications"
      ],
      "referenced_works_count": 362,
      "url": "https://openalex.org/W3140854437"
    },
    {
      "openalex_id": "W3110664450",
      "doi": "10.1609/aaai.v35i15.17601",
      "title": "MASKER: Masked Keyword Regularization for Reliable Text Classification",
      "authors": [
        {
          "name": "Seung Jun Moon",
          "openalex_id": "A5058020556",
          "orcid": "https://orcid.org/0000-0003-1995-5723",
          "institutions": [
            "Korea Advanced Institute of Science and Technology",
            "Kootenay Association for Science & Technology"
          ]
        },
        {
          "name": "Sangwoo Mo",
          "openalex_id": "A5050194076",
          "orcid": "https://orcid.org/0000-0002-3141-7859",
          "institutions": [
            "Kootenay Association for Science & Technology",
            "Korea Advanced Institute of Science and Technology"
          ]
        },
        {
          "name": "Kimin Lee",
          "openalex_id": "A5033571780",
          "orcid": "https://orcid.org/0000-0001-9017-3084",
          "institutions": [
            "Berkeley College",
            "University of California, Berkeley"
          ]
        },
        {
          "name": "Jaeho Lee",
          "openalex_id": "A5100331196",
          "orcid": "https://orcid.org/0000-0002-2735-0647",
          "institutions": [
            "Korea Advanced Institute of Science and Technology",
            "Kootenay Association for Science & Technology"
          ]
        },
        {
          "name": "Jinwoo Shin",
          "openalex_id": "A5102928677",
          "orcid": "https://orcid.org/0000-0003-4313-4669",
          "institutions": [
            "Kootenay Association for Science & Technology",
            "Korea Advanced Institute of Science and Technology"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-05-18",
      "abstract": "Pre-trained language models have achieved state-of-the-art accuracies on various text classification tasks, e.g., sentiment analysis, natural language inference, and semantic textual similarity. However, the reliability of the fine-tuned text classifiers is an often underlooked performance criterion. For instance, one may desire a model that can detect out-of-distribution (OOD) samples (drawn far from training distribution) or be robust against domain shifts. We claim that one central obstacle to the reliability is the over-reliance of the model on a limited number of keywords, instead of looking at the whole context. In particular, we find that (a) OOD samples often contain in-distribution keywords, while (b) cross-domain samples may not always contain keywords; over-relying on the keywords can be problematic for both cases. In light of this observation, we propose a simple yet effective fine-tuning method, coined masked keyword regularization (MASKER), that facilitates context-based prediction. MASKER regularizes the model to reconstruct the keywords from the rest of the words and make low-confidence predictions without enough context. When applied to various pre-trained language models (e.g., BERT, RoBERTa, and ALBERT), we demonstrate that MASKER improves OOD detection and cross-domain generalization without degrading classification accuracy. Code is available at https://github.com/alinlab/MASKER.",
      "cited_by_count": 28,
      "type": "article",
      "source": {
        "name": "Proceedings of the AAAI Conference on Artificial Intelligence",
        "type": "conference",
        "issn": [
          "2159-5399",
          "2374-3468"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "diamond",
        "oa_url": "https://ojs.aaai.org/index.php/AAAI/article/download/17601/17408"
      },
      "topics": [
        "Topic Modeling",
        "Sentiment Analysis and Opinion Mining",
        "Text and Document Classification Technologies"
      ],
      "referenced_works_count": 74,
      "url": "https://openalex.org/W3110664450"
    },
    {
      "openalex_id": "W4285787204",
      "doi": "10.48550/arxiv.2207.07411",
      "title": "Plex: Towards Reliability using Pretrained Large Model Extensions",
      "authors": [
        {
          "name": "Dustin Tran",
          "openalex_id": "A5081819708",
          "orcid": "https://orcid.org/0000-0002-3715-5378"
        },
        {
          "name": "Jeremiah Liu",
          "openalex_id": "A5054327137"
        },
        {
          "name": "Michael W. Dusenberry",
          "openalex_id": "A5050114946"
        },
        {
          "name": "Du Phan",
          "openalex_id": "A5102448182"
        },
        {
          "name": "Mark Collier",
          "openalex_id": "A5058235234",
          "orcid": "https://orcid.org/0000-0003-1391-9473"
        },
        {
          "name": "Jie Ren",
          "openalex_id": "A5100720534",
          "orcid": "https://orcid.org/0000-0001-9918-3000"
        },
        {
          "name": "Kehang Han",
          "openalex_id": "A5032655543",
          "orcid": "https://orcid.org/0000-0002-0628-5305"
        },
        {
          "name": "Zi Wang",
          "openalex_id": "A5100338332",
          "orcid": "https://orcid.org/0000-0002-5081-661X"
        },
        {
          "name": "Zelda Mariet",
          "openalex_id": "A5047711237"
        },
        {
          "name": "Huiyi Hu",
          "openalex_id": "A5070231479",
          "orcid": "https://orcid.org/0000-0002-4398-5167"
        },
        {
          "name": "Neil Band",
          "openalex_id": "A5030721728"
        },
        {
          "name": "Tim G. J. Rudner",
          "openalex_id": "A5031809940"
        },
        {
          "name": "Karan Singhal",
          "openalex_id": "A5027454515",
          "orcid": "https://orcid.org/0000-0001-9002-7490"
        },
        {
          "name": "Zachary Nado",
          "openalex_id": "A5016611202"
        },
        {
          "name": "Joost van Amersfoort",
          "openalex_id": "A5030606900"
        },
        {
          "name": "Andreas Kirsch",
          "openalex_id": "A5091107812",
          "orcid": "https://orcid.org/0000-0003-3578-7504"
        },
        {
          "name": "Rodolphe Jenatton",
          "openalex_id": "A5033851429"
        },
        {
          "name": "Nithum Thain",
          "openalex_id": "A5084311372",
          "orcid": "https://orcid.org/0000-0002-7367-0916"
        },
        {
          "name": "Honglin Yuan",
          "openalex_id": "A5101463909",
          "orcid": "https://orcid.org/0000-0002-5234-8549"
        },
        {
          "name": "Kelly Buchanan",
          "openalex_id": "A5006530776",
          "orcid": "https://orcid.org/0000-0002-7819-0583"
        },
        {
          "name": "Kevin Murphy",
          "openalex_id": "A5044098731",
          "orcid": "https://orcid.org/0000-0001-8982-3641"
        },
        {
          "name": "D. Sculley",
          "openalex_id": "A5019844381"
        },
        {
          "name": "Yarin Gal",
          "openalex_id": "A5029186201",
          "orcid": "https://orcid.org/0000-0002-2733-2078"
        },
        {
          "name": "Zoubin Ghahramani",
          "openalex_id": "A5010820865",
          "orcid": "https://orcid.org/0000-0002-7464-6475"
        },
        {
          "name": "Jasper Snoek",
          "openalex_id": "A5112347601"
        },
        {
          "name": "Balaji Lakshminarayanan",
          "openalex_id": "A5012859570",
          "orcid": "https://orcid.org/0000-0002-3334-1659"
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-07-15",
      "abstract": "A recent trend in artificial intelligence is the use of pretrained models for language and vision tasks, which have achieved extraordinary performance but also puzzling failures. Probing these models' abilities in diverse ways is therefore critical to the field. In this paper, we explore the reliability of models, where we define a reliable model as one that not only achieves strong predictive performance but also performs well consistently over many decision-making tasks involving uncertainty (e.g., selective prediction, open set recognition), robust generalization (e.g., accuracy and proper scoring rules such as log-likelihood on in- and out-of-distribution datasets), and adaptation (e.g., active learning, few-shot uncertainty). We devise 10 types of tasks over 40 datasets in order to evaluate different aspects of reliability on both vision and language domains. To improve reliability, we developed ViT-Plex and T5-Plex, pretrained large model extensions for vision and language modalities, respectively. Plex greatly improves the state-of-the-art across reliability tasks, and simplifies the traditional protocol as it improves the out-of-the-box performance and does not require designing scores or tuning the model for each task. We demonstrate scaling effects over model sizes up to 1B parameters and pretraining dataset sizes up to 4B examples. We also demonstrate Plex's capabilities on challenging tasks including zero-shot open set recognition, active learning, and uncertainty in conversational language understanding.",
      "cited_by_count": 38,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2207.07411"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Topic Modeling",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4285787204"
    },
    {
      "openalex_id": "W2136893259",
      "doi": "10.21832/9781800417151-006",
      "title": "4 Research Methods: Quantitative and Qualitative Approaches",
      "authors": [
        {
          "name": "Olive M. Mugenda",
          "openalex_id": "A5071502461",
          "orcid": "https://orcid.org/0000-0002-6804-8882"
        },
        {
          "name": "Jasone Cenoz",
          "openalex_id": ""
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-11-17",
      "abstract": null,
      "cited_by_count": 5005,
      "type": "book-chapter",
      "source": {
        "name": "Multilingual Matters eBooks",
        "type": "ebook platform",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://www.degruyter.com/document/doi/10.21832/9781800417151-006/pdf"
      },
      "topics": [],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W2136893259"
    },
    {
      "openalex_id": "W4389518756",
      "doi": "10.18653/v1/2023.emnlp-main.306",
      "title": "Prompting is not a substitute for probability measurements in large language models",
      "authors": [
        {
          "name": "Jennifer Hu",
          "openalex_id": "A5104474320",
          "orcid": "https://orcid.org/0000-0003-4075-6876",
          "institutions": [
            "Harvard University Press"
          ]
        },
        {
          "name": "Roger L\u00e9vy",
          "openalex_id": "A5090215557",
          "orcid": "https://orcid.org/0000-0002-4493-8864",
          "institutions": [
            "Institute of Cognitive and Brain Sciences",
            "Massachusetts Institute of Technology"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "Prompting is now a dominant method for evaluating the linguistic knowledge of large language models (LLMs). While other methods directly read out models' probability distributions over strings, prompting requires models to access this internal information by processing linguistic input, thereby implicitly testing a new type of emergent ability: metalinguistic judgment. In this study, we compare metalinguistic prompting and direct probability measurements as ways of measuring models' linguistic knowledge. Broadly, we find that LLMs' metalinguistic judgments are inferior to quantities directly derived from representations. Furthermore, consistency gets worse as the prompt query diverges from direct measurements of next-word probabilities. Our findings suggest that negative results relying on metalinguistic prompts cannot be taken as conclusive evidence that an LLM lacks a particular linguistic generalization. Our results also highlight the value that is lost with the move to closed APIs where access to probability distributions is limited.",
      "cited_by_count": 27,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2023.emnlp-main.306.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Speech and dialogue systems"
      ],
      "referenced_works_count": 48,
      "url": "https://openalex.org/W4389518756"
    },
    {
      "openalex_id": "W4312457137",
      "doi": "10.1007/978-3-031-20059-5_6",
      "title": "Rethinking Data Augmentation for\u00a0Robust Visual Question Answering",
      "authors": [
        {
          "name": "Long Chen",
          "openalex_id": "A5100336360",
          "orcid": "https://orcid.org/0000-0001-6148-9709",
          "institutions": [
            "Columbia University"
          ]
        },
        {
          "name": "Yuhang Zheng",
          "openalex_id": "A5030295721",
          "orcid": "https://orcid.org/0000-0001-9628-1940",
          "institutions": [
            "Zhejiang University"
          ]
        },
        {
          "name": "Jun Xiao",
          "openalex_id": "A5101485989",
          "orcid": "https://orcid.org/0000-0002-6142-9914",
          "institutions": [
            "Zhejiang University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": null,
      "cited_by_count": 47,
      "type": "book-chapter",
      "source": {
        "name": "Lecture notes in computer science",
        "type": "book series",
        "issn": [
          "0302-9743",
          "1611-3349"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Advanced Image and Video Retrieval Techniques",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 46,
      "url": "https://openalex.org/W4312457137"
    },
    {
      "openalex_id": "W4385572215",
      "doi": "10.18653/v1/2023.acl-long.600",
      "title": "Rethinking Masked Language Modeling for Chinese Spelling Correction",
      "authors": [
        {
          "name": "Hongqiu Wu",
          "openalex_id": "A5112570819",
          "institutions": [
            "Shanghai Municipal Education Commission",
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Shaohua Zhang",
          "openalex_id": "A5100325397",
          "orcid": "https://orcid.org/0000-0001-8737-8273"
        },
        {
          "name": "Yuchen Zhang",
          "openalex_id": "A5100424305",
          "orcid": "https://orcid.org/0000-0001-8536-7175"
        },
        {
          "name": "Hai Zhao",
          "openalex_id": "A5036050911",
          "orcid": "https://orcid.org/0000-0001-7290-0487",
          "institutions": [
            "Shanghai Jiao Tong University",
            "Shanghai Municipal Education Commission"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "In this paper, we study Chinese Spelling Correction (CSC) as a joint decision made by two separate models: a language model and an error model. Through empirical analysis, we find that fine-tuning BERT tends to over-fit the error model while under-fit the language model, resulting in poor generalization to out-of-distribution error patterns. Given that BERT is the backbone of most CSC models, this phenomenon has a significant negative impact. To address this issue, we are releasing a multi-domain benchmark LEMON, with higher quality and diversity than existing benchmarks, to allow a comprehensive assessment of the open domain generalization of CSC models. Then, we demonstrate that a very simple strategy \u2013 randomly masking 20% non-error tokens from the input sequence during fine-tuning \u2013 is sufficient for learning a much better language model without sacrificing the error model. This technique can be applied to any model architecture and achieves new state-of-the-art results on SIGHAN, ECSpell, and LEMON.",
      "cited_by_count": 18,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2023.acl-long.600.pdf"
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Speech Recognition and Synthesis"
      ],
      "referenced_works_count": 29,
      "url": "https://openalex.org/W4385572215"
    },
    {
      "openalex_id": "W4390871831",
      "doi": "10.1109/iccv51070.2023.00236",
      "title": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability",
      "authors": [
        {
          "name": "Xuanlin Li",
          "openalex_id": "A5026720933",
          "orcid": "https://orcid.org/0009-0005-6200-7309",
          "institutions": [
            "UC San Diego Health System"
          ]
        },
        {
          "name": "Yunhao Fang",
          "openalex_id": "A5101276796",
          "institutions": [
            "UC San Diego Health System"
          ]
        },
        {
          "name": "Minghua Liu",
          "openalex_id": "A5058453644",
          "orcid": "https://orcid.org/0000-0002-6603-1251",
          "institutions": [
            "UC San Diego Health System"
          ]
        },
        {
          "name": "Zhan Ling",
          "openalex_id": "A5100349188",
          "orcid": "https://orcid.org/0000-0001-9293-721X",
          "institutions": [
            "UC San Diego Health System"
          ]
        },
        {
          "name": "Zhuowen Tu",
          "openalex_id": "A5001760915",
          "orcid": "https://orcid.org/0000-0002-1900-2124",
          "institutions": [
            "UC San Diego Health System"
          ]
        },
        {
          "name": "Hao Su",
          "openalex_id": "A5091622325",
          "orcid": "https://orcid.org/0000-0002-9686-6540",
          "institutions": [
            "UC San Diego Health System"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-10-01",
      "abstract": "Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a small- or mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enriching the teacher's language representations with informative and fine-grained semantic attributes to effectively distinguish between different labels. We propose several metrics and conduct extensive experiments to investigate their techniques. The results demonstrate significant improvements in zero-shot and few-shot student performance on open-vocabulary out-of-distribution classification, highlighting the effectiveness of our proposed approaches. Code released at this link.",
      "cited_by_count": 19,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Advanced Image and Video Retrieval Techniques",
        "Multimodal Machine Learning Applications",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 85,
      "url": "https://openalex.org/W4390871831"
    },
    {
      "openalex_id": "W3093630174",
      "doi": "10.18653/v1/2021.acl-long.75",
      "title": "Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?",
      "authors": [
        {
          "name": "Peter Shaw",
          "openalex_id": "A5038781104",
          "orcid": "https://orcid.org/0000-0002-3187-8938",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Ming\u2010Wei Chang",
          "openalex_id": "A5076904467",
          "orcid": "https://orcid.org/0000-0002-0137-8895",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Panupong Pasupat",
          "openalex_id": "A5035867340",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Kristina Toutanova",
          "openalex_id": "A5053947885",
          "institutions": [
            "Google (United States)"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-01-01",
      "abstract": "Sequence-to-sequence models excel at handling natural language variation, but have been shown to struggle with out-of-distribution compositional generalization. This has motivated new specialized architectures with stronger compositional biases, but most of these approaches have only been evaluated on synthetically-generated datasets, which are not representative of natural language variation. In this work we ask: can we develop a semantic parsing approach that handles both natural language variation and compositional generalization? To better assess this capability, we propose new train and test splits of non-synthetic datasets. We demonstrate that strong existing approaches do not perform well across a broad set of evaluations. We also propose NQG-T5, a hybrid model that combines a high-precision grammar-based approach with a pre-trained sequence-to-sequence model. It outperforms existing approaches across several compositional generalization challenges on non-synthetic data, while also being competitive with the state-of-the-art on standard evaluations. While still far from solving this problem, our study highlights the importance of diverse evaluations and the open challenge of handling both compositional generalization and natural language variation in semantic parsing.",
      "cited_by_count": 16,
      "type": "preprint",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2021.acl-long.75.pdf"
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 59,
      "url": "https://openalex.org/W3093630174"
    },
    {
      "openalex_id": "W4385474529",
      "doi": "10.48550/arxiv.2307.16789",
      "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs",
      "authors": [
        {
          "name": "Yujia Qin",
          "openalex_id": "A5102894085",
          "orcid": "https://orcid.org/0000-0003-3608-5061"
        },
        {
          "name": "Shihao Liang",
          "openalex_id": "A5054536224"
        },
        {
          "name": "Yining Ye",
          "openalex_id": "A5064978939",
          "orcid": "https://orcid.org/0000-0001-8937-6917"
        },
        {
          "name": "Kunlun Zhu",
          "openalex_id": "A5101074704",
          "orcid": "https://orcid.org/0009-0009-9107-7401"
        },
        {
          "name": "Lan Yan",
          "openalex_id": "A5100306850",
          "orcid": "https://orcid.org/0000-0001-6452-9649"
        },
        {
          "name": "Yaxi Lu",
          "openalex_id": "A5042774315"
        },
        {
          "name": "Yankai Lin",
          "openalex_id": "A5043098453",
          "orcid": "https://orcid.org/0000-0002-0151-6178"
        },
        {
          "name": "Xin Cong",
          "openalex_id": "A5100546036"
        },
        {
          "name": "Xiangru Tang",
          "openalex_id": "A5108999586",
          "orcid": "https://orcid.org/0009-0006-2700-4513"
        },
        {
          "name": "Bill Qian",
          "openalex_id": "A5101389051"
        },
        {
          "name": "Sihan Zhao",
          "openalex_id": "A5102605942"
        },
        {
          "name": "Runchu Tian",
          "openalex_id": "A5007867221"
        },
        {
          "name": "Ruobing Xie",
          "openalex_id": "A5101577090",
          "orcid": "https://orcid.org/0000-0003-3170-5647"
        },
        {
          "name": "Jie Zhou",
          "openalex_id": "A5101853761",
          "orcid": "https://orcid.org/0009-0004-3384-0556"
        },
        {
          "name": "Mark Gerstein",
          "openalex_id": "A5042321575",
          "orcid": "https://orcid.org/0000-0002-9746-3719"
        },
        {
          "name": "Dahai Li",
          "openalex_id": "A5101592508",
          "orcid": "https://orcid.org/0000-0002-2382-9917"
        },
        {
          "name": "Zhiyuan Liu",
          "openalex_id": "A5100320723",
          "orcid": "https://orcid.org/0000-0002-7709-2543"
        },
        {
          "name": "Maosong Sun",
          "openalex_id": "A5046448314",
          "orcid": "https://orcid.org/0000-0002-6011-6115"
        },
        {
          "name": "Sun, Maosong",
          "openalex_id": ""
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-07-31",
      "abstract": "Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.",
      "cited_by_count": 59,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2307.16789"
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Text Readability and Simplification"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4385474529"
    },
    {
      "openalex_id": "W3127322093",
      "doi": "10.18653/v1/2021.eacl-main.291",
      "title": "Increasing Robustness to Spurious Correlations using Forgettable Examples",
      "authors": [
        {
          "name": "Yadollah Yaghoobzadeh",
          "openalex_id": "A5031030600",
          "orcid": "https://orcid.org/0000-0003-0646-0852",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Soroush Mehri",
          "openalex_id": "A5083454446",
          "institutions": [
            "Microsoft (United States)",
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "R\u00e9mi Tachet",
          "openalex_id": "A5009752117",
          "institutions": [
            "Microsoft (United States)",
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Timothy J. Hazen",
          "openalex_id": "A5114018312",
          "orcid": "https://orcid.org/0009-0006-1413-9590",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Alessandro Sordoni",
          "openalex_id": "A5108137151",
          "institutions": [
            "Microsoft (United States)",
            "Microsoft Research (United Kingdom)"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-01-01",
      "abstract": "Neural NLP models tend to rely on spurious correlations between labels and input features to perform their tasks. Minority examples, i.e., examples that contradict the spurious correlations present in the majority of data points, have been shown to increase the out-of-distribution generalization of pre-trained language models. In this paper, we first propose using example forgetting to find minority examples without prior knowledge of the spurious correlations present in the dataset. Forgettable examples are instances either learned and then forgotten during training or never learned. We empirically show how these examples are related to minorities in our training sets. Then, we introduce a new approach to robustify models by fine-tuning our models twice, first on the full training data and second on the minorities only. We obtain substantial improvements in out-of-distribution generalization when applying our approach to the MNLI, QQP, and FEVER datasets.",
      "cited_by_count": 15,
      "type": "preprint",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2021.eacl-main.291.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 59,
      "url": "https://openalex.org/W3127322093"
    },
    {
      "openalex_id": "W3135028703",
      "doi": "10.1007/s42979-021-00592-x",
      "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions",
      "authors": [
        {
          "name": "Iqbal H. Sarker",
          "openalex_id": "A5055312229",
          "orcid": "https://orcid.org/0000-0003-1740-5517",
          "institutions": [
            "Swinburne University of Technology"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-03-22",
      "abstract": null,
      "cited_by_count": 4586,
      "type": "review",
      "source": {
        "name": "SN Computer Science",
        "type": "journal",
        "issn": [
          "2661-8907",
          "2662-995X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "bronze",
        "oa_url": "https://link.springer.com/content/pdf/10.1007/s42979-021-00592-x.pdf"
      },
      "topics": [
        "Anomaly Detection Techniques and Applications",
        "Traffic Prediction and Management Techniques",
        "Data Stream Mining Techniques"
      ],
      "referenced_works_count": 160,
      "url": "https://openalex.org/W3135028703"
    },
    {
      "openalex_id": "W4386890345",
      "doi": "10.1007/s11263-023-01895-7",
      "title": "How Does Fine-Tuning Impact Out-of-Distribution Detection for Vision-Language Models?",
      "authors": [
        {
          "name": "Yifei Ming",
          "openalex_id": "A5035172001",
          "institutions": [
            "University of Wisconsin\u2013Madison"
          ]
        },
        {
          "name": "Yixuan Li",
          "openalex_id": "A5076432790",
          "orcid": "https://orcid.org/0000-0003-3479-4323",
          "institutions": [
            "University of Wisconsin\u2013Madison"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-09-20",
      "abstract": null,
      "cited_by_count": 25,
      "type": "article",
      "source": {
        "name": "International Journal of Computer Vision",
        "type": "journal",
        "issn": [
          "0920-5691",
          "1573-1405"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Domain Adaptation and Few-Shot Learning",
        "Advanced Image and Video Retrieval Techniques"
      ],
      "referenced_works_count": 29,
      "url": "https://openalex.org/W4386890345"
    },
    {
      "openalex_id": "W3031882196",
      "doi": "10.18653/v1/2020.coling-main.603",
      "title": "Neural Unsupervised Domain Adaptation in NLP\u2014A Survey",
      "authors": [
        {
          "name": "Alan Ramponi",
          "openalex_id": "A5031240530",
          "orcid": "https://orcid.org/0000-0002-4305-2404",
          "institutions": [
            "University of Trento",
            "The Microsoft Research - University of Trento Centre for Computational and Systems Biology"
          ]
        },
        {
          "name": "Barbara Plank",
          "openalex_id": "A5088832285",
          "orcid": "https://orcid.org/0000-0002-4394-1965",
          "institutions": [
            "IT University of Copenhagen"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-01",
      "abstract": "Deep neural networks excel at learning from labeled data and achieve state-of-the-art resultson a wide array of Natural Language Processing tasks. In contrast, learning from unlabeled data, especially under domain shift, remains a challenge. Motivated by the latest advances, in this survey we review neural unsupervised domain adaptation techniques which do not require labeled target domain data. This is a more challenging yet a more widely applicable setup. We outline methods, from early traditional non-neural methods to pre-trained model transfer. We also revisit the notion of domain, and we uncover a bias in the type of Natural Language Processing tasks which received most attention. Lastly, we outline future directions, particularly the broader need for out-of-distribution generalization of future NLP.",
      "cited_by_count": 20,
      "type": "preprint",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.aclweb.org/anthology/2020.coling-main.603.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 131,
      "url": "https://openalex.org/W3031882196"
    }
  ],
  "count": 30,
  "errors": []
}
