{
  "status": "success",
  "source": "semantic_scholar",
  "query": "inductive backdoors machine learning",
  "results": [
    {
      "paperId": "4ac1bfc3f4af5e356912a2a714bf4ce926f0c376",
      "title": "Architectural Backdoors in Neural Networks",
      "authors": [
        {
          "name": "Mikel Bober-Irizar",
          "authorId": "2328126601"
        },
        {
          "name": "Ilia Shumailov",
          "authorId": "47473421"
        },
        {
          "name": "Yiren Zhao",
          "authorId": "2109919449"
        },
        {
          "name": "R. Mullins",
          "authorId": "2768514"
        },
        {
          "name": "Nicolas Papernot",
          "authorId": "1967156"
        }
      ],
      "year": 2022,
      "abstract": "Machine learning is vulnerable to adversarial manipulation. Previous literature demonstrated that at the training stage attackers can manipulate data [14] and data sampling procedures [29] to control model behaviour. A common attack goal is to plant backdoors i.e. force the victim model to learn to recognise a trigger known only by the adversary. In this paper, we introduce a new class of backdoor attacks that hide inside model architectures i.e. in the inductive bias of the functions used to train. These backdoors are simple to implement, for instance by publishing open-source code for a backdoored model architecture that others will reuse unknowingly. We demonstrate that model architectural backdoors represent a real threat and, unlike other approaches, can survive a complete re-training from scratch. We formalise the main construction principles behind architectural backdoors, such as a connection between the input and the output, and describe some possible protections against them. We evaluate our attacks on computer vision benchmarks of different scales and demonstrate the underlying vulnerability is pervasive in a variety of common training settings.",
      "citationCount": 32,
      "doi": "10.1109/CVPR52729.2023.02356",
      "arxivId": "2206.07840",
      "url": "https://www.semanticscholar.org/paper/4ac1bfc3f4af5e356912a2a714bf4ce926f0c376",
      "venue": "Computer Vision and Pattern Recognition",
      "journal": {
        "name": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "pages": "24595-24604"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "9aac8ede28e102d6d1e65f9347fb02eff8e4efc6",
      "title": "Reliability-enhanced data cleaning in biomedical machine learning using inductive conformal prediction",
      "authors": [
        {
          "name": "Xianghao Zhan",
          "authorId": "83235944"
        },
        {
          "name": "Qinmei Xu",
          "authorId": "1825697067"
        },
        {
          "name": "Yuanning Zheng",
          "authorId": "2160948921"
        },
        {
          "name": "Guangming Lu",
          "authorId": "2240532671"
        },
        {
          "name": "Olivier Gevaert",
          "authorId": "2237966690"
        }
      ],
      "year": 2025,
      "abstract": "Accurately labeling large datasets is important for biomedical machine learning yet challenging while modern data augmentation methods may generate noise in the training data, which may deteriorate machine learning model performance. Existing approaches addressing noisy training data typically rely on strict modeling assumptions, classification models and well-curated dataset. To address these, we propose a novel reliability-based training-data-cleaning method employing inductive conformal prediction (ICP). This method uses a small set of well-curated training data and leverages ICP-calculated reliability metrics to selectively correct mislabeled data and outliers within vast quantities of noisy training data. The efficacy is validated across three classification tasks with distinct modalities: filtering drug-induced-liver-injury (DILI) literature with free-text title and abstract, predicting ICU admission of COVID-19 patients through CT radiomics and electronic health records, and subtyping breast cancer using RNA-sequencing data. Varying levels of noise to the training labels were introduced via label permutation. Our training-data-cleaning method significantly enhanced the downstream classification performance (paired t-tests, p \u2264 0 . 05 among 30 random train/test partitions): significant accuracy enhancement in 86 out of 96 DILI experiments (up to 11.4% increase from 0.812 to 0.905), significant AUROC and AUPRC enhancements in all 48 COVID-19 experiments (up to 23.8% increase from 0.597 to 0.739 for AUROC, and 69.8% increase from 0.183 to 0.311 for AUPRC), and significant accuracy and macro-average F1-score improvements in 47 out of 48 RNA-sequencing experiments (up to 74.6% increase from 0.351 to 0.613 for accuracy, and 89.0% increase from 0.267 to 0.505 for F1-score). The improvement can be both statistically and clinically significant for information retrieval, disease diagnosis and prognosis. The method offers the potential to substantially boost classification performance in biomedical machine learning tasks without necessitating an excessive volume of well-curated training data or strong data distribution and modeling assumptions in existing semi-supervised learning methods.",
      "citationCount": 3,
      "doi": "10.1371/journal.pcbi.1012803",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/9aac8ede28e102d6d1e65f9347fb02eff8e4efc6",
      "venue": "PLoS Comput. Biol.",
      "journal": {
        "name": "PLOS Computational Biology",
        "volume": "21"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "7cdc235a96259ca2e013e4a920bcdf72ebda488a",
      "title": "Evil from Within: Machine Learning Backdoors Through Dormant Hardware Trojans",
      "authors": [
        {
          "name": "Alexander Warnecke",
          "authorId": "1750929757"
        },
        {
          "name": "Julian Speith",
          "authorId": "115426632"
        },
        {
          "name": "Janka M\u00f6ller",
          "authorId": "2066619527"
        },
        {
          "name": "Konrad Rieck",
          "authorId": "2350821714"
        },
        {
          "name": "Christof Paar",
          "authorId": "2259872271"
        }
      ],
      "year": 2024,
      "abstract": "Backdoors pose a severe threat to machine learning, as they can compromise the integrity of security-critical systems, such as self-driving cars. While different defenses have been proposed to address this threat, they all rely on the assumption that the hardware accelerator executing a learning model is trusted. This paper challenges this assumption and investigates a backdoor attack that completely resides within such an accelerator. Outside of the hardware, neither the learning model nor the software is manipulated so that current defenses fail. As memory on a hardware accelerator is limited, we utilize minimal backdoors that deviate from the original model by a few model parameters only. To mount the backdoor, we develop a hardware trojan that lays dormant until it is programmed after in-field deployment. The trojan can be provisioned with the minimal backdoor and performs a parameter replacement only when the target model is processed. We demonstrate the feasibility of our attack by implanting our hardware trojan into a commercial machine-learning accelerator and programming it with a minimal backdoor for a traffic-sign recognition system. The backdoor affects only 30 model parameters (0.069%) with a backdoor trigger covering 6.25% of the input image, yet it reliably manipulates the recognition once the input contains a backdoor trigger. Our attack expands the circuit size of the accelerator by only 0.24% and does not increase the run-time, rendering detection hardly possible. Given the distributed hardware manufacturing process, our work points to a new threat in machine learning that currently eludes security mechanisms.",
      "citationCount": 3,
      "doi": "10.1109/ACSAC63791.2024.00077",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7cdc235a96259ca2e013e4a920bcdf72ebda488a",
      "venue": "Asia-Pacific Computer Systems Architecture Conference",
      "journal": {
        "name": "2024 Annual Computer Security Applications Conference (ACSAC)",
        "pages": "906-922"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "afebe22663bb64197604dcfcf517761fc9c8035a",
      "title": "Thematic Analysis with Open-Source Generative AI and Machine Learning: A New Method for Inductive Qualitative Codebook Development",
      "authors": [
        {
          "name": "A. Katz",
          "authorId": "2324782315"
        },
        {
          "name": "Gabriella Coloyan Fleming",
          "authorId": "2325092485"
        },
        {
          "name": "Joyce Main",
          "authorId": "2324781440"
        }
      ],
      "year": 2024,
      "abstract": "This paper aims to answer one central question: to what extent can open-source generative text models be used in a workflow to approximate thematic analysis in social science research? To answer this question, we present the Generative AI-enabled Theme Organization and Structuring (GATOS) workflow, which uses open-source machine learning techniques, natural language processing tools, and generative text models to facilitate thematic analysis. To establish validity of the method, we present three case studies applying the GATOS workflow, leveraging these models and techniques to inductively create codebooks similar to traditional procedures using thematic analysis. Specifically, we investigate the extent to which a workflow comprising open-source models and tools can inductively produce codebooks that approach the known space of themes and sub-themes. To address the challenge of gleaning insights from these texts, we combine open-source generative text models, retrieval-augmented generation, and prompt engineering to identify codes and themes in large volumes of text, i.e., generate a qualitative codebook. The process mimics an inductive coding process that researchers might use in traditional thematic analysis by reading text one unit of analysis at a time, considering existing codes already in the codebook, and then deciding whether or not to generate a new code based on whether the extant codebook provides adequate thematic coverage. We demonstrate this workflow using three synthetic datasets from hypothetical organizational research settings: a study of teammate feedback in teamwork settings, a study of organizational cultures of ethical behavior, and a study of employee perspectives about returning to their offices after the pandemic. We show that the GATOS workflow is able to identify themes in the text that were used to generate the original synthetic datasets.",
      "citationCount": 11,
      "doi": "10.48550/arXiv.2410.03721",
      "arxivId": "2410.03721",
      "url": "https://www.semanticscholar.org/paper/afebe22663bb64197604dcfcf517761fc9c8035a",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2410.03721"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2d6960d01ed1431635faba1db24c92d634bd4ca3",
      "title": "Combined 3D FEA and Machine Learning Design of Inductive Polyphase Coils for Wireless EV Charging",
      "authors": [
        {
          "name": "Lucas A. Gastineau",
          "authorId": "2301248410"
        },
        {
          "name": "Donovin D. Lewis",
          "authorId": "2007848330"
        },
        {
          "name": "D. Ionel",
          "authorId": "1793758"
        }
      ],
      "year": 2024,
      "abstract": "Wireless power transfer (WPT) technologies are currently researched and developed for charging the batteries of electric unmanned air and ground vehicles. This paper presents systems with special polyphase inductive coils, which generate rotating fields and achieve high power density and efficiency. The complex geometry is modeled and studied with 3D electromagnetic finite element analysis (FEA). In order to reduce the substantial computational effort, machine learning techniques are proposed for surrogate modeling. A deep learning algorithm is introduced to capture the physics-based relationships between geometry and electromagnetic properties in inductive coils for wireless charging. Parametric models are systematically gener-ated and analyzed by 3D FEA to create a data base with hundreds of designs, which are then used as training and testing data for the machine learning model. A multi-input univariate output for the mutual inductance between the transmitter and receiver for an example two-phase WPT system is established. The outputs of the deep learning model are satisfactorily validated with 3.3 % NRMSE and a R2 value of 0.985.",
      "citationCount": 2,
      "doi": "10.1109/ICRERA62673.2024.10815533",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2d6960d01ed1431635faba1db24c92d634bd4ca3",
      "venue": "IEEE International Conference on Renewable Energy Research and Applications",
      "journal": {
        "name": "2024 13th International Conference on Renewable Energy Research and Applications (ICRERA)",
        "pages": "1811-1816"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "a954ee1265fb1197030ee4429b5561981369bbe9",
      "title": "Elbow Gesture Recognition with an Array of Inductive Sensors and Machine Learning",
      "authors": [
        {
          "name": "Alma Abbasnia",
          "authorId": "2308944397"
        },
        {
          "name": "M. Ravan",
          "authorId": "2854422"
        },
        {
          "name": "R. Amineh",
          "authorId": "2921897"
        }
      ],
      "year": 2024,
      "abstract": "This work presents a novel approach for elbow gesture recognition using an array of inductive sensors and a machine learning algorithm (MLA). This paper describes the design of the inductive sensor array integrated into a flexible and wearable sleeve. The sensor array consists of coils sewn onto the sleeve, which form an LC tank circuit along with the externally connected inductors and capacitors. Changes in the elbow position modulate the inductance of these coils, allowing the sensor array to capture a range of elbow movements. The signal processing and random forest MLA to recognize 10 different elbow gestures are described. Rigorous evaluation on 8 subjects and data augmentation, which leveraged the dataset to 1270 trials per gesture, enabled the system to achieve remarkable accuracy of 98.3% and 98.5% using 5-fold cross-validation and leave-one-subject-out cross-validation, respectively. The test performance was then assessed using data collected from five new subjects. The high classification accuracy of 94% demonstrates the generalizability of the designed system. The proposed solution addresses the limitations of existing elbow gesture recognition designs and offers a practical and effective approach for intuitive human\u2013machine interaction.",
      "citationCount": 3,
      "doi": "10.3390/s24134202",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/a954ee1265fb1197030ee4429b5561981369bbe9",
      "venue": "Italian National Conference on Sensors",
      "journal": {
        "name": "Sensors (Basel, Switzerland)",
        "volume": "24"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "849ea7f2c0831ae2749e91fa654592231b512620",
      "title": "Causal Inductive Biases for Cognitive Machine Learning",
      "authors": [
        {
          "name": "Saketh Vishnubhatla",
          "authorId": "2042337560"
        },
        {
          "name": "Adrienne Raglin",
          "authorId": "2340524132"
        },
        {
          "name": "Raha Moraffah",
          "authorId": "11064745"
        },
        {
          "name": "Huan Liu",
          "authorId": "2258336599"
        }
      ],
      "year": 2024,
      "abstract": "One of the long-unsolved open problems in machine learning is imbuing machine learning algorithms with human-like cognitive reasoning capabilities. An essential aspect of cognitive reasoning is the causal reasoning capacity inherent in humans. While humans can easily find causal connections, many Google searches for \"pandemic\" do not cause a pandemic but the other way around; the algorithms relying only on observational data might learn such misleading patterns. Thus, an active area of research - causal machine learning - emerged, where we encode causal assumptions into the learning algorithms and constrain the hypotheses learned by the algorithm. Constraining the learning algorithm with prior knowledge is commonly referred to as \"inductive bias.\" The core contribution of any machine learning algorithm is primarily to build the correct inductive biases for the problem at hand. Causal machine learning researchers regularly employ causal assumptions in their learning algorithms, yet many fail to recognize these assumptions as inductive biases. Thinking of causal assumptions in terms of inductive biases helps researchers design better learning algorithms for the relevant task. We present a case for how causal assumptions restrict the hypothesis space of the learning algorithm and discuss the standard ways of encoding these assumptions, which we refer to as causal inductive biases. Our position is that causal inductive biases are necessary, to build causally interpretable and generalizable models.",
      "citationCount": 1,
      "doi": "10.1109/CogMI62246.2024.00012",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/849ea7f2c0831ae2749e91fa654592231b512620",
      "venue": "International Conference on Cognitive Machine Intelligence",
      "journal": {
        "name": "2024 IEEE 6th International Conference on Cognitive Machine Intelligence (CogMI)",
        "pages": "14-16"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "c5d438158f366832d2e340797452bfea72012a5e",
      "title": "Cross-border acquisition completion by emerging market MNEs revisited: Inductive evidence from a machine learning analysis",
      "authors": [
        {
          "name": "Jianhong Zhang",
          "authorId": "2281616743"
        },
        {
          "name": "Arjen van Witteloostuijn",
          "authorId": "1780694"
        },
        {
          "name": "Chaohong Zhou",
          "authorId": "1812792"
        },
        {
          "name": "Shengyang Zhou",
          "authorId": "2281618868"
        }
      ],
      "year": 2024,
      "abstract": null,
      "citationCount": 10,
      "doi": "10.1016/j.jwb.2024.101517",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/c5d438158f366832d2e340797452bfea72012a5e",
      "venue": "Journal of World Business",
      "journal": {
        "name": "Journal of World Business"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "c13f3f39ebd8c2a98357277894462269b218ba7d",
      "title": "The Curve Fitting Problem, Data Validation, and Inductive Generalization in Machine Learning",
      "authors": [
        {
          "name": "Michael Tamir",
          "authorId": "2202160311"
        },
        {
          "name": "E. Shech",
          "authorId": "46213648"
        }
      ],
      "year": 2024,
      "abstract": null,
      "citationCount": 1,
      "doi": "10.1007/s10670-024-00863-y",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/c13f3f39ebd8c2a98357277894462269b218ba7d",
      "venue": "Erkenntnis: An International Journal of Scientific Philosophy",
      "journal": {
        "name": "Erkenntnis",
        "pages": "3767 - 3781",
        "volume": "90"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "14eb1b5d846973785c33fe433a9c43d73be326f2",
      "title": "Contextuality and inductive bias in quantum machine learning",
      "authors": [
        {
          "name": "Joseph Bowles",
          "authorId": "31225573"
        },
        {
          "name": "Victoria J. Wright",
          "authorId": "2093117546"
        },
        {
          "name": "M. Farkas",
          "authorId": "31812830"
        },
        {
          "name": "N. Killoran",
          "authorId": "3399181"
        },
        {
          "name": "M. Schuld",
          "authorId": "3048564"
        }
      ],
      "year": 2023,
      "abstract": "Generalisation in machine learning often relies on the ability to encode structures present in data into an inductive bias of the model class. To understand the power of quantum machine learning, it is therefore crucial to identify the types of data structures that lend themselves naturally to quantum models. In this work we look to quantum contextuality -- a form of nonclassicality with links to computational advantage -- for answers to this question. We introduce a framework for studying contextuality in machine learning, which leads us to a definition of what it means for a learning model to be contextual. From this, we connect a central concept of contextuality, called operational equivalence, to the ability of a model to encode a linearly conserved quantity in its label space. A consequence of this connection is that contextuality is tied to expressivity: contextual model classes that encode the inductive bias are generally more expressive than their noncontextual counterparts. To demonstrate this, we construct an explicit toy learning problem -- based on learning the payoff behaviour of a zero-sum game -- for which this is the case. By leveraging tools from geometric quantum machine learning, we then describe how to construct quantum learning models with the associated inductive bias, and show through our toy problem that they outperform their corresponding classical surrogate models. This suggests that understanding learning problems of this form may lead to useful insights about the power of quantum machine learning.",
      "citationCount": 32,
      "doi": null,
      "arxivId": "2302.01365",
      "url": "https://www.semanticscholar.org/paper/14eb1b5d846973785c33fe433a9c43d73be326f2",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "0bde1c92e1786f95a1de5ddf77a34e68ec9b9414",
      "title": "The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning",
      "authors": [
        {
          "name": "Micah Goldblum",
          "authorId": "2126058635"
        },
        {
          "name": "Marc Finzi",
          "authorId": "51007156"
        },
        {
          "name": "K. Rowan",
          "authorId": "123864481"
        },
        {
          "name": "A. Wilson",
          "authorId": "145771261"
        }
      ],
      "year": 2023,
      "abstract": "No free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. Accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. While virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using Kolmogorov complexity. Notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. Our experiments show that pre-trained and even randomly initialized language models prefer to generate low-complexity sequences. Whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we explain how tasks that often require human intervention such as picking an appropriately sized model when labeled data is scarce or plentiful can be automated into a single learning algorithm. These observations justify the trend in deep learning of unifying seemingly disparate problems with an increasingly small set of machine learning models.",
      "citationCount": 60,
      "doi": "10.48550/arXiv.2304.05366",
      "arxivId": "2304.05366",
      "url": "https://www.semanticscholar.org/paper/0bde1c92e1786f95a1de5ddf77a34e68ec9b9414",
      "venue": "International Conference on Machine Learning",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2304.05366"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "38ab0972ea91d2b2d14abb18afe58c351018cf06",
      "title": "Planting Undetectable Backdoors in Machine Learning Models : [Extended Abstract]",
      "authors": [
        {
          "name": "S. Goldwasser",
          "authorId": "1706681"
        },
        {
          "name": "Michael P. Kim",
          "authorId": "2110079050"
        },
        {
          "name": "V. Vaikuntanathan",
          "authorId": "1749858"
        },
        {
          "name": "Or Zamir",
          "authorId": "3147193"
        }
      ],
      "year": 2022,
      "abstract": "Given the computational cost and technical expertise required to train machine learning models, users may delegate the task of learning to a service provider. Delegation of learning has clear benefits, and at the same time raises serious concerns of trust. This work studies possible abuses of power by untrusted learners.We show how a malicious learner can plant an undetectable backdoor into a classifier. On the surface, such a backdoored classifier behaves normally, but in reality, the learner maintains a mechanism for changing the classification of any input, with only a slight perturbation. Importantly, without the appropriate \u201cbackdoor key,\u201d the mechanism is hidden and cannot be detected by any computationally-bounded observer. We demonstrate two frameworks for planting undetectable backdoors, with incomparable guarantees.\u2022First, we show how to plant a backdoor in any model, using digital signature schemes. The construction guarantees that given query access to the original model and the backdoored version, it is computationally infeasible to find even a single input where they differ. This property implies that the backdoored model has generalization error comparable with the original model. Moreover, even if the distinguisher can request backdoored inputs of its choice, they cannot backdoor a new input\u2014a property we call non-replicability.\u2022Second, we demonstrate how to insert undetectable backdoors in models trained using the Random Fourier Features (RFF) learning paradigm (Rahimi, Recht; NeurIPS 2007). In this construction, undetectability holds against powerful white-box distinguishers: given a complete description of the network and the training data, no efficient distinguisher can guess whether the model is \u201cclean\u201d or contains a backdoor. The backdooring algorithm executes the RFF algorithm faithfully on the given training data, tampering only with its random coins. We prove this strong guarantee under the hardness of the Continuous Learning With Errors problem (Bruna, Regev, Song, Tang; STOC 2021). We show a similar white-box undetectable backdoor for random ReLU networks based on the hardness of Sparse PCA (Berthet, Rigollet; COLT 2013).Our construction of undetectable backdoors also sheds light on the related issue of robustness to adversarial examples. In particular, by constructing undetectable backdoor for an \u201cadversarially-robust\u201d learning algorithm, we can produce a classifier that is indistinguishable from a robust classifier, but where every input has an adversarial example! In this way, the existence of undetectable backdoors represent a significant theoretical roadblock to certifying adversarial robustness.",
      "citationCount": 84,
      "doi": "10.1109/FOCS54457.2022.00092",
      "arxivId": "2204.06974",
      "url": "https://www.semanticscholar.org/paper/38ab0972ea91d2b2d14abb18afe58c351018cf06",
      "venue": "IEEE Annual Symposium on Foundations of Computer Science",
      "journal": {
        "name": "2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)",
        "pages": "931-942"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2af02c0a99ea32ef62fc2c368bbfa6213d60c361",
      "title": "Evil from Within: Machine Learning Backdoors through Hardware Trojans",
      "authors": [
        {
          "name": "Alexander Warnecke",
          "authorId": "1750929757"
        },
        {
          "name": "Julian Speith",
          "authorId": "115426632"
        },
        {
          "name": "Janka M\u00f6ller",
          "authorId": "2066619527"
        },
        {
          "name": "Konrad Rieck",
          "authorId": "144825749"
        },
        {
          "name": "C. Paar",
          "authorId": "1790145"
        }
      ],
      "year": 2023,
      "abstract": "Backdoors pose a serious threat to machine learning, as they can compromise the integrity of security-critical systems, such as self-driving cars. While different defenses have been proposed to address this threat, they all rely on the assumption that the hardware on which the learning models are executed during inference is trusted. In this paper, we challenge this assumption and introduce a backdoor attack that completely resides within a common hardware accelerator for machine learning. Outside of the accelerator, neither the learning model nor the software is manipulated, so that current defenses fail. To make this attack practical, we overcome two challenges: First, as memory on a hardware accelerator is severely limited, we introduce the concept of a minimal backdoor that deviates as little as possible from the original model and is activated by replacing a few model parameters only. Second, we develop a configurable hardware trojan that can be provisioned with the backdoor and performs a replacement only when the specific target model is processed. We demonstrate the practical feasibility of our attack by implanting our hardware trojan into the Xilinx Vitis AI DPU, a commercial machine-learning accelerator. We configure the trojan with a minimal backdoor for a traffic-sign recognition system. The backdoor replaces only 30 (0.069%) model parameters, yet it reliably manipulates the recognition once the input contains a backdoor trigger. Our attack expands the hardware circuit of the accelerator by 0.24% and induces no run-time overhead, rendering a detection hardly possible. Given the complex and highly distributed manufacturing process of current hardware, our work points to a new threat in machine learning that is inaccessible to current security mechanisms and calls for hardware to be manufactured only in fully trusted environments.",
      "citationCount": 4,
      "doi": "10.48550/arXiv.2304.08411",
      "arxivId": "2304.08411",
      "url": "https://www.semanticscholar.org/paper/2af02c0a99ea32ef62fc2c368bbfa6213d60c361",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2304.08411"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "bedab3624cd968fd1a13c6140fb5c1835c0c2569",
      "title": "TRAPDOOR: Repurposing neural network backdoors to detect dataset bias in machine learning-based genomic analysis",
      "authors": [
        {
          "name": "Esha Sarkar",
          "authorId": "7803506"
        },
        {
          "name": "Constantine Doumanidis",
          "authorId": "84225013"
        },
        {
          "name": "Michail Maniatakos",
          "authorId": "1686192"
        }
      ],
      "year": 2023,
      "abstract": "Use of Machine Learning (ML) to understand underlying patterns in gene mutations (genomics) has far-reaching results in diagnosis and treatment for life-threatening diseases like cancer. Success and sustainability of ML algorithms depends on the quality and diversity of training data, and under-representation of groups (gender, race, etc.) can lead to exacerbation of systemic discrimination issues. In this work, we propose TRAPDOOR, a methodology for the identification of biased datasets by repurposing, otherwise malicious, neural backdoors. Our methodology can leak potential bias information about the cloud\u2019s dataset which is collected in a collaborative setting, without hampering the genuine performance. Using a real-world cancer genomics dataset, we analyze feasibility of leaking bias for gender and race attributes. Our experimental results show that TRAPDOOR can detect the presence of dataset bias with 100% accuracy, and furthermore can also extract the extent of bias by recovering the percentage with a small error.",
      "citationCount": 1,
      "doi": "10.1109/VLSI-SoC57769.2023.10321928",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/bedab3624cd968fd1a13c6140fb5c1835c0c2569",
      "venue": "IEEE/IFIP International Conference on Very Large Scale Integration of System-on-Chip",
      "journal": {
        "name": "2023 IFIP/IEEE 31st International Conference on Very Large Scale Integration (VLSI-SoC)",
        "pages": "1-6"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "2b992a76049e8a0166ee59e159d77cc7e91a7fab",
      "title": "Inductive Link Prediction Banking Fraud Detection System Using Homogeneous Graph-Based Machine Learning Model",
      "authors": [
        {
          "name": "Hilmi Aziz Bukhori",
          "authorId": "2114539589"
        },
        {
          "name": "R. Munir",
          "authorId": "2350273"
        }
      ],
      "year": 2023,
      "abstract": "Graph machine learning and fraud detection systems are growing and popular today. Fraud detection systems have been widely used as a tool to detect potentially fraudulent transactions. Fraud detection systems can be used to determine patterns of transactions that are suspected of being criminal transactions. Graph machine learning development can be implemented in anything that can be represented in graph form. The banking fraud detection system can be implemented in graph form by connecting customers who have made transactions with other customers or customer transactional activities. From the graph that has been formed, predictions will be made so that new transactions can be classified as fraudulent transactions or not by connecting these transactions with the graphs that have been made. The experimental results show that the graph-based fraud detection model produces better performance than the tree-based fraud detection model, but with a longer inference time.",
      "citationCount": 9,
      "doi": "10.1109/CCWC57344.2023.10099180",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2b992a76049e8a0166ee59e159d77cc7e91a7fab",
      "venue": "Computing and Communication Workshop and Conference",
      "journal": {
        "name": "2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)",
        "pages": "0246-0251"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "cbf421889e4255ac8080d575b6d6b1c818a3d23c",
      "title": "Machine Learning Optimizes the Efficiency of Picking and Packing in Automated Warehouse Robot Systems",
      "authors": [
        {
          "name": "Dezhi Yu",
          "authorId": "2372618689"
        },
        {
          "name": "Lipeng Liu",
          "authorId": "2334816177"
        },
        {
          "name": "Siye Wu",
          "authorId": "2345124891"
        },
        {
          "name": "Keqin Li",
          "authorId": "2330239760"
        },
        {
          "name": "Congyu Wang",
          "authorId": "2330220023"
        },
        {
          "name": "Jing Xie",
          "authorId": "2362078338"
        },
        {
          "name": "Runmian Chang",
          "authorId": "2317982084"
        },
        {
          "name": "Yixu Wang",
          "authorId": "2361257922"
        },
        {
          "name": "Zehan Wang",
          "authorId": "2362256398"
        },
        {
          "name": "Ryan Ji",
          "authorId": "2361189651"
        }
      ],
      "year": 2025,
      "abstract": "In order to improve the efficiency of automated warehouse robots in picking and packaging operations and enhance the control precision of their motion execution, this study incorporated machine learning algorithms into the design of the control system of automated warehouse robots. Mechanical learning and inductive learning were used to design machine learning methods applicable to these robots. Meanwhile, the learning process was optimized with the help of PID feedback adjustment, thus constructing an efficient execution system for the picking and packaging operations of automated warehouse robots. Taking the quantity of goods picked and packaged within the same period of time as the task indicator for the operations, simulation was carried out on the operation situations of robots adopting different machine learning methods. The results show that by using the combination of mechanical and inductive learning methods and the PID feedback adjustment approach, automated warehouse robots can handle more goods within the same period of time, significantly improving their motion execution efficiency in picking and packaging operations and providing strong support for the efficient operation of automated warehouses.",
      "citationCount": 35,
      "doi": "10.1109/EESPE63401.2025.10986975",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/cbf421889e4255ac8080d575b6d6b1c818a3d23c",
      "venue": "2025 IEEE International Conference on Electronics, Energy Systems and Power Engineering (EESPE)",
      "journal": {
        "name": "2025 IEEE International Conference on Electronics, Energy Systems and Power Engineering (EESPE)",
        "pages": "1325-1332"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "af20defde7175b915b59b4d655b71f7f746ca969",
      "title": "Spatial Visual Feedback for Robotic Arc-Welding Enforced by Inductive Machine Learning",
      "authors": [
        {
          "name": "Goran D. Putnik",
          "authorId": "2269657035"
        },
        {
          "name": "P. Petrovic",
          "authorId": "2788329"
        },
        {
          "name": "Vaibhav Shah",
          "authorId": "51019563"
        }
      ],
      "year": 2023,
      "abstract": "\n An intelligent system for spatial visual feedback is presented, that enables the robot's autonomy for a range of robotic assembly tasks, in particular for arc-welding, in an unstructured and \u2018fixtureless\u2019 environment. The robot's autonomy is empowered by embedded inductive inference based machine learning module which learns a welded object's structural properties in the form of geometrical properties. In particular, the system tries to recognize line segments, using a spatial (3-Dimensional) visual sensor in order to autonomously execute the objective task. The innovative result is that the recognition of the geometric primitives is done without a predefined Computer Aided Design (CAD) model, significantly improving the system's autonomy and robustness. The system is validated on real-world welding tasks.",
      "citationCount": 1,
      "doi": "10.1115/1.4064156",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/af20defde7175b915b59b4d655b71f7f746ca969",
      "venue": "Journal of manufacturing science and engineering",
      "journal": {
        "name": "Journal of Manufacturing Science and Engineering"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "15b81773f8fcfaddb91a1aad89a2b2e0e376bfb3",
      "title": "Proceedings of the 20th anniversary Workshop on Knowledge Discovery in Inductive Databases co-located with the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases 2022 (ECMLPKDD 2022), Grenoble, France, September 19-23, 2022",
      "authors": [],
      "year": 2023,
      "abstract": null,
      "citationCount": 2,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/15b81773f8fcfaddb91a1aad89a2b2e0e376bfb3",
      "venue": "International Workshop on Knowledge Discovery in Inductive Databases",
      "journal": {
        "volume": "3334"
      },
      "publicationTypes": null
    },
    {
      "paperId": "83c0c522ec9c7098ca350750307710bc0b6b72b5",
      "title": "Inductive Bias in Machine Learning",
      "authors": [
        {
          "name": "Luca Rendsburg",
          "authorId": "1768151410"
        }
      ],
      "year": 2023,
      "abstract": null,
      "citationCount": 3,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/83c0c522ec9c7098ca350750307710bc0b6b72b5",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "b9177e8d61c4a2ef1364d9b2ec72588cfdb2835e",
      "title": "An automatic detection system of diabetic retinopathy using a hybrid inductive machine learning algorithm",
      "authors": [
        {
          "name": "Mohamed H. Mahmoud",
          "authorId": "15666034"
        },
        {
          "name": "S. Alamery",
          "authorId": "3508975"
        },
        {
          "name": "H. Fouad",
          "authorId": "2242815332"
        },
        {
          "name": "Amir Altinawi",
          "authorId": "1885340084"
        },
        {
          "name": "Ahmed E. Youssef",
          "authorId": "2007561"
        }
      ],
      "year": 2021,
      "abstract": null,
      "citationCount": 59,
      "doi": "10.1007/s00779-020-01519-8",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/b9177e8d61c4a2ef1364d9b2ec72588cfdb2835e",
      "venue": "Personal and Ubiquitous Computing",
      "journal": {
        "name": "Personal and Ubiquitous Computing",
        "pages": "751-765",
        "volume": "27"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "6377a9fb8e360613eba9fbabb9e2f27c96629770",
      "title": "Inductive Risk, Understanding, and Opaque Machine Learning Models",
      "authors": [
        {
          "name": "Emily Sullivan",
          "authorId": "49503692"
        }
      ],
      "year": 2022,
      "abstract": "Abstract Under what conditions does machine learning (ML) model opacity inhibit the possibility of explaining and understanding phenomena? In this article, I argue that nonepistemic values give shape to the ML opacity problem even if we keep researcher interests fixed. Treating ML models as an instance of doing model-based science to explain and understand phenomena reveals that there is (i) an external opacity problem, where the presence of inductive risk imposes higher standards on externally validating models, and (ii) an internal opacity problem, where greater inductive risk demands a higher level of transparency regarding the inferences the model makes.",
      "citationCount": 14,
      "doi": "10.1017/psa.2022.62",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6377a9fb8e360613eba9fbabb9e2f27c96629770",
      "venue": "Philosophia Scienti\u00e6",
      "journal": {
        "name": "Philosophy of Science",
        "pages": "1065 - 1074",
        "volume": "89"
      },
      "publicationTypes": null
    },
    {
      "paperId": "aad9305e65019ba79d2a399e61fdde4db0dc731e",
      "title": "An intelligent literature review: adopting inductive approach to define machine learning applications in the clinical domain",
      "authors": [
        {
          "name": "Renu Sabharwal",
          "authorId": "66206134"
        },
        {
          "name": "S. Miah",
          "authorId": "2883076"
        }
      ],
      "year": 2022,
      "abstract": "Big data analytics utilizes different techniques to transform large volumes of big datasets. The analytics techniques utilize various computational methods such as Machine Learning (ML) for converting raw data into valuable insights. The ML assists individuals in performing work activities intelligently, which empowers decision-makers. Since academics and industry practitioners have growing interests in ML, various existing review studies have explored different applications of ML for enhancing knowledge about specific problem domains. However, in most of the cases existing studies suffer from the limitations of employing a holistic, automated approach. While several researchers developed various techniques to automate the systematic literature review process, they also seemed to lack transparency and guidance for future researchers. This research aims to promote the utilization of intelligent literature reviews for researchers by introducing a step-by-step automated framework. We offer an intelligent literature review to obtain in-depth analytical insight of ML applications in the clinical domain to (a) develop the intelligent literature framework using traditional literature and Latent Dirichlet Allocation (LDA) topic modeling, (b) analyze research documents using traditional systematic literature review revealing ML applications, and (c) identify topics from documents using LDA topic modeling. We used a PRISMA framework for the review to harness samples sourced from four major databases (e.g., IEEE, PubMed, Scopus, and Google Scholar) published between 2016 and 2021 (September). The framework comprises two stages\u2014(a) traditional systematic literature review consisting of three stages (planning, conducting, and reporting) and (b) LDA topic modeling that consists of three steps (pre-processing, topic modeling, and post-processing). The intelligent literature review framework transparently and reliably reviewed 305 sample documents.",
      "citationCount": 16,
      "doi": "10.1186/s40537-022-00605-3",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/aad9305e65019ba79d2a399e61fdde4db0dc731e",
      "venue": "Journal of Big Data",
      "journal": {
        "name": "Journal of Big Data",
        "volume": "9"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "133fcc7cdafa4f4650bd1f5b1eb2429c8f10b02f",
      "title": "Symbolic AI for XAI: Evaluating LFIT Inductive Programming for Explaining Biases in Machine Learning",
      "authors": [
        {
          "name": "A. Ortega",
          "authorId": "152640282"
        },
        {
          "name": "Julian Fierrez",
          "authorId": "1701431"
        },
        {
          "name": "A. Morales",
          "authorId": "144083995"
        },
        {
          "name": "Zilong Wang",
          "authorId": "2117425265"
        },
        {
          "name": "Marina De La Cruz",
          "authorId": "2111978190"
        },
        {
          "name": "C. Alonso",
          "authorId": "2650756"
        },
        {
          "name": "Tony Ribeiro",
          "authorId": "143681572"
        }
      ],
      "year": 2021,
      "abstract": "Machine learning methods are growing in relevance for biometrics and personal information processing in domains such as forensics, e-health, recruitment, and e-learning. In these domains, white-box (human-readable) explanations of systems built on machine learning methods become crucial. Inductive logic programming (ILP) is a subfield of symbolic AI aimed to automatically learn declarative theories about the processing of data. Learning from interpretation transition (LFIT) is an ILP technique that can learn a propositional logic theory equivalent to a given black-box system (under certain conditions). The present work takes a first step to a general methodology to incorporate accurate declarative explanations to classic machine learning by checking the viability of LFIT in a specific AI application scenario: fair recruitment based on an automatic tool generated with machine learning methods for ranking Curricula Vitae that incorporates soft biometric information (gender and ethnicity). We show the expressiveness of LFIT for this specific problem and propose a scheme that can be applicable to other domains. In order to check the ability to cope with other domains no matter the machine learning paradigm used, we have done a preliminary test of the expressiveness of LFIT, feeding it with a real dataset about adult incomes taken from the US census, in which we consider the income level as a function of the rest of attributes to verify if LFIT can provide logical theory to support and explain to what extent higher incomes are biased by gender and ethnicity.",
      "citationCount": 13,
      "doi": "10.3390/computers10110154",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/133fcc7cdafa4f4650bd1f5b1eb2429c8f10b02f",
      "venue": "De Computis",
      "journal": {
        "name": "Comput.",
        "pages": "154",
        "volume": "10"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "ac97dd2ec7f201b64a5b1cde01bbb62efda99e32",
      "title": "TRAPDOOR: Repurposing backdoors to detect dataset bias in machine learning-based genomic analysis",
      "authors": [
        {
          "name": "Esha Sarkar",
          "authorId": "7803506"
        },
        {
          "name": "Michail Maniatakos",
          "authorId": "1686192"
        }
      ],
      "year": 2021,
      "abstract": "Machine Learning (ML) has achieved unprecedented performance in several applications including image, speech, text, and data analysis. Use of ML to understand underlying patterns in gene mutations (genomics) has far-reaching results, not only in overcoming diagnostic pitfalls, but also in designing treatments for life-threatening diseases like cancer. Success and sustainability of ML algorithms depends on the quality and diversity of data collected and used for training. Under-representation of groups (ethnic groups, gender groups, etc.) in such a dataset can lead to inaccurate predictions for certain groups, which can further exacerbate systemic discrimination issues. In this work, we propose TRAPDOOR, a methodology for identification of biased datasets by repurposing a technique that has been mostly proposed for nefarious purposes: Neural network backdoors. We consider a typical collaborative learning setting of the genomics supply chain, where data may come from hospitals, collaborative projects, or research institutes to a central cloud without awareness of bias against a sensitive group. In this context, we develop a methodology to leak potential bias information of the collective data without hampering the genuine performance using ML backdooring catered for genomic applications. Using a real-world cancer dataset, we analyze the dataset with the bias that already existed towards white individuals and also introduced biases in datasets artificially, and our experimental result show that TRAPDOOR can detect the presence of dataset bias with 100% accuracy, and furthermore can also extract the extent of bias by recovering the percentage with a small error.",
      "citationCount": 4,
      "doi": null,
      "arxivId": "2108.10132",
      "url": "https://www.semanticscholar.org/paper/ac97dd2ec7f201b64a5b1cde01bbb62efda99e32",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2108.10132"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "6988e2c316e56c61729ae98e77a67f953f75aac0",
      "title": "Groundwater Level Data Imputation Using Machine Learning and Remote Earth Observations Using Inductive Bias",
      "authors": [
        {
          "name": "Saul G. Ramirez",
          "authorId": "1483987532"
        },
        {
          "name": "G. Williams",
          "authorId": "2230404564"
        },
        {
          "name": "N. Jones",
          "authorId": "2271771903"
        }
      ],
      "year": 2022,
      "abstract": "Sustainable groundwater management requires an accurate characterization of aquifer-storage change over time. This process begins with an analysis of historical water levels at observation wells. However, water-level records can be sparse, particularly in developing areas. To address this problem, we developed an imputation method to approximate missing monthly averaged groundwater-level observations at individual wells since 1948. To impute missing groundwater levels at individual wells, we used two global data sources: Palmer Drought Severity Index (PDSI), and the Global Land Data Assimilation System (GLDAS) for regression. In addition to the meteorological datasets, we engineered four additional features and encoded the temporal data as 13 parameters that represent the month and year of an observation. This extends previous similar work by using inductive bias to inform our models on groundwater trends and structure from existing groundwater observations, using prior estimates of groundwater behavior. We formed an initial prior by estimating the long-term ground trends and developed four additional priors by using smoothing. These prior features represent the expected behavior over the long term of the missing data and allow the regression approach to perform well, even over large gaps of up to 50 years. We demonstrated our method on the Beryl-Enterprise aquifer in Utah and found the imputed results follow trends in the observed data and hydrogeological principles, even over long periods with no observed data.",
      "citationCount": 7,
      "doi": "10.3390/rs14215509",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6988e2c316e56c61729ae98e77a67f953f75aac0",
      "venue": "Remote Sensing",
      "journal": {
        "name": "Remote. Sens.",
        "pages": "5509",
        "volume": "14"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "6684efeaa06e983ff47dff31693aefd1d7a6577f",
      "title": "The Immortal Science of ML: Machine Learning and the Theory-Free Ideal",
      "authors": [
        {
          "name": "Mel Andrews",
          "authorId": "2345198855"
        }
      ],
      "year": 2025,
      "abstract": null,
      "citationCount": 8,
      "doi": "10.1007/s10670-025-01010-x",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6684efeaa06e983ff47dff31693aefd1d7a6577f",
      "venue": "Erkenntnis: An International Journal of Scientific Philosophy",
      "journal": {
        "name": "Erkenntnis"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "f23a932d6d4f373af69b93e410fd381c8e86719c",
      "title": "Values and inductive risk in machine learning modelling: the case of binary classification models",
      "authors": [
        {
          "name": "Koray Karaca",
          "authorId": "2983358"
        }
      ],
      "year": 2021,
      "abstract": "I examine the construction and evaluation of machine learning (ML) binary classification models. These models are increasingly used for societal applications such as classifying patients into two categories according to the presence or absence of a certain disease like cancer and heart disease. I argue that the construction of ML (binary) classification models involves an optimisation process aiming at the minimization of the inductive risk associated with the intended uses of these models. I also argue that the construction of these models is underdetermined by the available data, and that this makes it necessary for ML modellers to make social value judgments in determining the error costs (associated with misclassifications) used in ML optimization. I thus suggest that the assessment of the inductive risk with respect to the social values of the intended users is an integral part of the construction and evaluation of ML classification models. I also discuss the implications of this conclusion for the philosophical debate concerning inductive risk.",
      "citationCount": 8,
      "doi": "10.1007/s13194-021-00405-1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f23a932d6d4f373af69b93e410fd381c8e86719c",
      "venue": "European Journal for Philosophy of Science",
      "journal": {
        "name": "European Journal for Philosophy of Science",
        "volume": "11"
      },
      "publicationTypes": null
    },
    {
      "paperId": "8985ae6ae17e1ee8cef31423d681302c4b94449d",
      "title": "The Role of Data Analytics and Machine Learning in Resurrecting Inductive-Based Accounting Research",
      "authors": [
        {
          "name": "Lawrence A. Gordon",
          "authorId": "39772730"
        }
      ],
      "year": 2021,
      "abstract": "The objective of this paper is to assess the impact of data analytics (DA) and machine learning (ML) on accounting research.[1] As discussed in the paper, the inherent inductive nature of DA and ML is creating an important trend in the way accounting research is being conducted. That trend is the increasing utilization of inductive-based research among accounting researchers. Indeed, as a result of the recent developments with DA and ML, a rebalancing is taking place between inductive-based and deductive-based research in accounting.[2] In essence, we are witnessing the resurrection of inductive-based accounting research. A brief review of some empirical evidence to support the above argument is also provided in the paper.\u00a0 \u00a0",
      "citationCount": 1,
      "doi": "10.14738/TMLAI.92.9823",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/8985ae6ae17e1ee8cef31423d681302c4b94449d",
      "venue": "",
      "journal": {
        "name": "Transactions on Machine Learning and Artificial Intelligence",
        "pages": "1-19",
        "volume": "9"
      },
      "publicationTypes": [
        "Review"
      ]
    },
    {
      "paperId": "2313602190c840b6824c2d03427ac8af53b27375",
      "title": "AEGIS: Exposing Backdoors in Robust Machine Learning Models",
      "authors": [
        {
          "name": "E. Soremekun",
          "authorId": "11032020"
        },
        {
          "name": "Sakshi Udeshi",
          "authorId": "9451906"
        },
        {
          "name": "Sudipta Chattopadhyay",
          "authorId": "2285146552"
        }
      ],
      "year": 2021,
      "abstract": null,
      "citationCount": 1,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2313602190c840b6824c2d03427ac8af53b27375",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "71ff23a33bc4db47a76808717acc78d9b04a7e1e",
      "title": "Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security",
      "authors": [
        {
          "name": "Pascal Debus",
          "authorId": "2264417298"
        },
        {
          "name": "Maximilian Wendlinger",
          "authorId": "2298270782"
        },
        {
          "name": "Kilian Tscharke",
          "authorId": "2226260062"
        },
        {
          "name": "Daniel Herr",
          "authorId": "2373446128"
        },
        {
          "name": "Cedric Br\u00fcgmann",
          "authorId": "2376444738"
        },
        {
          "name": "Daniel de Mello",
          "authorId": "2290176217"
        },
        {
          "name": "J. Ulmanis",
          "authorId": "11011412"
        },
        {
          "name": "Alexander Erhard",
          "authorId": "2372986967"
        },
        {
          "name": "Arthur Schmidt",
          "authorId": "2374466688"
        },
        {
          "name": "Fabian Petsch",
          "authorId": "2279542748"
        }
      ],
      "year": 2025,
      "abstract": "Quantum Machine Learning (QML) systems inherit vulnerabilities from classical machine learning while introducing new attack surfaces rooted in the physical and algorithmic layers of quantum computing. Despite a growing body of research on individual attack vectors - ranging from adversarial poisoning and evasion to circuit-level backdoors, side-channel leakage, and model extraction - these threats are often analyzed in isolation, with unrealistic assumptions about attacker capabilities and system environments. This fragmentation hampers the development of effective, holistic defense strategies. In this work, we argue that QML security requires more structured modeling of the attack surface, capturing not only individual techniques but also their relationships, prerequisites, and potential impact across the QML pipeline. We propose adapting kill chain models, widely used in classical IT and cybersecurity, to the quantum machine learning context. Such models allow for structured reasoning about attacker objectives, capabilities, and possible multi-stage attack paths - spanning reconnaissance, initial access, manipulation, persistence, and exfiltration. Based on extensive literature analysis, we present a detailed taxonomy of QML attack vectors mapped to corresponding stages in a quantum-aware kill chain framework that is inspired by the MITRE ATLAS for classical machine learning. We highlight interdependencies between physical-level threats (like side-channel leakage and crosstalk faults), data and algorithm manipulation (such as poisoning or circuit backdoors), and privacy attacks (including model extraction and training data inference). This work provides a foundation for more realistic threat modeling and proactive security-in-depth design in the emerging field of quantum machine learning.",
      "citationCount": 1,
      "doi": "10.1109/QCE65121.2025.00183",
      "arxivId": "2507.08623",
      "url": "https://www.semanticscholar.org/paper/71ff23a33bc4db47a76808717acc78d9b04a7e1e",
      "venue": "International Conference on Quantum Computing and Engineering",
      "journal": {
        "name": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
        "pages": "1653-1664",
        "volume": "01"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    }
  ],
  "count": 30,
  "errors": []
}
