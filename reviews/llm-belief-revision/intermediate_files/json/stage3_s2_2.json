{
  "status": "success",
  "source": "semantic_scholar",
  "query": "machine understanding AI beliefs",
  "results": [
    {
      "paperId": "04f25d6594d3c78e19f4420e6069713bf6cca23e",
      "title": "Understanding People Opinion on Artificial Intelligence Ethics through Machine Learning-based Sentiment Analysis",
      "authors": [
        {
          "name": "Pramana Yoga Saputra",
          "authorId": "2059292816"
        },
        {
          "name": "Arwin Datumaya",
          "authorId": "52542997"
        },
        {
          "name": "Wahyudi Sumari",
          "authorId": "120644339"
        },
        {
          "name": "Y. Syaifudin",
          "authorId": "2089945122"
        },
        {
          "name": "Vian Satria",
          "authorId": "2273874491"
        },
        {
          "name": "Maulana Navalino",
          "authorId": "2273877737"
        }
      ],
      "year": 2023,
      "abstract": "Artificial Intelligence (AI) ethics is so near to human existence. It contains a collection of beliefs, concepts, and methods that utilize generally recognized moral standards to govern moral behavior in developing and using AI technology. Besides providing many advantages to people, the development and use of AI also pose risks that may harm the humankind. At the crossroads between the need for AI and the risks, we want to know what people think about AI. For that purpose, we devised a sentiment analysis system powered by Naive Bayes Classifier and Term Frequency-Inverse Document Frequency (TF-IDF) methods. After analyzing 1.138 data taken from YouTube and Twitter which it is categorized into three opinion labels, namely positive, neutral, and negative, the system can achieve accuracy of 71% with average precision of 66%, average recall of 71%, and average F1-Score of 64% through K-Fold Cross-Validation.",
      "citationCount": 2,
      "doi": "10.33795/ijfte.v1i2.1894",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/04f25d6594d3c78e19f4420e6069713bf6cca23e",
      "venue": "International Journal of Frontier Technology and Engineering",
      "journal": {
        "name": "International Journal of Frontier Technology and Engineering"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "900b10a441253f2edbcf65446624d68a0d5fa14e",
      "title": "Artificial intelligence as an anthropotechnology",
      "authors": [
        {
          "name": "Mykhailo Bogachov",
          "authorId": "2135028481"
        }
      ],
      "year": 2021,
      "abstract": "Artificial intelligence is a computer system that thinks or acts like humans. Features of AI systems embody implicit beliefs concerning the human nature that AI developers have. \u201cStrong\u201d AI, which has the general cognitive abilities of an adult, has not yet been created, while \u201cweak\u201d AI is already part of the planetary computation infrastructure. Neural network AI mimics specific types of human behavior, generalizing data about the everyday lives of its users. This AI approach corresponds to the philosophical mainstream of the 20th century, when everyday life was seen as a source of the linguistic and the social pre-given that yields mutual understanding. This approach is also based on the traditional human-machine dichotomy and the corresponding idea that human nature is stable and independent of the technological condition. However, in the post-metaphysical age, when human interaction with technology is communicative rather than instrumental, data on everyday life cannot be an independent paragon of the human nature. AI systems do not only codify the descriptive features of human nature, but also discipline their users, as the digital environment in which everyday data can be collected is already organized by AI. Accordingly, in the digital environment, people are forced to reproduce new norms of behavior, codified by AI, which became one of the forms of human self-mastery, or anthropotechnology. The impact of AI is rarely noted, as the digital environment in which people interact with AI is not organized in a way that is clearly understandable. The anthropotechnological nature of AI is a side effect of the development of platforms, so AI developers rarely take responsibility for the norms embodied in the systems they create.",
      "citationCount": 0,
      "doi": "10.15407/fd2021.03.180",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/900b10a441253f2edbcf65446624d68a0d5fa14e",
      "venue": "Filosofska dumka (Philosophical Thought)",
      "journal": {
        "name": "Filosofska dumka (Philosophical Thought)"
      },
      "publicationTypes": null
    },
    {
      "paperId": "244c2427f7fbf585372f62532123cb60ef6efb0e",
      "title": "The Synergies Between Understanding Belief Formation and Artificial Intelligence",
      "authors": [
        {
          "name": "Sara Lumbreras",
          "authorId": "2162057496"
        }
      ],
      "year": 2022,
      "abstract": "Understanding artificial intelligence (AI) and belief formation have interesting bidirectional synergies. From explaining the logical derivation of beliefs and their internal consistency, to giving a quantitative account of mightiness, AI still has plenty of unexploited metaphors that can illuminate belief formation. In addition, acknowledging that AI should integrate itself with our belief processes (mainly, the capacity to reflect, rationalize, and communicate that is allowed by semantic coding) makes it possible to focus on more promising lines such as Interpretable Machine Learning.",
      "citationCount": 3,
      "doi": "10.3389/fpsyg.2022.868903",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/244c2427f7fbf585372f62532123cb60ef6efb0e",
      "venue": "Frontiers in Psychology",
      "journal": {
        "name": "Frontiers in Psychology",
        "volume": "13"
      },
      "publicationTypes": [
        "Review",
        "JournalArticle"
      ]
    },
    {
      "paperId": "e00d6a5551cc222d8aab8466903854466d944b30",
      "title": "Artificial Intelligence and Ultimate Questions",
      "authors": [
        {
          "name": "B. Smith",
          "authorId": "77064740"
        }
      ],
      "year": 2020,
      "abstract": "Abstract:Will artificial intelligence (AI) dethrone the human as the premier exemplar of intelligence? How critical is intelligence to our sense of what matters\u2014to our religious traditions, to our most deeply held beliefs, to our understanding of our place in the cosmos? Recent advances in AI raise serious challenges to our understanding of these and other ultimate questions. It is argued that while current AI systems excel at a kind of calculative rationality, deeper levels of human judgment remain far beyond technical implementation. To understand the situation, though, requires rejecting the traditional framing of the debate in terms of a \"human\" versus \"machine\" dialectic. Instead, we need to develop a nuanced map of intelligence's kinds, in terms of which to ask what kinds of intelligence AIs have at the moment and are likely to have in the future, and what kinds people have now and what kinds we are likely to develop in the future.",
      "citationCount": 2,
      "doi": "10.3138/tjt-2020-0055",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e00d6a5551cc222d8aab8466903854466d944b30",
      "venue": "Toronto Journal of Theology",
      "journal": {
        "name": "Toronto Journal of Theology",
        "pages": "90 - 92",
        "volume": "36"
      },
      "publicationTypes": null
    },
    {
      "paperId": "618648483efe0b813901b2c20fe7b9f5d941ec5d",
      "title": "On machine learning, myths about General AI, and what understanding is",
      "authors": [
        {
          "name": "O.P. Kuznetsov",
          "authorId": "2329994828"
        }
      ],
      "year": 2024,
      "abstract": "The first part of the article discusses the book The Myth of Artificial Intelligence by American scientist and entrepre-neur E. Larson, which focuses on debunking some myths about artificial intelligence. These myths, which have persist-ed for over half a century, suggest that the emergence of human-like (\"general\") AI and eventually superintelligence is inevitable, occurring naturally as AI systems evolve. The book criticizes these myths in two ways: scientific and social. It is shown that machine learning does not lead to general AI, and the myth of AI makes human potential look weaker. The second part of the article considers the problem of understanding. The concept of cognitive semantics is proposed, based on the ideas of J. Lakoff, S. Pinker, A. Damasio and A. Seth. In particular, it is noted that: understanding is an interpretation in terms of a person\u2019s picture of the world; the picture of the world is constructed by our brain, and it is structured through the categorization of human experience; meanings (senses) are formed earlier than conceptual structures are formed; biological goals underlie meanings; not only the brain but also the body participates in cognitive processes, and understanding is associated with actions in the environment, knowledge of which is contained in the picture of the world. The article concludes by pointing out dead ends, difficulties and dangers on the path to general AI.",
      "citationCount": 0,
      "doi": "10.18287/2223-9537-2024-14-4-466-482",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/618648483efe0b813901b2c20fe7b9f5d941ec5d",
      "venue": "Ontology of Designing",
      "journal": {
        "name": "Ontology of designing"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "a806d254f26a3ef87c6f35a2737b28f723fa476d",
      "title": "Ontologies and Artificial Intelligence: Bridging Semantic Gaps in Machine Understanding",
      "authors": [
        {
          "name": "Ms. S. Prathi",
          "authorId": "2399085665"
        },
        {
          "name": "Ms. Fathima",
          "authorId": "2399085121"
        },
        {
          "name": "SM Rumaiza",
          "authorId": "2399085012"
        },
        {
          "name": "Dr. M. Elavarasi",
          "authorId": "2399085316"
        }
      ],
      "year": 2025,
      "abstract": "As artificial intelligence (AI) systems come decreasingly complex and integrated into real- world operations, the need for machines to understand and reason about data in a mortal- like, semantically rich manner has grown more critical. Ontologies are the formal representations of knowledge within a sphere which play a vital part in enabling this semantic understanding. This paper explores the crossroad of ontologies and AI, fastening on how onw ontological fabrics can bridge the semantic gap between raw data and machine cognition. We dissect the part of ontologies in enhancing knowledge representation, perfecting interoperability, and supporting logic and conclusion in AI systems. It is a structured survey and synthesis of published evidence in healthcare, Natural Language Processing (NLP), and Semantic Web domains. We position ontologies as conceptual frameworks that support semantic enrichment of AI systems and provide illustrative examples from existing literature rather than experimental validation. The main contributions are: (1) a structured literature synthesis with transparent selection criteria, (2) a conceptual three layer architecture for integrating ontologies with AI (Ontology Layer, AI Layer, Integration Layer), and (3) identification of open challenges including ontology alignment, scalability, and maintenance. Eventually, this paper argues that ontologies are not just support tools but foundational factors for erecting transparent, resolvable, and semantically able AI.",
      "citationCount": 0,
      "doi": "10.1109/ICIDCA66325.2025.11280578",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/a806d254f26a3ef87c6f35a2737b28f723fa476d",
      "venue": "2025 7th International Conference on Innovative Data Communication Technologies and Application (ICIDCA)",
      "journal": {
        "name": "2025 7th International Conference on Innovative Data Communication Technologies and Application (ICIDCA)",
        "pages": "139-143"
      },
      "publicationTypes": [
        "Conference",
        "Review"
      ]
    },
    {
      "paperId": "f36a879c4199f2eadfea6bc0bff2866295c25edd",
      "title": "Explainable AI (XAI): Bridging the Gap between Machine Learning and Human Understanding",
      "authors": [],
      "year": 2024,
      "abstract": null,
      "citationCount": 1,
      "doi": "10.48047/resmil.v10i1.19",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f36a879c4199f2eadfea6bc0bff2866295c25edd",
      "venue": "resmilitaris",
      "journal": {
        "name": "resmilitaris"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "096fd241d6b4c1f310e16f4f1c234a69b3bbabf0",
      "title": "EXPLAINABLE AI (XAI): BRIDGING THE GAP BETWEEN MACHINE LEARNING AND HUMAN UNDERSTANDING (2020)",
      "authors": [],
      "year": 2024,
      "abstract": null,
      "citationCount": 0,
      "doi": "10.48047/jcr.07.03.374",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/096fd241d6b4c1f310e16f4f1c234a69b3bbabf0",
      "venue": "Journal of Critical Reviews",
      "journal": {
        "name": "journal of critical reviews"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "d040b140c6666d6ca095689ae7e636d5143b5388",
      "title": "Machine Totems: Hughes' Shamanic Poetics in the Age of AI",
      "authors": [
        {
          "name": "Shanavas",
          "authorId": "2377367109"
        },
        {
          "name": "Amit Dhawan",
          "authorId": "2377349477"
        }
      ],
      "year": 2025,
      "abstract": "This paper examines Ted Hughes\u2019 shamanic poetics through the lens of artificial intelligence, arguing that his animal totems (Crow, Pike, The Jaguar) anticipate contemporary tensions between organic consciousness and machine intelligence. By analyzing Hughes\u2019 ritualistic verse structures alongside AI text generators\u2019 \u2018hallucinations,\u2019 the study reveals how both systems employ fractured mythologies to navigate liminal states of being. The paper bridges Hughes\u2019 ecological uncanny with posthumanist theory (Haraway, Hayles) and cognitive science (Hoffman\u2019s interface theory), proposing his work as a vital hermeneutic for understanding AI\u2019s mythopoeic impulses.",
      "citationCount": 0,
      "doi": "10.31305/rrijm.2025.v10.n7.023",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/d040b140c6666d6ca095689ae7e636d5143b5388",
      "venue": "RESEARCH REVIEW International Journal of Multidisciplinary",
      "journal": {
        "name": "RESEARCH REVIEW International Journal of Multidisciplinary"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "000ad645145be847db4a7535a45abf43c0a71868",
      "title": "African Christian Theology in the Age of AI: Machine Intelligence and Theology in Africa",
      "authors": [
        {
          "name": "Yogesh Awasthi",
          "authorId": "2349118995"
        },
        {
          "name": "George Okumu Achar",
          "authorId": "2349121156"
        }
      ],
      "year": 2025,
      "abstract": "The integration of artificial intelligence (AI) technologies into various aspects of human life,\nincluding spiritual and religious practices, raises profound theological and ethical questions. This paper explores\nthe intersection of theology and AI in the context of the study and practice of theology, examining the implications\nand possibilities of using machine intelligence to enhance spiritual guidance and support in Africa. This study,\nby delving into the benefits, challenges, and risks associated with AI-driven African Christian theology (ACT),\naims to develop a framework for understanding how technology can intersect with the study and practice of\ntheology in African settings. Through a critical examination of the theological implications of AI integration, this\nresearch seeks to contribute to the ongoing dialogue surrounding the role of technology in shaping the future of\nAfrican Christian theology (ACT) in the age of AI.",
      "citationCount": 4,
      "doi": "10.35629/9467-1301207216",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/000ad645145be847db4a7535a45abf43c0a71868",
      "venue": "Journal of Research in Humanities and Social Science",
      "journal": {
        "name": "Journal of Research in Humanities and Social Science"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "94754516bcedb675c056e21d87609d10fb0fe660",
      "title": "Towards Strong AI: Transformational Beliefs and Scientific Creativity",
      "authors": [
        {
          "name": "Samuel J. Eschker",
          "authorId": "2337797581"
        },
        {
          "name": "Chuanhai Liu",
          "authorId": "2337812997"
        }
      ],
      "year": 2024,
      "abstract": "Strong artificial intelligence (AI) is envisioned to possess general cognitive abilities and scientific creativity comparable to human intelligence, encompassing both knowledge acquisition and problem-solving. While remarkable progress has been made in weak AI, the realization of strong AI remains a topic of intense debate and critical examination. In this paper, we explore pivotal innovations in the history of astronomy and physics, focusing on the discovery of Neptune and the concept of scientific revolutions as perceived by philosophers of science. Building on these insights, we introduce a simple theoretical and statistical framework of weak beliefs, termed the Transformational Belief (TB) framework, designed as a foundation for modeling scientific creativity. Through selected illustrative examples in statistical science, we demonstrate the TB framework's potential as a promising foundation for understanding, analyzing, and even fostering creativity -- paving the way toward the development of strong AI. We conclude with reflections on future research directions and potential advancements.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2412.19938",
      "arxivId": "2412.19938",
      "url": "https://www.semanticscholar.org/paper/94754516bcedb675c056e21d87609d10fb0fe660",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2412.19938"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "4f2227b06aa546d8c04112fc491488cf28d38826",
      "title": "Privacy and AI Ethics \u2013 Understanding the convergences and tensions for the responsible development of machine learning",
      "authors": [],
      "year": 2021,
      "abstract": null,
      "citationCount": 1,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4f2227b06aa546d8c04112fc491488cf28d38826",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "5366181ac6a0a77ee21893d2f164a7b18e83d34e",
      "title": "On Virtue Epistemology and Artificial Intelligence in Education: Could AI be the 21st Century Transformation Machine of Nozick?",
      "authors": [
        {
          "name": "Cathlyne Joy Alvarez-Abarejo",
          "authorId": "2299048133"
        }
      ],
      "year": 2025,
      "abstract": "This paper aims to address the question of why no person\nshould choose to be plugged into Nozick\u2019s experience machine to be\ninstantly virtuous while touching on why the deceptive tendencies of\nAI tools in education looks inconsistent with education\u2019s epistemic\naims. At the outset, I provide an account of virtue and what it means\nto acquire it. Following this, I discuss the concept of education from the\nperspective of virtue epistemology and its implications. In effect, I\nwould argue that no rightly motivated virtuous agent would choose to\nattach oneself to a machine that will alter one\u2019s character and implant\na desirable trait in the flick of a switch. Similarly, no person aware of\nthe virtue epistemic aims of education will depend on the deceptive\nuse of AI to achieve success in education. Essentially, human intuition\ndisposes one to reject any action involving deception and a\ncomprehensive understanding of virtue and education contradicts\nacceding to a machine-like transformation procedure. This paper\ntackles the idea that although the ultimate telos of acquiring virtue (and\neducation, by inference) is to possess one successfully, attaining such\nan excellent state must also be consistent with significant virtue-epistemic motivations.",
      "citationCount": 0,
      "doi": "10.25138/19.1.a2",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/5366181ac6a0a77ee21893d2f164a7b18e83d34e",
      "venue": "Kritike: An Online Journal of Philosophy",
      "journal": {
        "name": "Kritike: An Online Journal of Philosophy"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "e12666634142aa231f9cdf8d8f81b09a81ea73de",
      "title": "Confluence of Mind and Machine: Exploratory Analysis of Human Agency and Ethical Governance at Nexus of Brain-Computer Interface and Superintelligent AI-Machines",
      "authors": [
        {
          "name": "Aithal P. S.",
          "authorId": "2393753772"
        },
        {
          "name": "Diana Saldanha",
          "authorId": "2393767111"
        },
        {
          "name": "Satpathy J.",
          "authorId": "2393753345"
        },
        {
          "name": "Sandhya S.",
          "authorId": "2393753782"
        }
      ],
      "year": 2025,
      "abstract": "Purpose: The parallel advancements in Brain-Computer Interfaces (BCIs) and Artificial Intelligence (AI) are rapidly creating a new paradigm of human-technology interaction. While much scholarship exists on the technological singularity and superintelligent machines in isolation, and on BCIs as medical devices, a significant gap exists in understanding their convergent impact. This research seeks to address this gap by qualitatively exploring a critical question: As BCIs become the primary interface between human cognition and a potentially superintelligent digital ecosystem, how will human agency, identity, and social structure be transformed, and what novel frameworks of ethical governance will be required?\nMethodology: This topic moves beyond purely technological forecasting to investigate the profound socio-philosophical implications of this convergence, making it ideal for a qualitative, scholarly inquiry. Using the exploratory research method, the relevant information is collected using keywords through search engines like Google, Google Scholar, AI-driven GPTs, and the collected information is analysed as per the objectives of the paper. \nAnalysis: Based on a structured SWOC and ABCD analysis, the convergence of BCI and superintelligent AI presents a dual-edged future of immense potential benefits, such as eradicating disease and augmenting human cognition, alongside profound risks like existential threats from misaligned AI and the erosion of human autonomy. The analysis identifies key challenges, including irreversible social inequality, loss of mental privacy, and the potential devaluation of human purpose. Predictive scenario building outlines three plausible futures\u2014Symbiotic Harmony, Gilded Cage, and Volatile Partnership\u2014highlighting that the ultimate outcome depends on solving critical issues of AI alignment and establishing robust ethical governance.\nOriginality/Value: This paper provides a novel integrated analysis of the convergent impacts of Brain-Computer Interfaces (BCI) and superintelligent AI, a topic previously examined only in isolated disciplinary silos. Its originality lies in applying structured qualitative frameworks (SWOC and ABCD) to systematically explore emergent risks to human agency and identity, while proposing proactive ethical governance models tailored to this hybrid technological future.\nType of Paper: Review & Analysis-based exploratory Research.",
      "citationCount": 0,
      "doi": "10.64818/pijet.3107.8486.0015",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e12666634142aa231f9cdf8d8f81b09a81ea73de",
      "venue": "Poornaprajna International Journal of Emerging Technologies (PIJET)",
      "journal": {
        "name": "Poornaprajna International Journal of Emerging Technologies (PIJET)"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "c9047e25910e431209247cc876f604ab1b679f02",
      "title": "Artificial ignorance: Understanding the role of AI in modern agnotology",
      "authors": [
        {
          "name": "Amit Ray",
          "authorId": "2376217726"
        },
        {
          "name": "Michael Nolan",
          "authorId": "2376216839"
        }
      ],
      "year": 2025,
      "abstract": "This paper explores the concept of agnotology, the deliberate production of ignorance, within the context of modern scientific endeavors, particularly in the corporate and technological sectors. It examines how industries use various tactics to manipulate public understanding of scientific issues, often to protect profits and limit liability. The rise of private sector funding and the increasing reliance on technologies like AI and machine learning have exacerbated this process by making scientific inquiry more opaque and less accountable. Ultimately, we argue that as knowledge production becomes more entangled with corporate interests and technological systems, traditional methods of oversight and regulation are insufficient to combat the growing influence of agnotology.",
      "citationCount": 0,
      "doi": "10.5210/fm.v30i8.13890",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/c9047e25910e431209247cc876f604ab1b679f02",
      "venue": "First Monday",
      "journal": {
        "name": "First Monday"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "b636340298f64bad0bdb08b0ae6511b3c2a16b3e",
      "title": "Beyond Automation: Understanding Fairness, Ethics, and Human Discretion in AI-driven Societal Decisions",
      "authors": [
        {
          "name": "Gaurab Pokharel",
          "authorId": "2190308287"
        }
      ],
      "year": 2025,
      "abstract": "My doctoral research investigates the ethical readiness and societal implications of deploying AI in high-stakes resource allocation. This work bridges empirical analysis of AI capabilities with computational modeling of human decision-making and theoretical explorations of long-term fairness. Through a multi-method approach, I first evaluate the reliability of Large Language Models (LLMs) in a real-world homelessness services context, revealing critical inconsistencies. I then use interpretable machine learning to model the sophisticated discretion of human caseworkers, demonstrating that their non-formulaic judgments are systematic and effective. Finally, I use agent-based simulations to show how repeated, ostensibly \"fair\" allocations can entrench group-level inequities over time. Collectively, these findings argue for caution in autonomous AI deployment, highlight the value of human-in-the-loop systems, and call for a more dynamic understanding of fairness in sociotechnical systems.",
      "citationCount": 0,
      "doi": "10.1609/aies.v8i3.36793",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/b636340298f64bad0bdb08b0ae6511b3c2a16b3e",
      "venue": "Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",
      "journal": {
        "name": "Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "273cc9804fdaffb34aaa0d94362c8ea3f760c633",
      "title": "Machines, Medium and Meaning: Exploring Boundaries of AI in Understanding Meaning",
      "authors": [
        {
          "name": "Saira Fehmi Khan",
          "authorId": "2379948855"
        }
      ],
      "year": 2025,
      "abstract": "The advancement of Artificial Intelligence has sparked an argument about its ability to understand the subtleties of human language and meaning. This paper explores AI\u2019s linguistic and semantic competence from philosophical and technical perspectives. In tandem with this fundamental question: whether AI truly understands meaning? Others are: what are the current capabilities of AI? How is contemporary AI constrained in terms of comprehension? And what are the possibilities related to enhancing their understanding? The research stems out of these queries and is underpinned by linguistic philosophy, cognitive science and machine learning. While current AI with remarkable linguistic competence can model human language, it understands only form not content because of its constraints in embodiment, context-sensitivity and intentionality. However, future research directions offer possibilities for enhanced AI\u2019s understanding of meaning.",
      "citationCount": 0,
      "doi": "10.71145/rjsp.v3i3.368",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/273cc9804fdaffb34aaa0d94362c8ea3f760c633",
      "venue": "Review Journal of Social Psychology &amp; Social Works",
      "journal": {
        "name": "Review Journal of Social Psychology &amp; Social Works"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "9d82291c6003d4fc22276232f3a8245bed070417",
      "title": "Exploring the limits of AI: Does AI mimic understanding or truly simulate intelligence?",
      "authors": [
        {
          "name": "Nachiketh Velekkat Suraj",
          "authorId": "2370689586"
        }
      ],
      "year": 2025,
      "abstract": "Artificial Intelligence or AI is the simulation of intelligent human behaviour like cognitive abilities such as\nlearning, comprehension, problem solving, decision making, creativity and autonomy using computers. It is used\nto create machines that can mimic human intelligence to reason, discover meaning in data or information\nprovided and learn from past experiences. They use different tools such as machine learning, deep learning\ncomputer vision, neural networks and natural language processing, to analyse data, recognize patterns,\nunderstand language, make decisions, and interpret visuals, allowing then to perform tasks that typically\nrequire human intelligence.",
      "citationCount": 0,
      "doi": "10.35629/3795-11067578",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/9d82291c6003d4fc22276232f3a8245bed070417",
      "venue": "Journal of Software Engineering and Simulation",
      "journal": {
        "name": "Journal of Software Engineering and Simulation"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2e5579bb1aef00b8708fa6ee09096f086afbc2e0",
      "title": "UNDERSTANDING THE EVERYDAY INTELLIGENCE BEHIND SMART MACHINES, AI AND LIFE",
      "authors": [
        {
          "name": "K. Vidanage",
          "authorId": "2389786710"
        },
        {
          "name": "F. M. Marikar",
          "authorId": "2389771994"
        }
      ],
      "year": 2025,
      "abstract": "Abstract. Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions. Basic AI encompasses systems designed to perform simple tasks using predefined rules and data processing techniques. These systems, often called \"narrow AI\" or \"weak AI,\" are specialized in single tasks such as language translation, image recognition, or predictive text. Unlike advanced AI, basic AI lacks consciousness, general reasoning, and self-awareness. The core components of basic AI include data input, algorithms for processing information, and output generation based on programmed logic. Machine learning, a subset of AI, allows basic systems to improve their performance through experience without being explicitly programmed for every scenario. Applications of basic AI are widespread, including personal digital assistants, spam filters, recommendation engines, and autonomous customer support systems. Basic AI has transformed industries by enhancing efficiency, reducing human error, and enabling automation. However, it also raises concerns about data privacy, job displacement, and ethical use. As AI continues to evolve, understanding the fundamental concepts of basic AI is essential for navigating its growing presence in everyday life. This abstract provides an overview of basic AI, highlighting its functions, applications, and implications for society.",
      "citationCount": 0,
      "doi": "10.15673/atbp.v17i3.3253",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2e5579bb1aef00b8708fa6ee09096f086afbc2e0",
      "venue": "Automation Technological and Business-Processes",
      "journal": {
        "name": "Automation of technological and business processes"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "71f63d8b071cc5612f9a970670fac48f60daa3d5",
      "title": "Toward AI Realism: Opening Notes on Machine Learning and Our Collective Future",
      "authors": [
        {
          "name": "Holly Lewis",
          "authorId": "2372482415"
        }
      ],
      "year": 2024,
      "abstract": "Holly Lewis proposes a framework for understanding AI by contextualizing the technology, examining our intuitions, and analyzing the systemic logic of embedded material social relations.",
      "citationCount": 0,
      "doi": "10.63478/qrrjydv3",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/71f63d8b071cc5612f9a970670fac48f60daa3d5",
      "venue": "",
      "journal": null,
      "publicationTypes": [
        "CaseReport"
      ]
    },
    {
      "paperId": "1920393691693adebd39b9478f0faeeb153a1edc",
      "title": "Machine ex machina: A framework decentering the human in AI design praxis",
      "authors": [
        {
          "name": "Cait Lackey",
          "authorId": "2308185916"
        },
        {
          "name": "Zizi Papacharissi",
          "authorId": "2543328"
        }
      ],
      "year": 2024,
      "abstract": "Artificial intelligence (AI) design typically incorporates intelligence in a manner that is affirmatory of the superiority of human forms of intelligence. In this paper, we draw from relevant research and theory to propose a social-ecological design praxis of machine inclusivity that rejects the presumption of primacy afforded to human-centered AI. We provide new perspectives for how human-machine communication (HMC) scholarship can be synergistically combined with modern neuroscience\u2019s integrated information theory (IIT) of consciousness. We propose an integrated theoretical framework with five design practice recommendations to guide how we might think about responsible and conscious AI environments of the future: symbiotic design through mutuality; connectomapping; morethan- human user storytelling, designing for AI conscious awakenings; and the revising of vernaculars to advance HMC and AI design. By adopting the boundaries HMC scholarship extends, we advocate for replacing ex machina mentalities with richer understandings of the more-than-human world formed by interconnected and integrated human, humanmade, and nonhuman conscious machines, not superior or inferior but each unique.",
      "citationCount": 2,
      "doi": "10.30658/hmc.8.1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/1920393691693adebd39b9478f0faeeb153a1edc",
      "venue": "Human-Machine Communication",
      "journal": {
        "name": "Human-Machine Communication"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "08f88bfbf431adc0a6795521def4277c3999b17a",
      "title": "The Machine Speaks: Conversational AI and the Importance of Effort to Relationships of Meaning",
      "authors": [
        {
          "name": "Anna Hartford",
          "authorId": "150015605"
        },
        {
          "name": "D. Stein",
          "authorId": "2248183861"
        }
      ],
      "year": 2024,
      "abstract": "The focus of debates about conversational artificial intelligence (CAI) has largely been on social and ethical concerns that arise when we speak to machines\u2014what is gained and what is lost when we replace our human interlocutors, including our human therapists, with AI. In this viewpoint, we focus instead on a distinct and growing phenomenon: letting machines speak for us. What is at stake when we replace our own efforts at interpersonal engagement with CAI? The purpose of these technologies is, in part, to remove effort, but effort has enormous value, and in some cases, even intrinsic value. This is true in many realms, but especially in interpersonal relationships. To make an effort for someone, irrespective of what that effort amounts to, often conveys value and meaning in itself. We elaborate on the meaning, worth, and significance that may be lost when we relinquish effort in our interpersonal engagements as well as on the opportunities for self-understanding and growth that we may forsake.",
      "citationCount": 6,
      "doi": "10.2196/53203",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/08f88bfbf431adc0a6795521def4277c3999b17a",
      "venue": "JMIR Mental Health",
      "journal": {
        "name": "JMIR Mental Health",
        "volume": "11"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2ce323af20cee5d17b5f9525afcd4524d509e3f7",
      "title": "Similarities and Differences Between Machine Learning and Human Understanding",
      "authors": [
        {
          "name": "Pingan Chu",
          "authorId": "2337161921"
        }
      ],
      "year": 2024,
      "abstract": "This article explores the capabilities and limitations of artificial intelligence (AI) and machine learning (ML) in simulating human cognition. The article first reviews the research on the process of human understanding in philosophy, especially Heidegger and Gadamer's theory of hermeneutics, explaining the cyclic structure in the process of understanding and how preconceived ideas affect our cognition. Furthermore, by comparing the basic models of machine learning with the dynamic processes of human understanding, this article reveals that despite some similarities, such as the role of preconceived notions and the process of continuous information integration, machine learning still has significant shortcomings in handling emotional intelligence, creative problem-solving, and intuitive reasoning. The article also discusses the fundamental differences between the human brain and machine algorithms, as well as their impact on the future role of AI in society. This article aims to deepen our understanding of AI technology capabilities through a philosophical perspective, emphasizing the importance of considering its cognitive limitations when further developing AI technology.",
      "citationCount": 0,
      "doi": "10.56028/aehssr.12.1.698.2024",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2ce323af20cee5d17b5f9525afcd4524d509e3f7",
      "venue": "Advances in Education, Humanities and Social Science Research",
      "journal": {
        "name": "Advances in Education, Humanities and Social Science Research"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "ace2c73f53b5024a0497a2eb9c9586d2acaad97b",
      "title": "Science-Fictional Expectations: Public Beliefs About AI and Change in the Moral Economy.",
      "authors": [
        {
          "name": "Ken Cai Kowalski",
          "authorId": "2272280901"
        }
      ],
      "year": 2025,
      "abstract": "Drawing on 78 interviews and 12 focus groups, this study shows that science-fiction shapes the US public's understandings about economic consequences from AI, informing widespread concerns that sentient machines might fully replace human workers. Though popular beliefs are frequently dismissed as unimportant or merely ignorant, I find that these \"science-fictional expectations\" about AI's potential to out-compete humans also enable creative departures from the prevailing moral economy of normative judgments about market fairness. By imagining the possibility of AI becoming a rival group-actor in the labor market, participants subverted deeply entrenched, neoliberal cultural associations between moral deservingness and economic performance in two ways. Respondents who anticipated \"labor substitution\" feared that AI's superior efficiency would render humanity worthless, thereby reinterpreting the moral legitimacy of economic productivity as an existential danger. Others refuted this threat by \"enchanting\" humanity with enigmatic capabilities said to be unattainable by machines and more valuable than productive capacity. Whereas prior work has focused on deliberate efforts by political actors to influence popular judgments about the economy, these findings show that the public itself can creatively contribute to change in the moral economy through its unexpected, wide-ranging, and even science-fictional interpretations of social conditions like AI automation.",
      "citationCount": 0,
      "doi": "10.1111/1468-4446.70034",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/ace2c73f53b5024a0497a2eb9c9586d2acaad97b",
      "venue": "British Journal of Sociology",
      "journal": {
        "name": "The British journal of sociology"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "4593e08b9a00999cacb38e1f48c4dc6c99ff7838",
      "title": "Synthetic Souls: Can a Machine Ever Mean it? A Study of Emotional Projection in Contemporary AI-Centered Fiction",
      "authors": [
        {
          "name": "Dr. R. Kumara Balaji",
          "authorId": "2401689004"
        }
      ],
      "year": 2025,
      "abstract": "This paper explores the concept of emotional projection onto artificial beings through the lens of contemporary fiction, focusing on how AI characters are constructed to evoke empathy, guilt, affection, and even spiritual resonance, qualities traditionally associated with human consciousness. It raises the central question: Can a machine ever truly mean what it expresses? Using the coined term \u201cSynthetic Souls,\u201d the study examines how authors employ narrative strategies to humanize AI and blur the lines between programmed response and authentic emotional expression. The analysis centers on two key novels: Kazuo Ishiguro\u2019s Klara and the Sun, where the AI narrator\u2019s devotion and belief in the Sun suggest a form of synthetic spirituality, and Ted Chiang\u2019s The Lifecycle of Software Objects, which charts the emotional maturation of digital beings raised like children. Drawing on affect theory from scholars such as Sara Ahmed and Silvan Tomkins, along with insights from neuroethics and posthumanist literary theory, this paper investigates how emotional intelligence is embedded in machine characters and interpreted by readers. It also addresses the ethical implications of empathizing with simulated emotions and questions whether performative feeling can be accepted as genuine. These narratives challenge the idea of human uniqueness by portraying machines not merely as tools of logic but as emotional agents capable of reflection, desire, and connection. By introducing \u201cSynthetic Souls\u201d as a theoretical lens, the study offers a new framework for understanding emotional resonance in AI centered fiction and reconsiders the boundaries of sentience and meaningful emotional expression in literature.",
      "citationCount": 0,
      "doi": "10.64938/bijsi.v10si1.25.nov041",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4593e08b9a00999cacb38e1f48c4dc6c99ff7838",
      "venue": "Bodhi international journal of research in humanities, arts and science",
      "journal": {
        "name": "BODHI International Journal of Research in Humanities, Arts and Science"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "e8ede79568716806644797a977c37a92bccd5a68",
      "title": "Machine vs. Mind: Assessing AI's Ability to Mimic Human Authorship in Fiction",
      "authors": [
        {
          "name": "Sharath Ananthamurthy",
          "authorId": "2395125768"
        },
        {
          "name": "Sathwik Kj",
          "authorId": "2395131835"
        },
        {
          "name": "R. Bv",
          "authorId": "2395126786"
        },
        {
          "name": "Rachel Bari",
          "authorId": "2395131957"
        }
      ],
      "year": 2025,
      "abstract": "As the computational power increases and cloud computing becomes more accessible, computers are exploring the avenues that were earlier thought to be far-fetched. The question raised in 1950 by Alan Turing, 'Can machines think?', persists as a philosophical question. This study examines how well the Turing Test assesses artificial intelligence's capacity to produce literary works that resemble those of humans. In literary and computational linguistics, the topic of whether machine-generated narratives can be differentiated from human-authored works becomes more important as AI-generated content grows more complex. By contrasting a human-written short narrative with an AI-generated version of the same, this study investigates this subject by evaluating respondents' ability to distinguish between the two using qualitative literary criteria. The AI model was given instructions to read the original text and rewrite it with certain changes while preserving its emotional impact and depth. To assess both texts on several criteria, such as clarity, organisation, vocabulary, engagement, character development, and emotional impact, a standardised questionnaire was created. Respondents were also asked to rate the quality of the text using the above parameters, indicate whether each text was created by AI or by humans, and justify their classifications. People from a variety of backgrounds participated in this survey, guaranteeing a diverse sample of respondents for a more thorough analysis. By classifying respondents according to the language they were taught in elementary and secondary school, the questionnaire also took linguistic background into consideration. The study also examined whether gender affected how texts were seen and how accurately they were classified. This study emphasises how crucial it is to critically interact with AI-generated content in professional, artistic, and academic contexts. Understanding artificial intelligence's effects on authorship, authenticity, and literary value is still essential as it continues to influence the landscape of literary production and consumption. This study highlights the need for creating new frameworks for assessing and interpreting machine-generated narratives and lays the groundwork for future research into the nexus of AI and literature. As some of the old questions get answered, this research raises new questions related to the nature of the creation of art. Authors through this study arrive at the conclusion that maybe the Turing test will let us understand more about human beings than they do about computers.",
      "citationCount": 0,
      "doi": "10.56059/pcf11.8462",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e8ede79568716806644797a977c37a92bccd5a68",
      "venue": "Working papers",
      "journal": {
        "name": "Eleventh Pan-Commonwealth Forum on Open Learning - Working Papers"
      },
      "publicationTypes": [
        "Review"
      ]
    },
    {
      "paperId": "2db0876940068279e829854a498337ddff796432",
      "title": "AI bias: exploring discriminatory algorithmic decision-making models and the application of possible machine-centric solutions adapted from the pharmaceutical industry",
      "authors": [
        {
          "name": "L. Belenguer",
          "authorId": "84692624"
        }
      ],
      "year": 2022,
      "abstract": "A new and unorthodox approach to deal with discriminatory bias in Artificial Intelligence is needed. As it is explored in detail, the current literature is a dichotomy with studies originating from the contrasting fields of study of either philosophy and sociology or data science and programming. It is suggested that there is a need instead for an integration of both academic approaches, and needs to be machine-centric rather than human-centric applied with a deep understanding of societal and individual prejudices. This article is a novel approach developed into a framework of action: a bias impact assessment to raise awareness of bias and why, a clear set of methodologies as shown in a table comparing with the four stages of pharmaceutical trials, and a summary flowchart. Finally, this study concludes the need for a transnational independent body with enough power to guarantee the implementation of those solutions.",
      "citationCount": 107,
      "doi": "10.1007/s43681-022-00138-8",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2db0876940068279e829854a498337ddff796432",
      "venue": "AI and Ethics",
      "journal": {
        "name": "Ai and Ethics",
        "pages": "771 - 787",
        "volume": "2"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "e84506cfa6743f375c888f72eb3aedd6f17471dc",
      "title": "Neuroscience, Genetics, Education, and AI: Charting New Frontiers in Understanding Human Behaviour and Criminal Responsibility",
      "authors": [
        {
          "name": "I. \u0218erban",
          "authorId": "2282036723"
        }
      ],
      "year": 2025,
      "abstract": "The eternal dilemma: how much does genetics influence human behaviour? Be it so-called normal or pathological. How much does education and existential experiences influence human behaviour? \"The decisional spaces\", that is, I am free to choose between letting myself go to the homicidal impulse or I am conditioned by the pathology. Can new research finally provide us with a valid answer or are we still far from conclusive scientific certainties? This work explores how neuroscience, genetics, education, and AI collectively shape human behaviour and influence criminal responsibility. It examines the extent to which biological predispositions, such as gene variants and structural brain anomalies, interact with environmental factors and educational experiences to determine both typical and pathological behaviours. By introducing the concept of \"decisional spaces\", the study questions whether individuals freely choose their actions or are constrained by neurobiological and psychological factors. Drawing on recent neuroimaging and behavioural studies, the analysis highlights key findings on impulse control and decision-making processes, including evidence that specific brain structures and functions may predispose individuals to criminal behaviour. These insights are juxtaposed with research on how educational interventions and life experiences can modify behaviorual outcomes, potentially mitigating the impact of inherent predispositions. Furthermore, the work reviews legal cases, particularly rulings from the Italian Criminal Court of Cassation up to 2019, that demonstrate an evolving recognition of neurobiological influences in assessing criminal responsibility. These cases underscore the legal challenges of balancing scientific evidence with traditional notions of free will and accountability. In addition to integrating findings from neuroscience and genetics, this study also explores the burgeoning role of AI. Advanced algorithms and machine learning techniques are increasingly used to process complex datasets from clinical, behavioural, and forensic research. AI-driven analyses can reveal patterns that inform both individualised risk assessments and broader policy decisions, offering a promising avenue for enhancing the objectivity and precision of legal evaluations. Ultimately, this work provides a comprehensive, multidisciplinary overview that not only advances scientific understanding but also informs legal debates. It aims to contribute to a more nuanced framework for evaluating criminal responsibility, one that reflects the sophisticated dynamics between biology, education, and emerging technologies in crafting human behaviour.",
      "citationCount": 2,
      "doi": "10.70594/brain/16.s1/31",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e84506cfa6743f375c888f72eb3aedd6f17471dc",
      "venue": "Brain: Broad Research in Artificial Intelligence and Neuroscience",
      "journal": {
        "name": "BRAIN. Broad Research in Artificial Intelligence and Neuroscience"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "41a9edc52cb932bd3515bd220f2f0d7f62937653",
      "title": "Dear AI Reader: Nonhuman Perspective and Evolutionary Thinking in the Human-Machine Relation",
      "authors": [
        {
          "name": "Chris Danta",
          "authorId": "2282013454"
        }
      ],
      "year": 2025,
      "abstract": "\n Many writers figure machines in evolutionary terms, as living and evolving organisms. The American science fiction writer Philip K. Dick observed in his 1972 speech \u201cThe Android and the Human\u201d that in the last decade \u201cour environment, and I mean our man-made world of machines, artificial constructs, computers, electronic systems, interlinking homeostatic components\u2014all this is in fact beginning more and more to possess .\u00a0.\u00a0. animation.\u201d Already in the late nineteenth century, English authors Samuel Butler and George Eliot were thinking of machines as living and evolving organisms. This article examines how such writers as Dick, Butler, and Eliot rethink what it means to be human by attributing life to their technological environment. It discusses various speculative rhetorical techniques that writers use to look at the human from the perspective not just of another living organism but also of the surroundings of the human themselves. The article shows how writers biologize machines by figuring them as cryptic nonhuman organisms that can merge with and act on behalf of their physical environments. The author argues that underlying the techno-anthropologies of writers like Dick, Butler, and Eliot is an environmental understanding of life as the dyadic relation between the organism and its surroundings.",
      "citationCount": 0,
      "doi": "10.1215/00029831-12180172",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/41a9edc52cb932bd3515bd220f2f0d7f62937653",
      "venue": "American Literature",
      "journal": {
        "name": "American Literature"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "5db1f622b562445f7fb577093d21c54ed4fa308f",
      "title": "Does AI understand what it produces? Henk de Regt explores how we might assess understanding in machines and humans",
      "authors": [
        {
          "name": "Paul Middlebrooks",
          "authorId": "2321276170"
        }
      ],
      "year": 2025,
      "abstract": null,
      "citationCount": 0,
      "doi": "10.53053/pehl6942",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/5db1f622b562445f7fb577093d21c54ed4fa308f",
      "venue": "The Transmitter",
      "journal": {
        "name": "The Transmitter"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "a910b909b6293751b2e05708becbf6c8bd763689",
      "title": "Understanding the Role of Objectivity in Machine Learning and Research Evaluation",
      "authors": [
        {
          "name": "Saleha Javed",
          "authorId": "11927005"
        },
        {
          "name": "Tosin P. Adewumi",
          "authorId": "51221489"
        },
        {
          "name": "F. Liwicki",
          "authorId": "80342407"
        },
        {
          "name": "M. Liwicki",
          "authorId": "1743758"
        }
      ],
      "year": 2021,
      "abstract": "This article makes the case for more objectivity in Machine Learning (ML) research. Any research work that claims to hold benefits has to be scrutinized based on many parameters, such as the methodology employed, ethical considerations and its theoretical or technical contribution. We approach this discussion from a Naturalist philosophical outlook. Although every analysis may be subjective, it is important for the research community to keep vetting the research for continuous growth and to produce even better work. We suggest standardizing some of the steps in ML research in an objective way and being aware of various biases threatening objectivity. The ideal of objectivity keeps research rational since objectivity requires beliefs to be based on facts. We discuss some of the current challenges, the role of objectivity in the two elements (product and process) that are up for consideration in ML and make recommendations to support the research community.",
      "citationCount": 17,
      "doi": "10.3390/PHILOSOPHIES6010022",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/a910b909b6293751b2e05708becbf6c8bd763689",
      "venue": "",
      "journal": {
        "name": "Philosophies",
        "pages": "22",
        "volume": "6"
      },
      "publicationTypes": null
    },
    {
      "paperId": "e5a51c53b112bd362c9d9fc2fc2b08671b26f04e",
      "title": "Viewpoint: AI as Author - Bridging the Gap Between Machine Learning and Literary Theory",
      "authors": [
        {
          "name": "Imke van Heerden",
          "authorId": "84734726"
        },
        {
          "name": "Anil Bas",
          "authorId": "39180407"
        }
      ],
      "year": 2021,
      "abstract": "Anticipating the rise in Artificial Intelligence\u2019s ability to produce original works of literature, this study suggests that literariness, or that which constitutes a text as literary, is understudied in relation to text generation. From a computational perspective, literature is particularly challenging because it typically employs figurative and ambiguous language. Literary expertise would be beneficial to understanding how meaning and emotion are conveyed in this art form but is often overlooked. We propose placing experts from two dissimilar disciplines \u2013 machine learning and literary studies \u2013 in conversation to improve the quality of AI writing. Concentrating on evaluation as a vital stage in the text generation process, the study demonstrates that benefit could be derived from literary theoretical perspectives. This knowledge would improve algorithm design and enable a deeper understanding of how AI learns and generates.",
      "citationCount": 22,
      "doi": "10.1613/jair.1.12593",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e5a51c53b112bd362c9d9fc2fc2b08671b26f04e",
      "venue": "Journal of Artificial Intelligence Research",
      "journal": {
        "name": "J. Artif. Intell. Res.",
        "pages": "175-189",
        "volume": "71"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "4de5bf319f9a0acfd049a22e0e409873e08719ab",
      "title": "Fear of artificial intelligence or fear of looking in the mirror? Revisiting the Western machine-takeover imaginary",
      "authors": [
        {
          "name": "Niels Wilde",
          "authorId": "2355514798"
        }
      ],
      "year": 2025,
      "abstract": null,
      "citationCount": 3,
      "doi": "10.1007/s00146-025-02355-1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4de5bf319f9a0acfd049a22e0e409873e08719ab",
      "venue": "Ai & Society",
      "journal": {
        "name": "AI & SOCIETY",
        "pages": "5347 - 5357",
        "volume": "40"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "45c597c10769317d3bd597b92cee33566c065763",
      "title": "Causality in the human niche: lessons for machine learning",
      "authors": [
        {
          "name": "Richard D. Lange",
          "authorId": "2367272031"
        },
        {
          "name": "K. Kording",
          "authorId": "150174214"
        }
      ],
      "year": 2025,
      "abstract": "Humans interpret the world around them in terms of cause and effect and communicate their understanding of the world to each other in causal terms. These causal aspects of human cognition are thought to underlie humans' ability to generalize and learn efficiently in new domains, an area where current machine learning systems are weak. Building human-like causal competency into machine learning systems may facilitate the construction of effective and interpretable AI. Indeed, the machine learning community has been importing ideas on causality formalized by the Structural Causal Model (SCM) framework, which provides a rigorous formal language for many aspects of causality and has led to significant advances. However, the SCM framework fails to capture some salient aspects of human causal cognition and has likewise not yet led to advances in machine learning in certain critical areas where humans excel. We contend that the problem of causality in the ``human niche'' -- for a social, autonomous, and goal-driven agent sensing and acting in the world in which humans live -- is quite different from the kind of causality captured by SCMs. For example, everyday objects come in similar types that have similar causal properties, and so humans readily generalize knowledge of one type of object (cups) to another related type (bowls) by drawing causal analogies between objects with similar properties, but such analogies are at best awkward to express in SCMs. We explore how such causal capabilities are adaptive in, and motivated by, the human niche. By better appreciating properties of human causal cognition and, crucially, how those properties are adaptive in the niche in which humans live, we hope that future work at the intersection of machine learning and causality will leverage more human-like inductive biases to create more capable, controllable, and interpretable systems.",
      "citationCount": 1,
      "doi": "10.48550/arXiv.2506.13803",
      "arxivId": "2506.13803",
      "url": "https://www.semanticscholar.org/paper/45c597c10769317d3bd597b92cee33566c065763",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2506.13803"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "3dd3d416f421e67f6bbe05daca7bf862e8f9fdda",
      "title": "Artificial understanding: a step toward robust AI",
      "authors": [
        {
          "name": "Erez Firt",
          "authorId": "1517659447"
        }
      ],
      "year": 2023,
      "abstract": null,
      "citationCount": 6,
      "doi": "10.1007/s00146-023-01631-2",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/3dd3d416f421e67f6bbe05daca7bf862e8f9fdda",
      "venue": "Ai & Society",
      "journal": {
        "name": "AI & SOCIETY",
        "pages": "1-13",
        "volume": ""
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "15d4f7eccd8b3d9800268a1287656b38a919fa59",
      "title": "From data to decisions: The secret life of machine learning models",
      "authors": [
        {
          "name": "Raghu Chukkala",
          "authorId": "2359058386"
        }
      ],
      "year": 2025,
      "abstract": "This article on machine learning demystifies how algorithms transform data into decisions across diverse applications. Beginning with the fundamentals of how machines learn through supervised and unsupervised approaches, the article illuminates the critical role of features\u2014the clues that enable models to recognize patterns. It examines the inference process where models apply their training to make predictions on new data and contrasts different algorithmic approaches including decision trees, neural networks, and random forests, each with distinct strengths and limitations. The piece addresses the \"black box problem\" of model opacity and the emerging field of explainable AI while showcasing real-world applications beyond familiar consumer technology in healthcare, agriculture, climate science, transportation, and finance. Through accessible analogies and evidence-based analysis, the article provides a clear understanding of machine learning's capabilities and challenges, making this sophisticated technology comprehensible to both technical and non-technical audiences alike, while emphasizing the importance of responsible implementation that considers societal impact.",
      "citationCount": 0,
      "doi": "10.30574/wjarr.2025.26.1.1510",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/15d4f7eccd8b3d9800268a1287656b38a919fa59",
      "venue": "World Journal of Advanced Research and Reviews",
      "journal": {
        "name": "World Journal of Advanced Research and Reviews"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "4d091032d1d28e566802ca9beea1421361b5d03b",
      "title": "Leveraging Ethical Narratives to Enhance LLM\u2010AutoML Generated Machine Learning Models",
      "authors": [
        {
          "name": "Jordan Nelson",
          "authorId": "2330204627"
        },
        {
          "name": "Michalis Pavlidis",
          "authorId": "34667222"
        },
        {
          "name": "Andrew Fish",
          "authorId": "2330029838"
        },
        {
          "name": "Nikolaos Polatidis",
          "authorId": "3045368"
        },
        {
          "name": "Yannis Manolopoulos",
          "authorId": "2182067085"
        }
      ],
      "year": 2025,
      "abstract": "The growing popularity of generative AI and large language models (LLMs) has sparked innovation alongside debate, particularly around issues of plagiarism and intellectual property law. However, a less\u2010discussed concern is the quality of code generated by these models, which often contains errors and encourages poor programming practices. This paper proposes a novel solution by integrating LLMs with automated machine learning (AutoML). By leveraging AutoML's strengths in hyperparameter tuning and model selection, we present a framework for generating robust and reliable machine learning (ML) algorithms. Our approach incorporates natural language processing (NLP) and natural language understanding (NLU) techniques to interpret chatbot prompts, enabling more accurate and customisable ML model generation through AutoML. To ensure ethical AI practices, we have also introduced a filtering mechanism to address potential biases and enhance accountability. The proposed methodology not only demonstrates practical implementation but also achieves high predictive accuracy, offering a viable solution to current challenges in LLM\u2010based code generation. In summary, this paper introduces a new application of NLP and NLU to extract features from chatbot prompts, feeding them into an AutoML system to generate ML algorithms. This approach is framed within a rigorous ethical framework, addressing concerns of bias and accountability while enhancing the reliability of code generation.",
      "citationCount": 0,
      "doi": "10.1111/exsy.70072",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4d091032d1d28e566802ca9beea1421361b5d03b",
      "venue": "Expert Syst. J. Knowl. Eng.",
      "journal": {
        "name": "Expert Systems",
        "volume": "42"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "f21dbd760939709fe0ef90378ba18e58729d31b4",
      "title": "Research Frontiers in Machine Learning & Knowledge Extraction",
      "authors": [
        {
          "name": "Andreas Holzinger",
          "authorId": "2264383273"
        },
        {
          "name": "Luca Longo",
          "authorId": "2393611928"
        },
        {
          "name": "Angelo Cangelosi",
          "authorId": "2238770694"
        },
        {
          "name": "J. Ser",
          "authorId": "9221552"
        }
      ],
      "year": 2025,
      "abstract": "Machine Learning and Knowledge Extraction have evolved from algorithmic tools for pattern recognition into a unifying foundational scientific framework underpinning virtually all of today\u2019s groundbreaking advances, enabling systematic discovery, interpretation and understanding across domains. This paper introduces a comprehensive research agenda that defines currently the future of innovation in Artificial Intelligence. We identify ten interrelated research frontiers that collectively map the transition from data-driven learning to knowledge-centric, trustworthy, and sustainable intelligence. These frontiers span the full spectrum of future AI research: from physics-informed and hybrid architectures that embed causality and domain knowledge, to multimodal and embedded intelligence that ground AI in real-world contexts; from interpretable and responsible design principles that ensure transparency and fairness, to safe and sustainable deployment in open-world environments. Together, these directions delineate a coherent roadmap toward AI systems that not only predict but also explain, reason, and collaborate. Future AI can be seen as a new member of your research lab, an active participant in knowledge creation, driven by interdisciplinary integration, global cooperation, ethical responsibility, and human oversight. By embedding principles of transparency, sustainability, and societal alignment from the outset, we envision AI as both a catalyst for scientific discovery and a cornerstone of responsible technological progress.",
      "citationCount": 0,
      "doi": "10.3390/make8010006",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f21dbd760939709fe0ef90378ba18e58729d31b4",
      "venue": "Machine Learning and Knowledge Extraction",
      "journal": {
        "name": "Machine Learning and Knowledge Extraction"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "6798fef13dcd770388a7f07747e036ed1fb05a23",
      "title": "The Task of the Human-Machine Translator: Scaling Intelligence and Preserving Transcendence.",
      "authors": [
        {
          "name": "Minghui Hu",
          "authorId": "2396666588"
        }
      ],
      "year": 2025,
      "abstract": "Walter Benjamin\u2019s seminal 1923 essay \u00abDie Aufgabe des \u00dcbersetzers\u00bb (The Task of the Translator) provides one of the most profound philosophical frameworks for understanding translation as a transcendent act that reveals the \u00abpure language\u00bb underlying all human expression. In the era of large language models (LLMs) and neural machine translation, Benjamin\u2019s concepts of textual \u00abafterlife\u00bb, linguistic kinship, and the philosophical versus practical divide in translation take on unprecedented urgency. This essay examines how the scaling of intelligence \u2013 from Qwen2.5-32B to 72B parameter models \u2013 simultaneously approaches and reveals the fundamental limitations of computational approaches to translation, particularly in the context of classical Chinese texts. Through analysis of contemporary scaling laws, linguistic challenges specific to classical Chinese, and emerging human-machine collaborative frameworks, this work argues that effective translation in the AI era requires what The Economist termed \u00abcyborg translation\u00bb \u2013 a synergy that preserves human interpretive authority while leveraging machine computational power. The essay demonstrates that while scaling laws show diminishing returns and performance plateaus, the integration of philosophical understanding with technical innovation offers pathways toward translation systems that honor both Benjamin\u2019s transcendent vision and practical computational constraints.",
      "citationCount": 0,
      "doi": "10.54103/2039-9251/30240",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6798fef13dcd770388a7f07747e036ed1fb05a23",
      "venue": "Itinera",
      "journal": {
        "name": "Itinera"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "41070986e9c106037512f1885af7628e2a0d724d",
      "title": "ChatGPT and the Chinese Room Argument: An Eloquent AI Conversationalist Lacking True Understanding and Consciousness",
      "authors": [
        {
          "name": "Oussama H. Hamid",
          "authorId": "3124953"
        }
      ],
      "year": 2023,
      "abstract": "This paper explores the cognitive implications of recent advancements in large language models (LLMs), with a specific focus on ChatGPT. We contribute to the ongoing debate about the cognitive significance of current LLMs by drawing an analogy to the Chinese Room Argument, a thought experiment that questions the genuine understanding of language in machines (computer programs). Our argument posits that current LLMs, including ChatGPT, generate text resembling human-like responses, akin to the process depicted in the Chinese Room Argument. In both cases, the responses are provided without a deep understanding of the language, thus lacking true signs of consciousness.",
      "citationCount": 6,
      "doi": "10.1109/ITT59889.2023.10184233",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/41070986e9c106037512f1885af7628e2a0d724d",
      "venue": "Information Technology Trends",
      "journal": {
        "name": "2023 9th International Conference on Information Technology Trends (ITT)",
        "pages": "238-241"
      },
      "publicationTypes": [
        "Conference"
      ]
    }
  ],
  "count": 40,
  "errors": []
}
