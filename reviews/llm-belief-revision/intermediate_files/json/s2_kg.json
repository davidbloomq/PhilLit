{
  "status": "success",
  "source": "semantic_scholar",
  "query": "knowledge graph reasoning",
  "results": [
    {
      "paperId": "99766aebf4c9d30651b7f656ad256e823a7c940a",
      "title": "Temporal Knowledge Graph Reasoning Based on Evolutional Representation Learning",
      "authors": [
        {
          "name": "Zixuan Li",
          "authorId": "46947005"
        },
        {
          "name": "Xiaolong Jin",
          "authorId": "2149111400"
        },
        {
          "name": "Wei Li",
          "authorId": "48624966"
        },
        {
          "name": "Saiping Guan",
          "authorId": "24749412"
        },
        {
          "name": "Jiafeng Guo",
          "authorId": "70414094"
        },
        {
          "name": "Huawei Shen",
          "authorId": "2476503"
        },
        {
          "name": "Yuanzhuo Wang",
          "authorId": "2219600"
        },
        {
          "name": "Xueqi Cheng",
          "authorId": "1717004"
        }
      ],
      "year": 2021,
      "abstract": "Knowledge Graph (KG) reasoning that predicts missing facts for incomplete KGs has been widely explored. However, reasoning over Temporal KG (TKG) that predicts facts in the future is still far from resolved. The key to predict future facts is to thoroughly understand the historical facts. A TKG is actually a sequence of KGs corresponding to different timestamps, where all concurrent facts in each KG exhibit structural dependencies and temporally adjacent facts carry informative sequential patterns. To capture these properties effectively and efficiently, we propose a novel Recurrent Evolution network based on Graph Convolution Network (GCN), called RE-GCN, which learns the evolutional representations of entities and relations at each timestamp by modeling the KG sequence recurrently. Specifically, for the evolution unit, a relation-aware GCN is leveraged to capture the structural dependencies within the KG at each timestamp. In order to capture the sequential patterns of all facts in parallel, the historical KG sequence is modeled auto-regressively by the gate recurrent components. Moreover, the static properties of entities, such as entity types, are also incorporated via a static graph constraint component to obtain better entity representations. Fact prediction at future timestamps can then be realized based on the evolutional entity and relation representations. Extensive experiments demonstrate that the RE-GCN model obtains substantial performance and efficiency improvement for the temporal reasoning tasks on six benchmark datasets. Especially, it achieves up to 11.46% improvement in MRR for entity prediction with up to 82 times speedup compared to the state-of-the-art baseline.",
      "citationCount": 340,
      "doi": "10.1145/3404835.3462963",
      "arxivId": "2104.10353",
      "url": "https://www.semanticscholar.org/paper/99766aebf4c9d30651b7f656ad256e823a7c940a",
      "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "journal": {
        "name": "Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "9a14989424b16a4685c43ffc8057b40157631dd2",
      "title": "Reinforcement Knowledge Graph Reasoning for Explainable Recommendation",
      "authors": [
        {
          "name": "Yikun Xian",
          "authorId": "2885287"
        },
        {
          "name": "Zuohui Fu",
          "authorId": "2011378"
        },
        {
          "name": "S. Muthukrishnan",
          "authorId": "144963537"
        },
        {
          "name": "Gerard de Melo",
          "authorId": "144608002"
        },
        {
          "name": "Yongfeng Zhang",
          "authorId": "1739818"
        }
      ],
      "year": 2019,
      "abstract": "Recent advances in personalized recommendation have sparked great interest in the exploitation of rich structured information provided by knowledge graphs. Unlike most existing approaches that only focus on leveraging knowledge graphs for more accurate recommendation, we aim to conduct explicit reasoning with knowledge for decision making so that the recommendations are generated and supported by an interpretable causal inference procedure. To this end, we propose a method called Policy-Guided Path Reasoning (PGPR), which couples recommendation and interpretability by providing actual paths in a knowledge graph. Our contributions include four aspects. We first highlight the significance of incorporating knowledge graphs into recommendation to formally define and interpret the reasoning process. Second, we propose a reinforcement learning (RL) approach featured by an innovative soft reward strategy, user-conditional action pruning and a multi-hop scoring function. Third, we design a policy-guided graph search algorithm to efficiently and effectively sample reasoning paths for recommendation. Finally, we extensively evaluate our method on several large-scale real-world benchmark datasets, obtaining favorable results compared with state-of-the-art methods.",
      "citationCount": 523,
      "doi": "10.1145/3331184.3331203",
      "arxivId": "1906.05237",
      "url": "https://www.semanticscholar.org/paper/9a14989424b16a4685c43ffc8057b40157631dd2",
      "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "journal": {
        "name": "Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "e451cd1f8645589f71848eb97948052e07047748",
      "title": "A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multi-Modal",
      "authors": [
        {
          "name": "K. Liang",
          "authorId": "2024445866"
        },
        {
          "name": "Lingyuan Meng",
          "authorId": "13325191"
        },
        {
          "name": "Meng Liu",
          "authorId": "2152969291"
        },
        {
          "name": "Yue Liu",
          "authorId": "2119034129"
        },
        {
          "name": "Wenxuan Tu",
          "authorId": "1381761887"
        },
        {
          "name": "Siwei Wang",
          "authorId": "103307910"
        },
        {
          "name": "Sihang Zhou",
          "authorId": "2516087"
        },
        {
          "name": "Xinwang Liu",
          "authorId": "2130021053"
        },
        {
          "name": "Fu Sun",
          "authorId": "2119233425"
        }
      ],
      "year": 2022,
      "abstract": "Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to significantly benefit the usage of KGs in many AI applications, such as question answering, recommendation systems, and etc. According to the graph types, existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. Early works in this domain mainly focus on static KGR, and recent works try to leverage the temporal and multi-modal information, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the models are reviewed based on bi-level taxonomy, i.e., top-level (graph types) and base-level (techniques and scenarios). Besides, the performances, as well as datasets, are summarized and presented. Moreover, we point out the challenges and potential opportunities to enlighten the readers.",
      "citationCount": 225,
      "doi": "10.1109/TPAMI.2024.3417451",
      "arxivId": "2212.05767",
      "url": "https://www.semanticscholar.org/paper/e451cd1f8645589f71848eb97948052e07047748",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "journal": {
        "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "pages": "9456-9478",
        "volume": "46"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "22157f0bcde877743dc95715cf570d672f76520a",
      "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
      "authors": [
        {
          "name": "Yi Xu",
          "authorId": "2110289458"
        },
        {
          "name": "Junjie Ou",
          "authorId": "6292461"
        },
        {
          "name": "Hui Xu",
          "authorId": "2149189560"
        },
        {
          "name": "Luoyi Fu",
          "authorId": "1922573"
        }
      ],
      "year": 2022,
      "abstract": "Temporal knowledge graph, serving as an effective way to store and model dynamic relations, shows promising prospects in event forecasting. However, most temporal knowledge graph reasoning methods are highly dependent on the recurrence or periodicity of events, which brings challenges to inferring future events related to entities that lack historical interaction. In fact, the current moment is often the combined effect of a small part of historical information and those unobserved underlying factors. To this end, we propose a new event forecasting model called Contrastive Event Network (CENET), based on a novel training framework of historical contrastive learning. CENET learns both the historical and non-historical dependency to distinguish the most potential entities that can best match the given query. Simultaneously, it trains representations of queries to investigate whether the current moment depends more on historical or non-historical events by launching contrastive learning. The representations further help train a binary classifier whose output is a boolean mask to indicate related entities in the search space. During the inference process, CENET employs a mask-based strategy to generate the final results. We evaluate our proposed model on five benchmark graphs. The results demonstrate that CENET significantly outperforms all existing methods in most metrics, achieving at least 8.3% relative improvement of Hits@1 over previous state-of-the-art baselines on event-based datasets.",
      "citationCount": 137,
      "doi": "10.48550/arXiv.2211.10904",
      "arxivId": "2211.10904",
      "url": "https://www.semanticscholar.org/paper/22157f0bcde877743dc95715cf570d672f76520a",
      "venue": "AAAI Conference on Artificial Intelligence",
      "journal": {
        "pages": "4765-4773"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "4362edfd3907204cf1b7ec8e3c16c56db5cd14cf",
      "title": "Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Jiapu Wang",
          "authorId": "2163833353"
        },
        {
          "name": "Kai Sun",
          "authorId": "2220259324"
        },
        {
          "name": "Linhao Luo",
          "authorId": "2238130759"
        },
        {
          "name": "Wei Wei",
          "authorId": "2302892265"
        },
        {
          "name": "Yongli Hu",
          "authorId": "2140879677"
        },
        {
          "name": "Alan Wee-Chung Liew",
          "authorId": "2243282363"
        },
        {
          "name": "Shirui Pan",
          "authorId": "2294378361"
        },
        {
          "name": "Baocai Yin",
          "authorId": "2239088112"
        }
      ],
      "year": 2024,
      "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the process of utilizing temporal information to capture complex relations within a Temporal Knowledge Graph (TKG) to infer new knowledge. Conventional methods in TKGR typically depend on deep learning algorithms or temporal logical rules. However, deep learning-based TKGRs often lack interpretability, whereas rule-based TKGRs struggle to effectively learn temporal rules that capture temporal patterns. Recently, Large Language Models (LLMs) have demonstrated extensive knowledge and remarkable proficiency in temporal reasoning. Consequently, the employment of LLMs for Temporal Knowledge Graph Reasoning (TKGR) has sparked increasing interest among researchers. Nonetheless, LLMs are known to function as black boxes, making it challenging to comprehend their reasoning process. Additionally, due to the resource-intensive nature of fine-tuning, promptly updating LLMs to integrate evolving knowledge within TKGs for reasoning is impractical. To address these challenges, in this paper, we propose a Large Language Models-guided Dynamic Adaptation (LLM-DA) method for reasoning on TKGs. Specifically, LLM-DA harnesses the capabilities of LLMs to analyze historical data and extract temporal logical rules. These rules unveil temporal patterns and facilitate interpretable reasoning. To account for the evolving nature of TKGs, a dynamic adaptation strategy is proposed to update the LLM-generated rules with the latest events. This ensures that the extracted rules always incorporate the most recent knowledge and better generalize to the predictions on future events. Experimental results show that without the need of fine-tuning, LLM-DA significantly improves the accuracy of reasoning over several common datasets, providing a robust framework for TKGR tasks.",
      "citationCount": 33,
      "doi": "10.48550/arXiv.2405.14170",
      "arxivId": "2405.14170",
      "url": "https://www.semanticscholar.org/paper/4362edfd3907204cf1b7ec8e3c16c56db5cd14cf",
      "venue": "Neural Information Processing Systems",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2405.14170"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "b64fb9eb7a9f523ee15e9a1fe4170cc1d8189fc3",
      "title": "Knowledge Graph Reasoning with Relational Digraph",
      "authors": [
        {
          "name": "Yongqi Zhang",
          "authorId": "48379419"
        },
        {
          "name": "Quanming Yao",
          "authorId": "3259992"
        }
      ],
      "year": 2021,
      "abstract": "Reasoning on the knowledge graph (KG) aims to infer new facts from existing ones. Methods based on the relational path have shown strong, interpretable, and transferable reasoning ability. However, paths are naturally limited in capturing local evidence in graphs. In this paper, we introduce a novel relational structure, i.e., relational directed graph (r-digraph), which is composed of overlapped relational paths, to capture the KG\u2019s local evidence. Since the r-digraphs are more complex than paths, how to efficiently construct and effectively learn from them are challenging. Directly encoding the r-digraphs cannot scale well and capturing query-dependent information is hard in r-digraphs. We propose a variant of graph neural network, i.e., RED-GNN, to address the above challenges. Specifically, RED-GNN makes use of dynamic programming to recursively encodes multiple r-digraphs with shared edges, and utilizes query-dependent attention mechanism to select the strongly correlated edges. We demonstrate that RED-GNN is not only efficient but also can achieve significant performance gains in both inductive and transductive reasoning tasks over existing methods. Besides, the learned attention weights in RED-GNN can exhibit interpretable evidence for KG reasoning. 1",
      "citationCount": 167,
      "doi": "10.1145/3485447.3512008",
      "arxivId": "2108.06040",
      "url": "https://www.semanticscholar.org/paper/b64fb9eb7a9f523ee15e9a1fe4170cc1d8189fc3",
      "venue": "The Web Conference",
      "journal": {
        "name": "Proceedings of the ACM Web Conference 2022"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "9b31288d4aba4858dd143646b33b4ad58c3bb6d5",
      "title": "Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Mufan Xu",
          "authorId": "2335823258"
        },
        {
          "name": "Gewen Liang",
          "authorId": "2349259697"
        },
        {
          "name": "Kehai Chen",
          "authorId": "2266796043"
        },
        {
          "name": "Wei Wang",
          "authorId": "2349271722"
        },
        {
          "name": "Xun Zhou",
          "authorId": "2340275838"
        },
        {
          "name": "Muyun Yang",
          "authorId": "2320745836"
        },
        {
          "name": "Tiejun Zhao",
          "authorId": "2237773157"
        },
        {
          "name": "Min Zhang",
          "authorId": "2273887691"
        }
      ],
      "year": 2025,
      "abstract": "Large language models (LLMs) have achieved remarkable performance on knowledge graph question answering (KGQA) tasks by planning and interacting with knowledge graphs. However, existing methods often confuse tool utilization with knowledge reasoning, harming readability of model outputs and giving rise to hallucinatory tool invocations, which hinder the advancement of KGQA. To address this issue, we propose Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning (MemQ) to decouple LLM from tool invocation tasks using LLM-built query memory. By establishing a memory module with explicit descriptions of query statements, the proposed MemQ facilitates the KGQA process with natural language reasoning and memory-augmented query reconstruction. Meanwhile, we design an effective and readable reasoning to enhance the LLM's reasoning capability in KGQA. Experimental results that MemQ achieves state-of-the-art performance on widely used benchmarks WebQSP and CWQ.",
      "citationCount": 5,
      "doi": "10.48550/arXiv.2503.05193",
      "arxivId": "2503.05193",
      "url": "https://www.semanticscholar.org/paper/9b31288d4aba4858dd143646b33b4ad58c3bb6d5",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2503.05193"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "eb1fa5c23dd04690cbfb38e091c2b9dcbe269f18",
      "title": "Towards Foundation Models for Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Mikhail Galkin",
          "authorId": "2066369448"
        },
        {
          "name": "Xinyu Yuan",
          "authorId": "2258299935"
        },
        {
          "name": "Hesham Mostafa",
          "authorId": "2256992354"
        },
        {
          "name": "Jian Tang",
          "authorId": "2255480226"
        },
        {
          "name": "Zhaocheng Zhu",
          "authorId": "9031926"
        }
      ],
      "year": 2023,
      "abstract": "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. Knowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap. The key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies. In this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. ULTRA builds relational representations as a function conditioned on their interactions. Such a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph. Conducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. Fine-tuning further boosts the performance.",
      "citationCount": 78,
      "doi": "10.48550/arXiv.2310.04562",
      "arxivId": "2310.04562",
      "url": "https://www.semanticscholar.org/paper/eb1fa5c23dd04690cbfb38e091c2b9dcbe269f18",
      "venue": "International Conference on Learning Representations",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2310.04562"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "d162b7e09bf16cd9aa0b7b5304938f49a6b9e6de",
      "title": "Multi-Hop Knowledge Graph Reasoning in Few-Shot Scenarios",
      "authors": [
        {
          "name": "Shangfei Zheng",
          "authorId": "1384404569"
        },
        {
          "name": "Wei Chen",
          "authorId": "2154939288"
        },
        {
          "name": "Weiqing Wang",
          "authorId": "2109080349"
        },
        {
          "name": "Pengpeng Zhao",
          "authorId": "2927967"
        },
        {
          "name": "Hongzhi Yin",
          "authorId": "2416851"
        },
        {
          "name": "Lei Zhao",
          "authorId": "98756666"
        }
      ],
      "year": 2024,
      "abstract": "Reinforcement learning (RL)-based multi-hop reasoning has become an interpretable way for knowledge graph reasoning owing to its persuasive explanations for the predicted results, but the reasoning performance of these methods drops significantly over few-shot relations (only contain few triplets). To address this problem, recent studies introduce meta-learning into RL-based reasoning methods. However, the performance of these studies is still limited due to the following points: (1) the overall reasoning accuracy is impaired due to the low reasoning accuracies over some hard relations; (2) the reasoning process becomes laborious and ineffective owing to the existence of noisy data; (3) the generalizability is negatively affected due to the lack of knowledge-sharing. To tackle these challenges, we propose a novel model HMLS consisting of two modules HHML (Hierarchical Hardness-aware Meta-reinforcement Learning) and HHS (Hierarchical Hardness-aware Sampling). Specifically, HHML contains the following two components: (1) a hardness-aware RL conducts multi-hop reasoning by training hardness-aware batches and reducing noise; (2) a knowledge-sharing meta-learning adapts to few-shot relations by exploiting common features in the hierarchical relation structure. The other module HHS generates hardness-aware batches from relation and relation-cluster levels. The experimental results demonstrate that this work notably outperforms the state-of-the-art approaches in few-shot scenarios.",
      "citationCount": 21,
      "doi": "10.1109/TKDE.2023.3304665",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/d162b7e09bf16cd9aa0b7b5304938f49a6b9e6de",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "journal": {
        "name": "IEEE Transactions on Knowledge and Data Engineering",
        "pages": "1713-1727",
        "volume": "36"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "7b64ef6f5fa018a39df8597f2c853747b81706e3",
      "title": "Enhancing Multi-Hop Knowledge Graph Reasoning through Reward Shaping Techniques",
      "authors": [
        {
          "name": "Chen Li",
          "authorId": "2290858477"
        },
        {
          "name": "Haotian Zheng",
          "authorId": "2290719494"
        },
        {
          "name": "Yiping Sun",
          "authorId": "2291003534"
        },
        {
          "name": "Cangqing Wang",
          "authorId": "2290869608"
        },
        {
          "name": "Liqiang Yu",
          "authorId": "2269702502"
        },
        {
          "name": "Che Chang",
          "authorId": "2290879535"
        },
        {
          "name": "Xinyu Tian",
          "authorId": "2291015534"
        },
        {
          "name": "Bo Liu",
          "authorId": "2291016110"
        }
      ],
      "year": 2024,
      "abstract": "In the realm of computational knowledge representation, Knowledge Graph Reasoning (KG-R) stands at the fore-front of facilitating sophisticated inferential capabilities across multifarious domains. The quintessence of this research elucidates the employment of reinforcement learning (RL) strategies, notably the REINFORCE algorithm, to navigate the intricacies inherent in multi-hop KG-R. This investigation critically addresses the prevalent challenges introduced by the inherent incompleteness of Knowledge Graphs (KGs), which frequently results in erroneous inferential outcomes, manifesting as both false negatives and misleading positives. By partitioning the Unified Medical Language System (UMLS) benchmark dataset into rich and sparse subsets, we investigate the efficacy of pretrained BERT embeddings and Prompt Learning methodologies to refine the reward shaping process. This approach not only enhances the precision of multi-hop KG-R but also sets a new precedent for future research in the field, aiming to improve the robustness and accuracy of knowledge inference within complex KG frameworks. Our work contributes a novel perspective to the discourse on KG reasoning, offering a methodological advancement that aligns with the academic rigor and scholarly aspirations of the Natural journal, promising to invigorate further advancements in the realm of computational knowledge representation.",
      "citationCount": 22,
      "doi": "10.1109/MLISE62164.2024.10674566",
      "arxivId": "2403.05801",
      "url": "https://www.semanticscholar.org/paper/7b64ef6f5fa018a39df8597f2c853747b81706e3",
      "venue": "2024 4th International Conference on Machine Learning and Intelligent Systems Engineering (MLISE)",
      "journal": {
        "name": "2024 4th International Conference on Machine Learning and Intelligent Systems Engineering (MLISE)",
        "pages": "1-5"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "fe4c802b1af7da02aaee7a2bd8deb97bff0de6d7",
      "title": "TiRGN: Time-Guided Recurrent Graph Network with Local-Global Historical Patterns for Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Yujia Li",
          "authorId": "2177254692"
        },
        {
          "name": "Shiliang Sun",
          "authorId": "20632291"
        },
        {
          "name": "Jing Zhao",
          "authorId": "46509200"
        }
      ],
      "year": 2022,
      "abstract": "Temporal knowledge graphs (TKGs) have been widely used in various fields that model the dynamics of facts along the timeline. In the extrapolation setting of TKG reasoning, since facts happening in the future are entirely unknowable, insight into history is the key to predicting future facts. However, it is still a great challenge for existing models as they hardly learn the characteristics of historical events adequately. From the perspective of historical development laws, comprehensively considering the sequential, repetitive, and cyclical patterns of historical facts is conducive to predicting future facts. To this end, we propose a novel representation learning model for TKG reasoning, namely TiRGN, a time-guided recurrent graph network with local-global historical patterns. Specifically, TiRGN uses a local recurrent graph encoder network to model the historical dependency of events at adjacent timestamps and uses the global history encoder network to collect repeated historical facts. After the trade-off between the two encoders, the final inference is performed by a decoder with periodicity. We use six benchmark datasets to evaluate the proposed method. The experimental results show that TiRGN outperforms the state-of-the-art TKG reasoning methods in most cases.",
      "citationCount": 102,
      "doi": "10.24963/ijcai.2022/299",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/fe4c802b1af7da02aaee7a2bd8deb97bff0de6d7",
      "venue": "International Joint Conference on Artificial Intelligence",
      "journal": {
        "pages": "2152-2158"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "7a941148d8c5865749801b2f9f67f9ad1fba1d25",
      "title": "Multi-Hop Knowledge Graph Reasoning with Reward Shaping",
      "authors": [
        {
          "name": "Xi Victoria Lin",
          "authorId": "143724481"
        },
        {
          "name": "R. Socher",
          "authorId": "2166511"
        },
        {
          "name": "Caiming Xiong",
          "authorId": "2228109"
        }
      ],
      "year": 2018,
      "abstract": "Multi-hop reasoning is an effective approach for query answering (QA) over incomplete knowledge graphs (KGs). The problem can be formulated in a reinforcement learning (RL) setup, where a policy-based agent sequentially extends its inference path until it reaches a target. However, in an incomplete KG environment, the agent receives low-quality rewards corrupted by false negatives in the training data, which harms generalization at test time. Furthermore, since no golden action sequence is used for training, the agent can be misled by spurious search trajectories that incidentally lead to the correct answer. We propose two modeling advances to address both issues: (1) we reduce the impact of false negative supervision by adopting a pretrained one-hop embedding model to estimate the reward of unobserved facts; (2) we counter the sensitivity to spurious paths of on-policy RL by forcing the agent to explore a diverse set of paths using randomly generated edge masks. Our approach significantly improves over existing path-based KGQA models on several benchmark datasets and is comparable or better than embedding-based models.",
      "citationCount": 370,
      "doi": "10.18653/v1/D18-1362",
      "arxivId": "1808.10568",
      "url": "https://www.semanticscholar.org/paper/7a941148d8c5865749801b2f9f67f9ad1fba1d25",
      "venue": "Conference on Empirical Methods in Natural Language Processing",
      "journal": {
        "pages": "3243-3253"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "b84a9730b1833e6a901e14ed1093190f83257b81",
      "title": "Towards knowledge graph reasoning for supply chain risk management using graph neural networks",
      "authors": [
        {
          "name": "E. Kosasih",
          "authorId": "2082947331"
        },
        {
          "name": "F. Margaroli",
          "authorId": "4716414"
        },
        {
          "name": "S. Gelli",
          "authorId": "47730444"
        },
        {
          "name": "Ajmal Aziz",
          "authorId": "153220690"
        },
        {
          "name": "N. Wildgoose",
          "authorId": "14721990"
        },
        {
          "name": "A. Brintrup",
          "authorId": "3385621"
        }
      ],
      "year": 2022,
      "abstract": "Modern supply chains are complex, interconnected systems that contain emergent, invisible dependencies. Lack of visibility often hinders effective risk planning and results in delayed discovery of supply chain problems, with examples ranging from product contamination, unsustainable production practices, or exposure to suppliers clustered in geographical areas prone to natural or man-made disasters. Initiatives that rely on manual collection of data often fail due to supply chain complexity and unwillingness of suppliers to share data. In this paper, we propose a neurosymbolic machine learning technique to proactively uncover hidden risks in supply chains and discover new information. Our method uses a combination of graph neural networks and knowledge graph reasoning. Unlike existing research our model is able to infer multiple types of hidden relationship risks, presenting a step change in automated supply chain surveillance. The approach has been tested on two empirical datasets from the automotive and energy industries, illustrating that it can provide inference in multiple types of links such as companies, products, production capabilities, certifications; thereby facilitating complex queries that go beyond who-supplies-whom. As such, additional risk insights can emerge from graph structure, providing practitioners with new knowledge.",
      "citationCount": 91,
      "doi": "10.1080/00207543.2022.2100841",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/b84a9730b1833e6a901e14ed1093190f83257b81",
      "venue": "International Journal of Production Research",
      "journal": {
        "name": "International Journal of Production Research",
        "pages": "5596 - 5612",
        "volume": "62"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "77822354c3ff9981bc6d8eddbd6e903d1ff306b4",
      "title": "Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Zixuan Li",
          "authorId": "46947005"
        },
        {
          "name": "Saiping Guan",
          "authorId": "24749412"
        },
        {
          "name": "Xiaolong Jin",
          "authorId": "2149111400"
        },
        {
          "name": "W. Peng",
          "authorId": "2067858672"
        },
        {
          "name": "Yajuan Lyu",
          "authorId": "8020700"
        },
        {
          "name": "Yong Zhu",
          "authorId": "2116512598"
        },
        {
          "name": "Long Bai",
          "authorId": "2075398318"
        },
        {
          "name": "Wei Li",
          "authorId": "48624966"
        },
        {
          "name": "J. Guo",
          "authorId": "1777025"
        },
        {
          "name": "Xueqi Cheng",
          "authorId": "1717004"
        }
      ],
      "year": 2022,
      "abstract": "A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to different timestamps. TKG reasoning aims to predict potential facts in the future given the historical KG sequences. One key of this task is to mine and understand evolutional patterns of facts from these sequences. The evolutional patterns are complex in two aspects, length-diversity and time-variability. Existing models for TKG reasoning focus on modeling fact sequences of a fixed length, which cannot discover complex evolutional patterns that vary in length. Furthermore, these models are all trained offline, which cannot well adapt to the changes of evolutional patterns from then on. Thus, we propose a new model, called Complex Evolutional Network (CEN), which uses a length-aware Convolutional Neural Network (CNN) to handle evolutional patterns of different lengths via an easy-to-difficult curriculum learning strategy. Besides, we propose to learn the model under the online setting so that it can adapt to the changes of evolutional patterns over time. Extensive experiments demonstrate that CEN obtains substantial performance improvement under both the traditional offline and the proposed online settings.",
      "citationCount": 103,
      "doi": "10.48550/arXiv.2203.07782",
      "arxivId": "2203.07782",
      "url": "https://www.semanticscholar.org/paper/77822354c3ff9981bc6d8eddbd6e903d1ff306b4",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2203.07782"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "9582be5f1876036e3760f805f2db7f19220831de",
      "title": "Simple Yet Effective: Structure Guided Pre-trained Transformer for Multi-modal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "K. Liang",
          "authorId": "2024445866"
        },
        {
          "name": "Lingyuan Meng",
          "authorId": "13325191"
        },
        {
          "name": "Yueping Liu",
          "authorId": "2306234554"
        },
        {
          "name": "Meng Liu",
          "authorId": "2293946144"
        },
        {
          "name": "Wei Wei",
          "authorId": "2328123885"
        },
        {
          "name": "Suyuan Liu",
          "authorId": "2237601711"
        },
        {
          "name": "Wenxuan Tu",
          "authorId": "1381761887"
        },
        {
          "name": "Siwei Wang",
          "authorId": "2257357309"
        },
        {
          "name": "Sihang Zhou",
          "authorId": "2516087"
        },
        {
          "name": "Xinwang Liu",
          "authorId": "2261062346"
        }
      ],
      "year": 2024,
      "abstract": "Various information in different modalities in an intuitive way in multi-modal knowledge graphs (MKGs), which are utilized in different downstream tasks, like recommendation. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial intelligence, pre-trained transformers have drawn increasing attention, especially in multi-modal scenarios. However, the research of multi-modal pre-trained transformers (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multi-modal data, the rich structural information underlying the MKG is still not fully utilized in previous MPT. Most of them only use the graph structure as a retrieval map for matching images and texts connected with the same entity, which hinders their reasoning performances. To this end, the graph Structure Guided Multi-modal Pre-trained Transformer is proposed for knowledge graph reasoning (SGMPT). Specifically, the graph structure encoder is adopted for structural feature encoding. Then, a structure-guided fusion module with two simple yet effective strategies, i.e., weighted summation and alignment constraint, is designed to inject the structural information into both the textual and visual features. To the best of our knowledge, SGMPT is the first MPT for multi-modal KGR, which mines structural information underlying MKGs. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that our SGMPT outperforms existing state-of-the-art models, and proves the effectiveness of the designed strategies.",
      "citationCount": 17,
      "doi": "10.1145/3664647.3681112",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/9582be5f1876036e3760f805f2db7f19220831de",
      "venue": "ACM Multimedia",
      "journal": {
        "name": "Proceedings of the 32nd ACM International Conference on Multimedia"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book"
      ]
    },
    {
      "paperId": "8b874d6d1e86567128b4b7623f7e59bbbfe8bf22",
      "title": "Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Wen Zhang",
          "authorId": "49039960"
        },
        {
          "name": "B. Paudel",
          "authorId": "2380612"
        },
        {
          "name": "Liang Wang",
          "authorId": "2155131551"
        },
        {
          "name": "Jiaoyan Chen",
          "authorId": "1731892"
        },
        {
          "name": "Hai Zhu",
          "authorId": "2115315561"
        },
        {
          "name": "Wei Zhang",
          "authorId": null
        },
        {
          "name": "A. Bernstein",
          "authorId": "145704191"
        },
        {
          "name": "Huajun Chen",
          "authorId": "49178307"
        }
      ],
      "year": 2019,
      "abstract": "Reasoning is essential for the development of large knowledge graphs, especially for completion, which aims to infer new triples based on existing ones. Both rules and embeddings can be used for knowledge graph reasoning and they have their own advantages and difficulties. Rule-based reasoning is accurate and explainable but rule learning with searching over the graph always suffers from efficiency due to huge search space. Embedding-based reasoning is more scalable and efficient as the reasoning is conducted via computation between embeddings, but it has difficulty learning good representations for sparse entities because a good embedding relies heavily on data richness. Based on this observation, in this paper we explore how embedding and rule learning can be combined together and complement each other's difficulties with their advantages. We propose a novel framework IterE iteratively learning embeddings and rules, in which rules are learned from embeddings with proper pruning strategy and embeddings are learned from existing triples and new triples inferred by rules. Evaluations on embedding qualities of IterE show that rules help improve the quality of sparse entity embeddings and their link prediction results. We also evaluate the efficiency of rule learning and quality of rules from IterE compared with AMIE+, showing that IterE is capable of generating high quality rules more efficiently. Experiments show that iteratively learning embeddings and rules benefit each other during learning and prediction.",
      "citationCount": 212,
      "doi": "10.1145/3308558.3313612",
      "arxivId": "1903.08948",
      "url": "https://www.semanticscholar.org/paper/8b874d6d1e86567128b4b7623f7e59bbbfe8bf22",
      "venue": "The Web Conference",
      "journal": {
        "name": "The World Wide Web Conference"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "776326c4f324f67ca7c61515d4508563efa05f3c",
      "title": "Learn from Relational Correlations and Periodic Events for Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "K. Liang",
          "authorId": "2024445866"
        },
        {
          "name": "Lingyuan Meng",
          "authorId": "13325191"
        },
        {
          "name": "Meng Liu",
          "authorId": "2152969291"
        },
        {
          "name": "Yue Liu",
          "authorId": "2119034129"
        },
        {
          "name": "Wenxuan Tu",
          "authorId": "1381761887"
        },
        {
          "name": "Siwei Wang",
          "authorId": "103307910"
        },
        {
          "name": "Sihang Zhou",
          "authorId": "2516087"
        },
        {
          "name": "Xinwang Liu",
          "authorId": "2130021053"
        }
      ],
      "year": 2023,
      "abstract": "Reasoning on temporal knowledge graphs (TKGR), aiming to infer missing events along the timeline, has been widely studied to alleviate incompleteness issues in TKG, which is composed of a series of KG snapshots at different timestamps. Two types of information, i.e., intra-snapshot structural information and inter-snapshot temporal interactions, mainly contribute to the learned representations for reasoning in previous models. However, these models fail to leverage (1) semantic correlations between relationships for the former information and (2) the periodic temporal patterns along the timeline for the latter one. Thus, such insufficient mining manners hinder expressive ability, leading to sub-optimal performances. To address these limitations, we propose a novel reasoning model, termed RPC, which sufficiently mines the information underlying the Relational correlations and Periodic patterns via two novel Correspondence units, i.e., relational correspondence unit (RCU) and periodic correspondence unit (PCU). Concretely, relational graph convolutional network (RGCN) and RCU are used to encode the intra-snapshot graph structural information for entities and relations, respectively. Besides, the gated recurrent units (GRU) and PCU are designed for sequential and periodic inter-snapshot temporal interactions, separately. Moreover, the model-agnostic time vectors are generated by time2vector encoders to guide the time-dependent decoder for fact scoring. Extensive experiments on six benchmark datasets show that RPC outperforms the state-of-the-art TKGR models, and also demonstrate the effectiveness of two novel strategies in our model.",
      "citationCount": 89,
      "doi": "10.1145/3539618.3591711",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/776326c4f324f67ca7c61515d4508563efa05f3c",
      "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
      "journal": {
        "name": "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "427e9e98ac83b32bae0b2ddc4eaeb56b454820f9",
      "title": "Knowledge graph reasoning for cyber attack detection",
      "authors": [
        {
          "name": "E. Gilliard",
          "authorId": "112878619"
        },
        {
          "name": "Jinshuo Liu",
          "authorId": "2244572727"
        },
        {
          "name": "Ahmed Abubakar Aliyu",
          "authorId": "2244541026"
        }
      ],
      "year": 2024,
      "abstract": "In today's digital landscape, cybercriminals are constantly evolving their tactics, making it challenging for traditional cybersecurity methods to keep up. To address this issue, this study explores the potential of knowledge graph reasoning as a more adaptable and sophisticated approach to identify and counter network attacks. By leveraging graph structures imbued with human\u2010like thinking, this method enhances the resilience of cybersecurity systems. The study focuses on three critical aspects: data preparation, semantic foundations, and knowledge graph inference techniques. Through an in\u2010depth analysis of these components, the research aims to reveal how knowledge graph reasoning can improve cyberattack detection and enhance the overall efficacy of cybersecurity measures, including intrusion detection systems. The proposed approach has undergone extensive experimentation to validate its effectiveness compared to existing methods. The results of the experiment have shown a remarkable advancement in accuracy, speed, and recall for recognition, surpassing current methods. This achievement is a notable contribution in the realm of managing big data in cybersecurity. The study establishes a foundation for the automation of network attack detection, ultimately enhancing overall network\u00a0security.",
      "citationCount": 12,
      "doi": "10.1049/cmu2.12736",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/427e9e98ac83b32bae0b2ddc4eaeb56b454820f9",
      "venue": "IET Communications",
      "journal": {
        "name": "IET Commun.",
        "pages": "297-308",
        "volume": "18"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2779b025ae0d7be6003d0aaf814f7e812575f925",
      "title": "Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective",
      "authors": [
        {
          "name": "Bo Ni",
          "authorId": "2303464225"
        },
        {
          "name": "Yu Wang",
          "authorId": "2284900701"
        },
        {
          "name": "Lu Cheng",
          "authorId": "2309204674"
        },
        {
          "name": "Erik Blasch",
          "authorId": "2325727308"
        },
        {
          "name": "Tyler Derr",
          "authorId": "2067148039"
        }
      ],
      "year": 2024,
      "abstract": "Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, e.g., KG-based retrieval-augmented framework. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in applications where the cost of errors is significant. Directly incorporating uncertainty quantification into KG-LLM frameworks presents a challenge due to their more complex architectures and the intricate interactions between the knowledge graph and language model components. To address this crucial gap, we propose a new trustworthy KG-LLM framework, UAG (Uncertainty Aware Knowledge-Graph Reasoning), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Extensive experiments show that UAG can achieve any pre-defined coverage rate while reducing the prediction set/interval size by 40% on average over the baselines.",
      "citationCount": 10,
      "doi": "10.48550/arXiv.2410.08985",
      "arxivId": "2410.08985",
      "url": "https://www.semanticscholar.org/paper/2779b025ae0d7be6003d0aaf814f7e812575f925",
      "venue": "AAAI Conference on Artificial Intelligence",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2410.08985"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "005f33acbc9054dfe35a438260124fb9c0f5553d",
      "title": "FedEAN: Entity-Aware Adversarial Negative Sampling for Federated Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Lingyuan Meng",
          "authorId": "13325191"
        },
        {
          "name": "K. Liang",
          "authorId": "2024445866"
        },
        {
          "name": "Hao Yu",
          "authorId": "2110750027"
        },
        {
          "name": "Yue Liu",
          "authorId": "2283355518"
        },
        {
          "name": "Sihang Zhou",
          "authorId": "2516087"
        },
        {
          "name": "Meng Liu",
          "authorId": "2293946144"
        },
        {
          "name": "Xinwang Liu",
          "authorId": "2279159599"
        }
      ],
      "year": 2024,
      "abstract": "Federated knowledge graph reasoning (FedKGR) aims to perform reasoning over different clients while protecting data privacy, drawing increasing attention to its high practical value. Previous works primarily focus on data heterogeneity, ignoring challenges from limited data scale and primitive negative sample strategies, i.e., random entity replacement, which yield low-quality negatives and zero loss issues. Meanwhile, generative adversarial networks (GANs) are widely used in different fields to generate high-quality negative samples, but no work has been developed for FedKGR. To this end, we propose a plug-and-play Entity-aware Adversarial Negative sampling strategy for FedKGR, termed FedEAN. Specifically, we are the first to adopt GANs to generate high-quality negative samples in different clients. It takes the target triplet in each batch as input and outputs high-quality negative samples, which guaranteed by the joint training of the generator and discriminator. Moreover, we design an entity-aware adaptive negative sampling mechanism based on the similarity of entity representations before and after server aggregation, which can persevere the entity global consistency across clients during training. Extensive experiments demonstrate that FedEAN excels with various FedKGR backbones, demonstrating its ability to construct high-quality negative samples and address the zero-loss issue.",
      "citationCount": 10,
      "doi": "10.1109/TKDE.2024.3464516",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/005f33acbc9054dfe35a438260124fb9c0f5553d",
      "venue": "IEEE Transactions on Knowledge and Data Engineering",
      "journal": {
        "name": "IEEE Transactions on Knowledge and Data Engineering",
        "pages": "8206-8219",
        "volume": "36"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "c5523327cdd075898578529a93045445989e0d34",
      "title": "Neural-Symbolic Methods for Knowledge Graph Reasoning: A Survey",
      "authors": [
        {
          "name": "Kewei Cheng",
          "authorId": "2260755600"
        },
        {
          "name": "Nesreen K. Ahmed",
          "authorId": "144741751"
        },
        {
          "name": "R. Rossi",
          "authorId": "2176092943"
        },
        {
          "name": "T. Willke",
          "authorId": "2268234685"
        },
        {
          "name": "Yizhou Sun",
          "authorId": "2311128604"
        }
      ],
      "year": 2024,
      "abstract": "Neural symbolic knowledge graph (KG) reasoning offers a promising approach that combines the expressive power of symbolic reasoning with the learning capabilities inherent in neural networks. This survey provides a comprehensive overview of advancements, techniques, and challenges in the field of neural symbolic KG reasoning. The survey introduces the fundamental concepts of KGs and symbolic logic, followed by an exploration of three significant KG reasoning tasks: KG completion, complex query answering, and logical rule learning. For each task, we thoroughly discuss three distinct categories of methods: pure symbolic methods, pure neural approaches, and the integration of neural networks and symbolic reasoning methods known as neural-symbolic. We carefully analyze and compare the strengths and limitations of each category of methods to provide a comprehensive understanding. By synthesizing recent research contributions and identifying open research directions, this survey aims to equip researchers and practitioners with a comprehensive understanding of the state-of-the-art in neural symbolic KG reasoning, fostering future advancements in this interdisciplinary domain.",
      "citationCount": 18,
      "doi": "10.1145/3686806",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/c5523327cdd075898578529a93045445989e0d34",
      "venue": "ACM Transactions on Knowledge Discovery from Data",
      "journal": {
        "name": "ACM Transactions on Knowledge Discovery from Data",
        "pages": "1 - 44",
        "volume": "18"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "3b57df4285498b57d3703107895908d3b76e784f",
      "title": "Learning Long- and Short-term Representations for Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Mengqi Zhang",
          "authorId": "48985110"
        },
        {
          "name": "Yuwei Xia",
          "authorId": "1625825549"
        },
        {
          "name": "Q. Liu",
          "authorId": "48873756"
        },
        {
          "name": "Shu Wu",
          "authorId": "50425438"
        },
        {
          "name": "Liang Wang",
          "authorId": "1693997"
        }
      ],
      "year": 2023,
      "abstract": "Temporal Knowledge graph (TKG) reasoning aims to predict missing facts based on historical TKG data. Most of the existing methods are incapable of explicitly modeling the long-term time dependencies from history and neglect the adaptive integration of the long- and short-term information. To tackle these problems, we propose a novel method that utilizes a designed Hierarchical Relational Graph Neural Network to learn the Long- and Short-term representations for TKG reasoning, namely HGLS. Specifically, to explicitly associate entities in different timestamps, we first transform the TKG into a global graph. Based on the built graph, we design a Hierarchical Relational Graph Neural Network that executes in two levels: The sub-graph level is to capture the semantic dependencies within concurrent facts of each KG. And the global-graph level aims to model the temporal dependencies between entities. Furthermore, we design a module to extract the long- and short-term information from the output of these two levels. Finally, the long- and short-term representations are fused into a unified one by Gating Integration for entity prediction. Extensive experiments on four datasets demonstrate the effectiveness of HGLS.",
      "citationCount": 65,
      "doi": "10.1145/3543507.3583242",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/3b57df4285498b57d3703107895908d3b76e784f",
      "venue": "The Web Conference",
      "journal": {
        "name": "Proceedings of the ACM Web Conference 2023"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "ab7293b4a3b492a003f13c813d348e9c228a472f",
      "title": "Learning Dynamic and Static Representations for Extrapolation-Based Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Pengfei Li",
          "authorId": "2327646052"
        },
        {
          "name": "Guangyou Zhou",
          "authorId": "2312182214"
        },
        {
          "name": "Zhiwen Xie",
          "authorId": "3408236"
        },
        {
          "name": "Penghui Xie",
          "authorId": "2327396335"
        },
        {
          "name": "J. Huang",
          "authorId": "2249204838"
        }
      ],
      "year": 2024,
      "abstract": "Temporal knowledge graph reasoning aims to predict the missing links (facts) in the future timestamps. However, most existing methods have a common limitation: they focus on learning dynamic representations of temporal knowledge graphs and rarely consider static characteristics that remain unchanged over time. To address the above issues, we propose to learn the dynamic and static representations for temporal knowledge graph reasoning (DSTKG), which introduces two latent variables to capture the dynamic and static characteristics of entities in temporal knowledge graphs. First, we use a Bi-GRU-based inference network to learn the static latent representation of historical facts and a nonlinear discrete-time transition-based inference network to learn the dynamic latent representation. Then, we sample the latent variables multiple times using re-parameterization tricks to obtain high-quality embeddings and make predictions in the future timestamps. The empirical results on four benchmark datasets show that our model is more effective than state-of-the-art approaches. Compared with the strong baseline model DBKGE (RotatE), the proposed model achieves performance improvements of 2.69%, $1.59\\%$, 1.18% and 1.22% on Yago11k, Wikidata12k, ICEWS14 and ICEWS05-15 respectively, regarding the evaluation metric MRR.",
      "citationCount": 6,
      "doi": "10.1109/TASLP.2024.3485500",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/ab7293b4a3b492a003f13c813d348e9c228a472f",
      "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing",
      "journal": {
        "name": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
        "pages": "4741-4754",
        "volume": "32"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "886fc70a609212fe0e58b50b87c6ef40875c35ad",
      "title": "KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "J. Liu",
          "authorId": "40478976"
        },
        {
          "name": "Qianren Mao",
          "authorId": "67081502"
        },
        {
          "name": "Weifeng Jiang",
          "authorId": "1720821940"
        },
        {
          "name": "Jianxin Li",
          "authorId": "2260198301"
        }
      ],
      "year": 2024,
      "abstract": "Knowledge graph reasoning plays a vital role in various applications and has garnered considerable attention. Recently, path-based methods have achieved impressive performance. However, they may face limitations stemming from constraints in message-passing neural networks, such as missing paths and information over-squashing. In this paper, we revisit the application of transformers for knowledge graph reasoning to address the constraints faced by path-based methods and propose a novel method KnowFormer. KnowFormer utilizes a transformer architecture to perform reasoning on knowledge graphs from the message-passing perspective, rather than reasoning by textual information like previous pretrained language model based methods. Specifically, we define the attention computation based on the query prototype of knowledge graph reasoning, facilitating convenient construction and efficient optimization. To incorporate structural information into the self-attention mechanism, we introduce structure-aware modules to calculate query, key, and value respectively. Additionally, we present an efficient attention computation method for better scalability. Experimental results demonstrate the superior performance of KnowFormer compared to prominent baseline methods on both transductive and inductive benchmarks.",
      "citationCount": 5,
      "doi": "10.48550/arXiv.2409.12865",
      "arxivId": "2409.12865",
      "url": "https://www.semanticscholar.org/paper/886fc70a609212fe0e58b50b87c6ef40875c35ad",
      "venue": "International Conference on Machine Learning",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2409.12865"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "0cffe0a56e6505106932a13dfde869725f810b18",
      "title": "New Frontiers of Knowledge Graph Reasoning: Recent Advances and Future Trends",
      "authors": [
        {
          "name": "Lihui Liu",
          "authorId": "1505803281"
        },
        {
          "name": "Zihao Wang",
          "authorId": "2117421814"
        },
        {
          "name": "Jiaxin Bai",
          "authorId": "145677395"
        },
        {
          "name": "Yangqiu Song",
          "authorId": "2275626612"
        },
        {
          "name": "Hanghang Tong",
          "authorId": "2254262311"
        }
      ],
      "year": 2024,
      "abstract": "Knowledge graph reasoning plays an important role in data mining, AI, Web, and social science. These knowledge graphs serve as intuitive repositories of human knowledge, allowing for the inference of new information. However, traditional symbolic reasoning, while powerful in its own right, faces challenges posed by incomplete and noisy data in the knowledge graphs. In contrast, recent years have witnessed the emergence of Neural Symbolic AI, an exciting development that fuses the capabilities of deep learning and symbolic reasoning. It aims to create AI systems that are not only highly interpretable and explainable but also incredibly versatile, effectively bridging the gap between symbolic and neural approaches. Furthermore, with the advent of large language models, the integration of LLMs with knowledge graph reasoning has emerged as a prominent frontier, offering the potential to unlock unprecedented capabilities. This tutorial aims to comprehensively review different aspects of knowledge graph reasoning applications and also introduce the recent advances about Neural Symbolic reasoning and combining knowledge graph reasoning with large language models. It is intended to benefit researchers and practitioners in the fields of data mining, AI, Web, and social science.",
      "citationCount": 5,
      "doi": "10.1145/3589335.3641254",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/0cffe0a56e6505106932a13dfde869725f810b18",
      "venue": "The Web Conference",
      "journal": {
        "name": "Companion Proceedings of the ACM Web Conference 2024"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference",
        "Review"
      ]
    },
    {
      "paperId": "9f12a8726377b7b67880822c7996090859d67437",
      "title": "Knowledge Graph Reasoning over Entities and Numerical Values",
      "authors": [
        {
          "name": "Jiaxin Bai",
          "authorId": "145677395"
        },
        {
          "name": "Cheng-hsin Luo",
          "authorId": "143884453"
        },
        {
          "name": "Zheng Li",
          "authorId": "2146249169"
        },
        {
          "name": "Qingyu Yin",
          "authorId": "3393799"
        },
        {
          "name": "Bing Yin",
          "authorId": "2021632793"
        },
        {
          "name": "Yangqiu Song",
          "authorId": "1809614"
        }
      ],
      "year": 2023,
      "abstract": "A complex logic query in a knowledge graph refers to a query expressed in logic form that conveys a complex meaning, such as where did the Canadian Turing award winner graduate from? Knowledge graph reasoning-based applications, such as dialogue systems and interactive search engines, rely on the ability to answer complex logic queries as a fundamental task. In most knowledge graphs, edges are typically used to either describe the relationships between entities or their associated attribute values. An attribute value can be in categorical or numerical format, such as dates, years, sizes, etc. However, existing complex query answering (CQA) methods simply treat numerical values in the same way as they treat entities. This can lead to difficulties in answering certain queries, such as which Australian Pulitzer award winner is born before 1927, and which drug is a pain reliever and has fewer side effects than Paracetamol. In this work, inspired by the recent advances in numerical encoding and knowledge graph reasoning, we propose numerical complex query answering. In this task, we introduce new numerical variables and operations to describe queries involving numerical attribute values. To address the difference between entities and numerical values, we also propose the framework of Number Reasoning Network (NRN) for alternatively encoding entities and numerical values into separate encoding structures. During the numerical encoding process, NRN employs a parameterized density function to encode the distribution of numerical values. During the entity encoding process, NRN uses established query encoding methods for the original CQA problem. Experimental results show that NRN consistently improves various query encoding methods on three different knowledge graphs and achieves state-of-the-art results.",
      "citationCount": 22,
      "doi": "10.1145/3580305.3599399",
      "arxivId": "2306.01399",
      "url": "https://www.semanticscholar.org/paper/9f12a8726377b7b67880822c7996090859d67437",
      "venue": "Knowledge Discovery and Data Mining",
      "journal": {
        "name": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "c47686aa5f65ce60293dd326efbff13189c17f6b",
      "title": "Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Kewei Cheng",
          "authorId": "2260755600"
        },
        {
          "name": "Yizhou Sun",
          "authorId": "2257321412"
        }
      ],
      "year": 2025,
      "abstract": null,
      "citationCount": 1,
      "doi": "10.1007/978-3-031-72008-6",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/c47686aa5f65ce60293dd326efbff13189c17f6b",
      "venue": "Synthesis Lectures on Data, Semantics, and Knowledge",
      "journal": {
        "name": "Synthesis Lectures on Data, Semantics, and Knowledge"
      },
      "publicationTypes": [
        "Book"
      ]
    },
    {
      "paperId": "b4ba06e178e3a56436d1253b794669d4831be328",
      "title": "Query2Particles: Knowledge Graph Reasoning with Particle Embeddings",
      "authors": [
        {
          "name": "Jiaxin Bai",
          "authorId": "145677395"
        },
        {
          "name": "Zihao Wang",
          "authorId": "1390878075"
        },
        {
          "name": "Hongming Zhang",
          "authorId": "48212577"
        },
        {
          "name": "Yangqiu Song",
          "authorId": "1809614"
        }
      ],
      "year": 2022,
      "abstract": "Answering complex logical queries on incomplete knowledge graphs (KGs) with missing edges is a fundamental and important task for knowledge graph reasoning. The query embedding method is proposed to answer these queries by jointly encoding queries and entities to the same embedding space. Then the answer entities are selected according to the similarities between the entity embeddings and the query embedding. As the answers to a complex query are obtained from a combination of logical operations over sub-queries, the embeddings of the answer entities may not always follow a uni-modal distribution in the embedding space. Thus, it is challenging to simultaneously retrieve a set of diverse answers from the embedding space using a single and concentrated query representation such as a vector or a hyper-rectangle. To better cope with queries with diversified answers, we propose Query2Particles (Q2P), a complex KG query answering method. Q2P encodes each query into multiple vectors, named particle embeddings. By doing so, the candidate answers can be retrieved from different areas over the embedding space using the maximal similarities between the entity embeddings and any of the particle embeddings. Meanwhile, the corresponding neural logic operations are defined to support its reasoning over arbitrary first-order logic queries. The experiments show that Query2Particles achieves state-of-the-art performance on the complex query answering tasks on FB15k, FB15K-237, and NELL knowledge graphs.",
      "citationCount": 43,
      "doi": "10.48550/arXiv.2204.12847",
      "arxivId": "2204.12847",
      "url": "https://www.semanticscholar.org/paper/b4ba06e178e3a56436d1253b794669d4831be328",
      "venue": "NAACL-HLT",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2204.12847"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "5f324c41e38b87f9885b3a1137dc59d0de3e055a",
      "title": "Logical Rule-Based Knowledge Graph Reasoning: A Comprehensive Survey",
      "authors": [
        {
          "name": "Zefan Zeng",
          "authorId": "2154142572"
        },
        {
          "name": "Qing Cheng",
          "authorId": "2263917570"
        },
        {
          "name": "Yuehang Si",
          "authorId": "2067366549"
        }
      ],
      "year": 2023,
      "abstract": "With its powerful expressive capability and intuitive presentation, the knowledge graph has emerged as one of the primary forms of knowledge representation and management. However, the presence of biases in our cognitive and construction processes often leads to varying degrees of incompleteness and errors within knowledge graphs. To address this, reasoning becomes essential for supplementing and rectifying these shortcomings. Logical rule-based knowledge graph reasoning methods excel at performing inference by uncovering underlying logical rules, showcasing remarkable generalization ability and interpretability. Moreover, the flexibility of logical rules allows for seamless integration with diverse neural network models, thereby offering promising prospects for research and application. Despite the growing number of logical rule-based knowledge graph reasoning methods, a systematic classification and analysis of these approaches is lacking. In this review, we delve into the relevant research on logical rule-based knowledge graph reasoning, classifying them into four categories: methods based on inductive logic programming (ILP), methods that unify probabilistic graphical models and logical rules, methods that unify embedding techniques and logical rules, and methods that jointly use neural networks (NNs) and logical rules. We introduce and analyze the core concepts and key techniques, as well as the advantages and disadvantages associated with these methods, while also providing a comparative evaluation of their performance. Furthermore, we summarize the main problems and challenges, and offer insights into potential directions for future research.",
      "citationCount": 22,
      "doi": "10.3390/math11214486",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/5f324c41e38b87f9885b3a1137dc59d0de3e055a",
      "venue": "Mathematics",
      "journal": {
        "name": "Mathematics"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "f3f7d995f4e3edf4695c4b6bb7f79a32831e9f6d",
      "title": "A Survey of Temporal Knowledge Graph Reasoning",
      "authors": [
        {
          "name": "Yutong Bu",
          "authorId": "2340235538"
        },
        {
          "name": "Yiwei Lu",
          "authorId": "2340546159"
        },
        {
          "name": "Yizhi Wang",
          "authorId": "2340373720"
        },
        {
          "name": "Bo Huang",
          "authorId": "2346808094"
        },
        {
          "name": "Yu Tao",
          "authorId": "2221602894"
        },
        {
          "name": "Yongqi Shi",
          "authorId": "2213204848"
        }
      ],
      "year": 2024,
      "abstract": "With the rapid development of science and technology, people use communication, sensor, computer technology and other means to collect, process and analyze information. However, in the era of big data, static knowledge graph technology is difficult to effectively integrate massive amounts of information quickly and in real time. Temporal knowledge graph utilizes timestamp information elements to learn and mine knowledge effectively. Temporal knowledge graph reasoning technology can reason and predict future actions or development trends. This article introduces two ways of temporal knowledge graph reasoning technology, namely temporal knowledge graph reasoning for facial completion and temporal knowledge graph reasoning for prediction, and conducts a comparative analysis. In summary, this article aims to enable readers to deeply understand knowledge graph technology and its application in temporal knowledge graph reasoning, providing valuable references for research and application in related fields.",
      "citationCount": 3,
      "doi": "10.1109/PRAI62207.2024.10826769",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f3f7d995f4e3edf4695c4b6bb7f79a32831e9f6d",
      "venue": "2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)",
      "journal": {
        "name": "2024 7th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)",
        "pages": "657-661"
      },
      "publicationTypes": [
        "Conference",
        "Review"
      ]
    }
  ],
  "count": 30,
  "errors": []
}
