{
  "status": "success",
  "source": "openalex",
  "query": "language model understanding",
  "results": [
    {
      "openalex_id": "W4281485151",
      "doi": "10.48550/arxiv.2205.11487",
      "title": "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding",
      "authors": [
        {
          "name": "Chitwan Saharia",
          "openalex_id": "A5022455158"
        },
        {
          "name": "William Chan",
          "openalex_id": "A5036374472",
          "orcid": "https://orcid.org/0000-0001-9684-888X"
        },
        {
          "name": "Saurabh Saxena",
          "openalex_id": "A5014971774",
          "orcid": "https://orcid.org/0000-0001-5592-054X"
        },
        {
          "name": "Lala Li",
          "openalex_id": "A5055940122"
        },
        {
          "name": "Jay Whang",
          "openalex_id": "A5046333438",
          "orcid": "https://orcid.org/0009-0000-0084-5933"
        },
        {
          "name": "Emily Denton",
          "openalex_id": "A5045383831",
          "orcid": "https://orcid.org/0000-0003-4915-0512"
        },
        {
          "name": "Seyed Kamyar Seyed Ghasemipour",
          "openalex_id": "A5005349853"
        },
        {
          "name": "Burcu Karagol Ayan",
          "openalex_id": "A5022200342"
        },
        {
          "name": "S. Sara Mahdavi",
          "openalex_id": "A5063201022",
          "orcid": "https://orcid.org/0000-0001-6823-598X"
        },
        {
          "name": "Rapha Gontijo Lopes",
          "openalex_id": "A5079837530"
        },
        {
          "name": "Tim Salimans",
          "openalex_id": "A5082512329"
        },
        {
          "name": "Jonathan Ho",
          "openalex_id": "A5007990046",
          "orcid": "https://orcid.org/0000-0001-9299-9824"
        },
        {
          "name": "David J. Fleet",
          "openalex_id": "A5035123135"
        },
        {
          "name": "Mohammad Norouzi",
          "openalex_id": "A5103947107"
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-05-23",
      "abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment. See https://imagen.research.google/ for an overview of the results.",
      "cited_by_count": 2096,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2205.11487"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Topic Modeling",
        "Computational and Text Analysis Methods"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4281485151"
    },
    {
      "openalex_id": "W3008110149",
      "doi": "10.48550/arxiv.2003.00104",
      "title": "AraBERT: Transformer-based Model for Arabic Language Understanding",
      "authors": [
        {
          "name": "Wissam Antoun",
          "openalex_id": "A5050749439",
          "orcid": "https://orcid.org/0000-0001-8021-5834"
        },
        {
          "name": "Fady Baly",
          "openalex_id": "A5050198833"
        },
        {
          "name": "Hazem Hajj",
          "openalex_id": "A5088085383",
          "orcid": "https://orcid.org/0000-0002-9954-7924",
          "institutions": [
            "American University of Beirut"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-28",
      "abstract": "The Arabic language is a morphologically rich language with relatively few resources and a less explored syntax compared to English. Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle. Recently, with the surge of transformers based models, language-specific BERT based models have proven to be very efficient at language understanding, provided they are pre-trained on a very large corpus. Such models were able to set new standards and achieve state-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT specifically for the Arabic language in the pursuit of achieving the same success that BERT did for the English language. The performance of AraBERT is compared to multilingual BERT from Google and other state-of-the-art approaches. The results showed that the newly developed AraBERT achieved state-of-the-art performance on most tested Arabic NLP tasks. The pretrained araBERT models are publicly available on https://github.com/aub-mind/arabert hoping to encourage research and applications for Arabic NLP.",
      "cited_by_count": 614,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2003.00104"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Sentiment Analysis and Opinion Mining"
      ],
      "referenced_works_count": 47,
      "url": "https://openalex.org/W3008110149"
    },
    {
      "openalex_id": "W4366850747",
      "doi": "10.48550/arxiv.2304.10592",
      "title": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models",
      "authors": [
        {
          "name": "Deyao Zhu",
          "openalex_id": "A5082616743",
          "orcid": "https://orcid.org/0000-0001-8014-7309"
        },
        {
          "name": "Jun Chen",
          "openalex_id": "A5100450148",
          "orcid": "https://orcid.org/0000-0001-8883-0970"
        },
        {
          "name": "Xiaoqian Shen",
          "openalex_id": "A5020511969",
          "orcid": "https://orcid.org/0000-0001-6284-520X"
        },
        {
          "name": "Xiang Li",
          "openalex_id": "A5100331094",
          "orcid": "https://orcid.org/0000-0002-9851-6376"
        },
        {
          "name": "Mohamed Elhoseiny",
          "openalex_id": "A5085089542",
          "orcid": "https://orcid.org/0000-0001-9659-1551"
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-04-20",
      "abstract": "The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability. Our code, pre-trained model, and collected dataset are available at https://minigpt-4.github.io/.",
      "cited_by_count": 469,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2304.10592"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Natural Language Processing Techniques",
        "Topic Modeling"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4366850747"
    },
    {
      "openalex_id": "W4312480274",
      "doi": "10.1007/978-3-031-19833-5_7",
      "title": "Prompting Visual-Language Models for\u00a0Efficient Video Understanding",
      "authors": [
        {
          "name": "Chen Ju",
          "openalex_id": "A5100774574",
          "orcid": "https://orcid.org/0000-0001-8472-7677",
          "institutions": [
            "Shanghai Jiao Tong University",
            "Shandong Jiaotong University"
          ]
        },
        {
          "name": "Tengda Han",
          "openalex_id": "A5075613881",
          "orcid": "https://orcid.org/0000-0002-1874-9664",
          "institutions": [
            "University of Oxford"
          ]
        },
        {
          "name": "Kunhao Zheng",
          "openalex_id": "A5014451563",
          "institutions": [
            "Shandong Jiaotong University",
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Ya Zhang",
          "openalex_id": "A5100342828",
          "orcid": "https://orcid.org/0000-0002-5390-9053",
          "institutions": [
            "Shandong Jiaotong University",
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Weidi Xie",
          "openalex_id": "A5076097168",
          "orcid": "https://orcid.org/0000-0003-3804-2639",
          "institutions": [
            "Shanghai Jiao Tong University",
            "Shandong Jiaotong University",
            "University of Oxford"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": null,
      "cited_by_count": 310,
      "type": "book-chapter",
      "source": {
        "name": "Lecture notes in computer science",
        "type": "book series",
        "issn": [
          "0302-9743",
          "1611-3349"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Human Pose and Action Recognition",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 79,
      "url": "https://openalex.org/W4312480274"
    },
    {
      "openalex_id": "W4389519587",
      "doi": "10.18653/v1/2023.emnlp-demo.49",
      "title": "Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding",
      "authors": [
        {
          "name": "Hang Zhang",
          "openalex_id": "A5100438461",
          "orcid": "https://orcid.org/0000-0002-7816-4238",
          "institutions": [
            "Alibaba Group (China)"
          ]
        },
        {
          "name": "Xin Li",
          "openalex_id": "A5100353783",
          "orcid": "https://orcid.org/0000-0002-0144-9489",
          "institutions": [
            "Alibaba Group (China)"
          ]
        },
        {
          "name": "Lidong Bing",
          "openalex_id": "A5086674741",
          "orcid": "https://orcid.org/0000-0003-4565-6313",
          "institutions": [
            "Alibaba Group (China)"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "We present Video-LLaMA, a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous works that complement LLMs to process the visual or audio signals only, Video-LLaMA enables video comprehension by tackling two challenges: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble a pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities, as the pre-trained audio encoder and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for the LLM module. To align the output of both visual & audio encoders with LLM\u2019s embedding space, we first train Video-LLaMA on massive video/image-caption pairs and then tune our model with visual-instruction datasets of moderate amount but higher quality. We found Video-LLaMA shows the ability to perceive and comprehend video content and generate meaningful responses grounded in the visual and auditory information presented in the videos.",
      "cited_by_count": 340,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2023.emnlp-demo.49.pdf"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Domain Adaptation and Few-Shot Learning",
        "Advanced Image and Video Retrieval Techniques"
      ],
      "referenced_works_count": 33,
      "url": "https://openalex.org/W4389519587"
    },
    {
      "openalex_id": "W4328049044",
      "doi": "10.1073/pnas.2215907120",
      "title": "The debate over understanding in AI\u2019s large language models",
      "authors": [
        {
          "name": "Melanie Mitchell",
          "openalex_id": "A5086956524",
          "orcid": "https://orcid.org/0000-0001-8881-3505",
          "institutions": [
            "Santa Fe Institute"
          ]
        },
        {
          "name": "David C. Krakauer",
          "openalex_id": "A5035224908",
          "orcid": "https://orcid.org/0000-0002-0827-6525",
          "institutions": [
            "Santa Fe Institute"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-03-21",
      "abstract": "We survey a current, heated debate in the artificial intelligence (AI) research community on whether large pretrained language models can be said to understand language\u2014and the physical and social situations language encodes\u2014in any humanlike sense. We describe arguments that have been made for and against such understanding and key questions for the broader sciences of intelligence that have arisen in light of these arguments. We contend that an extended science of intelligence can be developed that will provide insight into distinct modes of understanding, their strengths and limitations, and the challenge of integrating diverse forms of cognition.",
      "cited_by_count": 244,
      "type": "article",
      "source": {
        "name": "Proceedings of the National Academy of Sciences",
        "type": "journal",
        "issn": [
          "0027-8424",
          "1091-6490"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC10068812/pdf/pnas.202215907.pdf"
      },
      "topics": [
        "Language and cultural evolution",
        "Topic Modeling",
        "Language, Metaphor, and Cognition"
      ],
      "referenced_works_count": 59,
      "url": "https://openalex.org/W4328049044"
    },
    {
      "openalex_id": "W4389519352",
      "doi": "10.18653/v1/2023.emnlp-main.68",
      "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation",
      "authors": [
        {
          "name": "Yue Wang",
          "openalex_id": "A5100372089",
          "orcid": "https://orcid.org/0000-0003-0146-7262"
        },
        {
          "name": "Hung L\u00ea",
          "openalex_id": "A5101936199",
          "orcid": "https://orcid.org/0000-0002-3126-184X"
        },
        {
          "name": "Akhilesh Deepak Gotmare",
          "openalex_id": "A5104211341",
          "orcid": "https://orcid.org/0000-0001-6502-0350"
        },
        {
          "name": "Nghi Bui",
          "openalex_id": "A5062399934"
        },
        {
          "name": "Junnan Li",
          "openalex_id": "A5100608756",
          "orcid": "https://orcid.org/0000-0002-1405-2034"
        },
        {
          "name": "Steven C. H. Hoi",
          "openalex_id": "A5074834854",
          "orcid": "https://orcid.org/0000-0002-4584-3453"
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "Large language models (LLMs) pretrained on vast source code have achieved prominent progress in code intelligence. However, existing code LLMs have two main limitations. First, they often adopt a specific architecture (encoder-only or decoder-only) or rely on a unified encoder-decoder network for different downstream tasks, lacking the flexibility to operate in the optimal architecture for a specific task. Secondly, they often employ a limited set of pretraining objectives which might not be relevant to some tasks and hence result in substantial performance degrade. To address these limitations, we propose \u201cCodeT5+\u201d, a family of encoder-decoder LLMs for code in which component modules can be flexibly combined to suit a wide range of code tasks. Such flexibility is enabled by our proposed mixture of pretraining objectives, which cover span denoising, contrastive learning, text-code matching, and causal LM pretraining tasks, on both unimodal and bimodal multilingual code corpora. Furthermore, we propose to initialize CodeT5+ with frozen off-the-shelf LLMs without training from scratch to efficiently scale up our models, and explore instruction-tuning to align with natural language instructions. We extensively evaluate CodeT5+ on over 20 code-related benchmarks in different settings, including zero-shot, finetuning, and instruction-tuning. We observe state-of-the-art (SoTA) performance on various code-related tasks, and our instruction-tuned CodeT5+ 16B achieves new SoTA results of 35.0% pass@1 and 54.5% pass@10 on the HumanEval code generation task against other open code LLMs, even surpassing the OpenAI code-cushman-001 model.",
      "cited_by_count": 279,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.18653/v1/2023.emnlp-main.68"
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Software Engineering Research"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4389519352"
    },
    {
      "openalex_id": "W3088592174",
      "doi": null,
      "title": "AraBERT: Transformer-based Model for Arabic Language Understanding",
      "authors": [
        {
          "name": "Wissam Antoun",
          "openalex_id": "A5050749439",
          "orcid": "https://orcid.org/0000-0001-8021-5834"
        },
        {
          "name": "Fady Baly",
          "openalex_id": "A5050198833"
        },
        {
          "name": "Hazem Hajj",
          "openalex_id": "A5088085383",
          "orcid": "https://orcid.org/0000-0002-9954-7924"
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-28",
      "abstract": "The Arabic language is a morphologically rich language with relatively few resources and a less explored syntax compared to English. Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle. Recently, with the surge of transformers based models, language-specific BERT based models have proven to be very efficient at language understanding, provided they are pre-trained on a very large corpus. Such models were able to set new standards and achieve state-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT specifically for the Arabic language in the pursuit of achieving the same success that BERT did for the English language. The performance of AraBERT is compared to multilingual BERT from Google and other state-of-the-art approaches. The results showed that the newly developed AraBERT achieved state-of-the-art performance on most tested Arabic NLP tasks. The pretrained araBERT models are publicly available on https://github.com/aub-mind/araBERT hoping to encourage research and applications for Arabic NLP.",
      "cited_by_count": 135,
      "type": "article",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2003.00104"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Sentiment Analysis and Opinion Mining"
      ],
      "referenced_works_count": 40,
      "url": "https://openalex.org/W3088592174"
    },
    {
      "openalex_id": "W4394659899",
      "doi": "10.48550/arxiv.2002.06353",
      "title": "UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation",
      "authors": [
        {
          "name": "Huaishao Luo",
          "openalex_id": "A5060295796",
          "orcid": "https://orcid.org/0000-0003-4297-1270"
        },
        {
          "name": "Lei Ji",
          "openalex_id": "A5100754482",
          "orcid": "https://orcid.org/0000-0001-7753-3313"
        },
        {
          "name": "Botian Shi",
          "openalex_id": "A5058342038",
          "orcid": "https://orcid.org/0000-0003-3677-7252"
        },
        {
          "name": "Haoyang Huang",
          "openalex_id": "A5020769158"
        },
        {
          "name": "Nan Duan",
          "openalex_id": "A5042018181",
          "orcid": "https://orcid.org/0000-0002-3387-4674"
        },
        {
          "name": "Tianrui Li",
          "openalex_id": "A5070559820",
          "orcid": "https://orcid.org/0000-0001-7780-104X"
        },
        {
          "name": "Jason Li",
          "openalex_id": "A5100762970",
          "orcid": "https://orcid.org/0000-0002-1150-3549"
        },
        {
          "name": "Taroon Bharti",
          "openalex_id": "A5060313707"
        },
        {
          "name": "Ming Zhou",
          "openalex_id": "A5100701574",
          "orcid": "https://orcid.org/0000-0002-5701-1996"
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-15",
      "abstract": "With the recent success of the pre-training technique for NLP and image-linguistic tasks, some video-linguistic pre-training works are gradually developed to improve video-text related downstream tasks. However, most of the existing multimodal models are pre-trained for understanding tasks, leading to a pretrain-finetune discrepancy for generation tasks. This paper proposes UniVL: a Unified Video and Language pre-training model for both multimodal understanding and generation. It comprises four components, including two single-modal encoders, a cross encoder, and a decoder with the Transformer backbone. Five objectives, including video-text joint, conditioned masked language model (CMLM), conditioned masked frame model (CMFM), video-text alignment, and language reconstruction, are designed to train each of the components. We further develop two pre-training strategies, stage by stage pre-training (StagedP) and enhanced video representation (EnhancedV), to make the training process of the UniVL more effective. The pre-train is carried out on a sizeable instructional video dataset HowTo100M. Experimental results demonstrate that the UniVL can learn strong video-text representation and achieves state-of-the-art results on five downstream tasks.",
      "cited_by_count": 169,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2002.06353"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Speech and dialogue systems",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4394659899"
    },
    {
      "openalex_id": "W4221142828",
      "doi": "10.18653/v1/2022.acl-long.398",
      "title": "Can Prompt Probe Pretrained Language Models? Understanding the Invisible Risks from a Causal View",
      "authors": [
        {
          "name": "Boxi Cao",
          "openalex_id": "A5007288942",
          "orcid": "https://orcid.org/0000-0001-9916-7406",
          "institutions": [
            "University of Chinese Academy of Sciences"
          ]
        },
        {
          "name": "Hongyu Lin",
          "openalex_id": "A5041809943",
          "orcid": "https://orcid.org/0000-0001-7151-922X"
        },
        {
          "name": "Xianpei Han",
          "openalex_id": "A5100620300",
          "orcid": "https://orcid.org/0000-0002-1304-6302",
          "institutions": [
            "Chinese Academy of Sciences",
            "Institute of Software",
            "Beijing Academy of Artificial Intelligence"
          ]
        },
        {
          "name": "Fangchao Liu",
          "openalex_id": "A5103326017",
          "orcid": "https://orcid.org/0009-0000-6646-1369",
          "institutions": [
            "University of Chinese Academy of Sciences"
          ]
        },
        {
          "name": "Le Sun",
          "openalex_id": "A5101652785",
          "institutions": [
            "Institute of Software",
            "Chinese Academy of Sciences"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": "Prompt-based probing has been widely used in evaluating the abilities of pretrained language models (PLMs). Unfortunately, recent studies have discovered such an evaluation may be inaccurate, inconsistent and unreliable. Furthermore, the lack of understanding its inner workings, combined with its wide applicability, has the potential to lead to unforeseen risks for evaluating and applying PLMs in real-world applications. To discover, understand and quantify the risks, this paper investigates the prompt-based probing from a causal view, highlights three critical biases which could induce biased results and conclusions, and proposes to conduct debiasing via causal intervention. This paper provides valuable insights for the design of unbiased datasets, better probing frameworks and more reliable evaluations of pretrained language models. Furthermore, our conclusions also echo that we need to rethink the criteria for identifying better pretrained language models.",
      "cited_by_count": 20,
      "type": "article",
      "source": {
        "name": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
        "type": "conference",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://aclanthology.org/2022.acl-long.398.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 52,
      "url": "https://openalex.org/W4221142828"
    },
    {
      "openalex_id": "W4402671548",
      "doi": "10.18653/v1/2024.acl-long.679",
      "title": "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models",
      "authors": [
        {
          "name": "Muhammad Maaz",
          "openalex_id": "A5034370385",
          "orcid": "https://orcid.org/0000-0002-3869-631X"
        },
        {
          "name": "Hanoona Rasheed",
          "openalex_id": "A5064948724"
        },
        {
          "name": "Salman Khan",
          "openalex_id": "A5000300751",
          "orcid": "https://orcid.org/0000-0002-9502-1749"
        },
        {
          "name": "Fahad Shahbaz Khan",
          "openalex_id": "A5100760570",
          "orcid": "https://orcid.org/0000-0002-4263-3143"
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-01-01",
      "abstract": null,
      "cited_by_count": 213,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.18653/v1/2024.acl-long.679"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Human Pose and Action Recognition",
        "COVID-19 diagnosis using AI"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4402671548"
    },
    {
      "openalex_id": "W3100452049",
      "doi": "10.18653/v1/2020.clinicalnlp-1.17",
      "title": "Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art",
      "authors": [
        {
          "name": "Patrick Lewis",
          "openalex_id": "A5063377058",
          "orcid": "https://orcid.org/0000-0002-2192-9543",
          "institutions": [
            "University College London"
          ]
        },
        {
          "name": "Myle Ott",
          "openalex_id": "A5076248976",
          "institutions": [
            "Meta (Israel)"
          ]
        },
        {
          "name": "Jingfei Du",
          "openalex_id": "A5006191011",
          "institutions": [
            "Meta (Israel)"
          ]
        },
        {
          "name": "Veselin Stoyanov",
          "openalex_id": "A5091317839",
          "institutions": [
            "Meta (Israel)"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-01",
      "abstract": "A large array of pretrained models are available to the biomedical NLP (BioNLP) community. Finding the best model for a particular task can be difficult and time-consuming. For many applications in the biomedical and clinical domains, it is crucial that models can be built quickly and are highly accurate. We present a large-scale study across 18 established biomedical and clinical NLP tasks to determine which of several popular open-source biomedical and clinical NLP models work well in different settings. Furthermore, we apply recent advances in pretraining to train new biomedical language models, and carefully investigate the effect of various design choices on downstream performance. Our best models perform well in all of our benchmarks, and set new State-of-the-Art in 9 tasks. We release these models in the hope that they can help the community to speed up and increase the accuracy of BioNLP and text mining applications.",
      "cited_by_count": 166,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.aclweb.org/anthology/2020.clinicalnlp-1.17.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Biomedical Text Mining and Ontologies"
      ],
      "referenced_works_count": 64,
      "url": "https://openalex.org/W3100452049"
    },
    {
      "openalex_id": "W3172205429",
      "doi": "10.48550/arxiv.2106.13219",
      "title": "Towards Understanding and Mitigating Social Biases in Language Models",
      "authors": [
        {
          "name": "Paul Pu Liang",
          "openalex_id": "A5086233510",
          "orcid": "https://orcid.org/0000-0001-7768-3610"
        },
        {
          "name": "Chiyu Wu",
          "openalex_id": "A5075261035",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Louis\u2013Philippe Morency",
          "openalex_id": "A5081398601",
          "orcid": "https://orcid.org/0000-0001-6376-7696",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Ruslan Salakhutdinov",
          "openalex_id": "A5071983998",
          "orcid": "https://orcid.org/0000-0002-3752-2756"
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-06-24",
      "abstract": "As machine learning methods are deployed in real-world settings such as healthcare, legal systems, and social science, it is crucial to recognize how they shape social biases and stereotypes in these sensitive decision-making processes. Among such real-world deployments are large-scale pretrained language models (LMs) that can be potentially dangerous in manifesting undesirable representational biases - harmful biases resulting from stereotyping that propagate negative generalizations involving gender, race, religion, and other social constructs. As a step towards improving the fairness of LMs, we carefully define several sources of representational biases before proposing new benchmarks and metrics to measure them. With these tools, we propose steps towards mitigating social biases during text generation. Our empirical results and human evaluation demonstrate effectiveness in mitigating bias while retaining crucial contextual information for high-fidelity text generation, thereby pushing forward the performance-fairness Pareto frontier.",
      "cited_by_count": 127,
      "type": "article",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2106.13219"
      },
      "topics": [
        "Topic Modeling",
        "Text Readability and Simplification",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W3172205429"
    },
    {
      "openalex_id": "W4287888679",
      "doi": "10.18653/v1/2022.findings-naacl.98",
      "title": "BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource Language Understanding Evaluation in Bangla",
      "authors": [
        {
          "name": "Abhik Bhattacharjee",
          "openalex_id": "A5015510710",
          "institutions": [
            "University of Rochester"
          ]
        },
        {
          "name": "Tahmid Hasan",
          "openalex_id": "A5069644647",
          "orcid": "https://orcid.org/0000-0003-2748-5098",
          "institutions": [
            "University of Rochester"
          ]
        },
        {
          "name": "Wasi Uddin Ahmad",
          "openalex_id": "A5103968040",
          "orcid": "https://orcid.org/0000-0001-8171-9583",
          "institutions": [
            "Bangladesh University of Engineering and Technology"
          ]
        },
        {
          "name": "Kazi Samin Mubasshir",
          "openalex_id": "A5006899349",
          "institutions": [
            "University of Rochester"
          ]
        },
        {
          "name": "Md. Saiful Islam",
          "openalex_id": "A5100420857",
          "orcid": "https://orcid.org/0000-0003-3725-3493"
        },
        {
          "name": "Anindya Iqbal",
          "openalex_id": "A5027377957",
          "orcid": "https://orcid.org/0000-0001-6636-0963",
          "institutions": [
            "University of Rochester"
          ]
        },
        {
          "name": "M. Sohel Rahman",
          "openalex_id": "A5104083661",
          "institutions": [
            "University of Rochester"
          ]
        },
        {
          "name": "Rifat Shahriyar",
          "openalex_id": "A5090604535",
          "orcid": "https://orcid.org/0000-0001-9540-315X",
          "institutions": [
            "University of Rochester"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": "Abhik Bhattacharjee, Tahmid Hasan, Wasi Ahmad, Kazi Samin Mubasshir, Md Saiful Islam, Anindya Iqbal, M. Sohel Rahman, Rifat Shahriyar. Findings of the Association for Computational Linguistics: NAACL 2022. 2022.",
      "cited_by_count": 132,
      "type": "article",
      "source": {
        "name": "Findings of the Association for Computational Linguistics: NAACL 2022",
        "type": "conference",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://aclanthology.org/2022.findings-naacl.98.pdf"
      },
      "topics": [
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 49,
      "url": "https://openalex.org/W4287888679"
    },
    {
      "openalex_id": "W3032299950",
      "doi": "10.1007/s11063-021-10528-4",
      "title": "ParsBERT: Transformer-based Model for Persian Language Understanding",
      "authors": [
        {
          "name": "Mehrdad Farahani",
          "openalex_id": "",
          "institutions": [
            "Islamic Azad University North Tehran Branch",
            "Ume\u00e5 University"
          ]
        },
        {
          "name": "Mohammad Gharachorloo",
          "openalex_id": "",
          "institutions": [
            "Queensland University of Technology"
          ]
        },
        {
          "name": "Marzieh Farahani",
          "openalex_id": "",
          "institutions": [
            "Islamic Azad University North Tehran Branch",
            "Ume\u00e5 University"
          ]
        },
        {
          "name": "Mohammad Manthouri",
          "openalex_id": "",
          "orcid": "https://orcid.org/0000-0003-3461-9250",
          "institutions": [
            "Shahed University"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-10-08",
      "abstract": null,
      "cited_by_count": 123,
      "type": "article",
      "source": {
        "name": "Neural Processing Letters",
        "type": "journal",
        "issn": [
          "1370-4621",
          "1573-773X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2005.12515"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Sentiment Analysis and Opinion Mining"
      ],
      "referenced_works_count": 24,
      "url": "https://openalex.org/W3032299950"
    },
    {
      "openalex_id": "W4405064339",
      "doi": "10.1115/1.4067333",
      "title": "DesignQA: A Multimodal Benchmark for Evaluating Large Language Models\u2019 Understanding of Engineering Documentation",
      "authors": [
        {
          "name": "Anna C. Doris",
          "openalex_id": "A5093321387",
          "orcid": "https://orcid.org/0009-0003-0125-0909",
          "institutions": [
            "Massachusetts Institute of Technology"
          ]
        },
        {
          "name": "Daniele Grandi",
          "openalex_id": "A5067938085",
          "institutions": [
            "Autodesk (United States)"
          ]
        },
        {
          "name": "Ryan Tomich",
          "openalex_id": "A5095384045",
          "institutions": [
            "Massachusetts Institute of Technology",
            "Mitsubishi Motors (Japan)"
          ]
        },
        {
          "name": "Md Ferdous Alam",
          "openalex_id": "A5035835155",
          "orcid": "https://orcid.org/0000-0002-8469-7591",
          "institutions": [
            "Massachusetts Institute of Technology"
          ]
        },
        {
          "name": "Mohammadmehdi Ataei",
          "openalex_id": "A5095912580",
          "institutions": [
            "University of Toronto",
            "Autodesk (United States)"
          ]
        },
        {
          "name": "Hyunmin Cheong",
          "openalex_id": "A5025070841",
          "orcid": "https://orcid.org/0000-0002-6683-701X",
          "institutions": [
            "University of Toronto",
            "Autodesk (United States)"
          ]
        },
        {
          "name": "Faez Ahmed",
          "openalex_id": "A5040705509",
          "orcid": "https://orcid.org/0000-0002-5227-2628",
          "institutions": [
            "Massachusetts Institute of Technology"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-12-05",
      "abstract": "Abstract This research introduces DesignQA, a novel benchmark aimed at evaluating the proficiency of multimodal large language models (MLLMs) in comprehending and applying engineering requirements in technical documentation. Developed with a focus on real-world engineering challenges, DesignQA uniquely combines multimodal data\u2014including textual design requirements, CAD images, and engineering drawings\u2014derived from the Formula SAE student competition. Unlike many existing MLLM benchmarks, DesignQA contains document-grounded visual questions where the input image and the input document come from different sources. The benchmark features automatic evaluation metrics and is divided into segments\u2014Rule Comprehension, Rule Compliance, and Rule Extraction\u2014based on tasks that engineers perform when designing according to requirements. We evaluate state-of-the-art models (at the time of writing) like GPT-4o, GPT-4, Claude-Opus, Gemini-1.0, and LLaVA-1.5 against the benchmark, and our study uncovers the existing gaps in MLLMs\u2019 abilities to interpret complex engineering documentation. The MLLMs tested, while promising, struggle to reliably retrieve relevant rules from the Formula SAE documentation, face challenges in recognizing technical components in CAD images and encounter difficulty in analyzing engineering drawings. These findings underscore the need for multimodal models that can better handle the multifaceted questions characteristic of design according to technical documentation. This benchmark sets a foundation for future advancements in AI-supported engineering design processes. DesignQA is publicly available at online.",
      "cited_by_count": 13,
      "type": "article",
      "source": {
        "name": "Journal of Computing and Information Science in Engineering",
        "type": "journal",
        "issn": [
          "1530-9827",
          "1944-7078"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Design Education and Practice",
        "linguistics and terminology studies",
        "Engineering and Information Technology"
      ],
      "referenced_works_count": 36,
      "url": "https://openalex.org/W4405064339"
    },
    {
      "openalex_id": "W3128912454",
      "doi": "10.48550/arxiv.2102.02503",
      "title": "Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models",
      "authors": [
        {
          "name": "Alex Tamkin",
          "openalex_id": "A5081558429",
          "orcid": "https://orcid.org/0009-0006-0007-3746"
        },
        {
          "name": "Miles Brundage",
          "openalex_id": "A5066559387"
        },
        {
          "name": "Jack Clark",
          "openalex_id": "A5031107879"
        },
        {
          "name": "Deep Ganguli",
          "openalex_id": "A5006294201",
          "orcid": "https://orcid.org/0009-0007-9435-3817"
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-02-04",
      "abstract": "On October 14th, 2020, researchers from OpenAI, the Stanford Institute for Human-Centered Artificial Intelligence, and other universities convened to discuss open research questions surrounding GPT-3, the largest publicly-disclosed dense language model at the time. The meeting took place under Chatham House Rules. Discussants came from a variety of research backgrounds including computer science, linguistics, philosophy, political science, communications, cyber policy, and more. Broadly, the discussion centered around two main questions: 1) What are the technical capabilities and limitations of large language models? 2) What are the societal effects of widespread use of large language models? Here, we provide a detailed summary of the discussion organized by the two themes above.",
      "cited_by_count": 128,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2102.02503"
      },
      "topics": [
        "Artificial Intelligence in Healthcare and Education",
        "Topic Modeling"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W3128912454"
    },
    {
      "openalex_id": "W3122866338",
      "doi": "10.1145/3547138",
      "title": "A Survey of Joint Intent Detection and Slot Filling Models in Natural Language Understanding",
      "authors": [
        {
          "name": "Henry Weld",
          "openalex_id": "A5044248980",
          "orcid": "https://orcid.org/0000-0002-6628-0290",
          "institutions": [
            "University of Sydney"
          ]
        },
        {
          "name": "Xiaoqi Huang",
          "openalex_id": "A5038412255",
          "orcid": "https://orcid.org/0000-0002-8287-9447",
          "institutions": [
            "University of Sydney"
          ]
        },
        {
          "name": "Siqu Long",
          "openalex_id": "A5032358151",
          "orcid": "https://orcid.org/0000-0003-0590-7587",
          "institutions": [
            "University of Sydney"
          ]
        },
        {
          "name": "Josiah Poon",
          "openalex_id": "A5085086413",
          "orcid": "https://orcid.org/0000-0003-3371-8628",
          "institutions": [
            "University of Sydney"
          ]
        },
        {
          "name": "Soyeon Caren Han",
          "openalex_id": "A5084419965",
          "orcid": "https://orcid.org/0000-0002-1948-6819",
          "institutions": [
            "University of Sydney"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-07-09",
      "abstract": "Intent classification, to identify the speaker\u2019s intention, and slot filling, to label each token with a semantic type, are critical tasks in natural language understanding. Traditionally the two tasks have been addressed independently. More recently joint models that address the two tasks together have achieved state-of-the-art performance for each task and have shown there exists a strong relationship between the two. In this survey, we bring the coverage of methods up to 2021 including the many applications of deep learning in the field. As well as a technological survey, we look at issues addressed in the joint task and the approaches designed to address these issues. We cover datasets, evaluation metrics, and experiment design and supply a summary of reported performance on the standard datasets.",
      "cited_by_count": 116,
      "type": "review",
      "source": {
        "name": "ACM Computing Surveys",
        "type": "journal",
        "issn": [
          "0360-0300",
          "1557-7341"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Speech Recognition and Synthesis"
      ],
      "referenced_works_count": 171,
      "url": "https://openalex.org/W3122866338"
    },
    {
      "openalex_id": "W4366591012",
      "doi": "10.1145/3544548.3581503",
      "title": "Understanding the Benefits and Challenges of Deploying Conversational AI Leveraging Large Language Models for Public Health Intervention",
      "authors": [
        {
          "name": "Eunkyung Jo",
          "openalex_id": "A5015228589",
          "orcid": "https://orcid.org/0000-0002-6494-3396",
          "institutions": [
            "University of California, Irvine",
            "Naver (South Korea)"
          ]
        },
        {
          "name": "Daniel A. Epstein",
          "openalex_id": "A5088906729",
          "orcid": "https://orcid.org/0000-0002-2657-6345",
          "institutions": [
            "University of California, Irvine"
          ]
        },
        {
          "name": "Hyunhoon Jung",
          "openalex_id": "A5006893167",
          "orcid": "https://orcid.org/0000-0002-5161-2782",
          "institutions": [
            "Naver (South Korea)"
          ]
        },
        {
          "name": "Young\u2010Ho Kim",
          "openalex_id": "A5062848438",
          "orcid": "https://orcid.org/0000-0002-2681-2774",
          "institutions": [
            "Naver (South Korea)"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-04-19",
      "abstract": "Recent large language models (LLMs) have advanced the quality of open-ended conversations with chatbots. Although LLM-driven chatbots have the potential to support public health interventions by monitoring populations at scale through empathetic interactions, their use in real-world settings is underexplored. We thus examine the case of CareCall, an open-domain chatbot that aims to support socially isolated individuals via check-up phone calls and monitoring by teleoperators. Through focus group observations and interviews with 34 people from three stakeholder groups, including the users, the teleoperators, and the developers, we found CareCall offered a holistic understanding of each individual while offloading the public health workload and helped mitigate loneliness and emotional burdens. However, our findings highlight that traits of LLM-driven chatbots led to challenges in supporting public and personal health needs. We discuss considerations of designing and deploying LLM-driven chatbots for public health intervention, including tensions among stakeholders around system expectations.",
      "cited_by_count": 143,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3544548.3581503"
      },
      "topics": [
        "AI in Service Interactions",
        "Digital Mental Health Interventions",
        "Innovative Human-Technology Interaction"
      ],
      "referenced_works_count": 71,
      "url": "https://openalex.org/W4366591012"
    },
    {
      "openalex_id": "W4221149883",
      "doi": "10.48550/arxiv.2202.04538",
      "title": "Generating Training Data with Language Models: Towards Zero-Shot Language Understanding",
      "authors": [
        {
          "name": "Meng Yu",
          "openalex_id": "A5100770786",
          "orcid": "https://orcid.org/0000-0003-2554-2888"
        },
        {
          "name": "Jiaxin Huang",
          "openalex_id": "A5101940974",
          "orcid": "https://orcid.org/0000-0002-4036-3741"
        },
        {
          "name": "Yu Zhang",
          "openalex_id": "A5100433691",
          "orcid": "https://orcid.org/0000-0003-1100-4835"
        },
        {
          "name": "Jiawei Han",
          "openalex_id": "A5019539533",
          "orcid": "https://orcid.org/0000-0002-3629-2696"
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-02-09",
      "abstract": "Pretrained language models (PLMs) have demonstrated remarkable performance in various natural language processing tasks: Unidirectional PLMs (e.g., GPT) are well known for their superior text generation capabilities; bidirectional PLMs (e.g., BERT) have been the prominent choice for natural language understanding (NLU) tasks. While both types of models have achieved promising few-shot learning performance, their potential for zero-shot learning has been underexplored. In this paper, we present a simple approach that uses both types of PLMs for fully zero-shot learning of NLU tasks without requiring any task-specific data: A unidirectional PLM generates class-conditioned texts guided by prompts, which are used as the training data for fine-tuning a bidirectional PLM. With quality training data selected based on the generation probability and regularization techniques (label smoothing and temporal ensembling) applied to the fine-tuning stage for better generalization and stability, our approach demonstrates strong performance across seven classification tasks of the GLUE benchmark (e.g., 72.3/73.8 on MNLI-m/mm and 92.8 on SST-2), significantly outperforming zero-shot prompting methods and achieving even comparable results to strong few-shot approaches using 32 training samples per class.",
      "cited_by_count": 80,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2202.04538"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Text Readability and Simplification"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4221149883"
    },
    {
      "openalex_id": "W3088418428",
      "doi": "10.1073/pnas.1910416117",
      "title": "Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models",
      "authors": [
        {
          "name": "James L. McClelland",
          "openalex_id": "A5020224649",
          "orcid": "https://orcid.org/0000-0002-8217-405X",
          "institutions": [
            "DeepMind (United Kingdom)",
            "Stanford University"
          ]
        },
        {
          "name": "Felix Hill",
          "openalex_id": "A5010396788",
          "orcid": "https://orcid.org/0000-0002-6712-1718",
          "institutions": [
            "DeepMind (United Kingdom)"
          ]
        },
        {
          "name": "Maja Rudolph",
          "openalex_id": "A5077309439",
          "orcid": "https://orcid.org/0009-0007-3739-2203",
          "institutions": [
            "Robert Bosch (Germany)"
          ]
        },
        {
          "name": "Jason Baldridge",
          "openalex_id": "A5048931310",
          "orcid": "https://orcid.org/0000-0002-4712-1841",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Hinrich Sch\u00fctze",
          "openalex_id": "A5071144367",
          "institutions": [
            "Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-09-28",
      "abstract": "Language is crucial for human intelligence, but what exactly is its role? We take language to be a part of a system for understanding and communicating about situations. In humans, these abilities emerge gradually from experience and depend on domain-general principles of biological neural networks: connection-based learning, distributed representation, and context-sensitive, mutual constraint satisfaction-based processing. Current artificial language processing systems rely on the same domain general principles, embodied in artificial neural networks. Indeed, recent progress in this field depends on query-based attention, which extends the ability of these systems to exploit context and has contributed to remarkable breakthroughs. Nevertheless, most current models focus exclusively on language-internal tasks, limiting their ability to perform tasks that depend on understanding situations. These systems also lack memory for the contents of prior situations outside of a fixed contextual span. We describe the organization of the brain\u2019s distributed understanding system, which includes a fast learning system that addresses the memory problem. We sketch a framework for future models of understanding drawing equally on cognitive neuroscience and artificial intelligence and exploiting query-based attention. We highlight relevant current directions and consider further developments needed to fully capture human-level language understanding in a computational system.",
      "cited_by_count": 93,
      "type": "article",
      "source": {
        "name": "Proceedings of the National Academy of Sciences",
        "type": "journal",
        "issn": [
          "0027-8424",
          "1091-6490"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://epub.ub.uni-muenchen.de/74086/"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Neurobiology of Language and Bilingualism"
      ],
      "referenced_works_count": 95,
      "url": "https://openalex.org/W3088418428"
    },
    {
      "openalex_id": "W3006320872",
      "doi": null,
      "title": "UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation.",
      "authors": [
        {
          "name": "Huaishao Luo",
          "openalex_id": "A5060295796",
          "orcid": "https://orcid.org/0000-0003-4297-1270"
        },
        {
          "name": "Lei Ji",
          "openalex_id": "A5100754482",
          "orcid": "https://orcid.org/0000-0001-7753-3313"
        },
        {
          "name": "Botian Shi",
          "openalex_id": "A5058342038",
          "orcid": "https://orcid.org/0000-0003-3677-7252"
        },
        {
          "name": "Haoyang Huang",
          "openalex_id": "A5020769158"
        },
        {
          "name": "Nan Duan",
          "openalex_id": "A5042018181",
          "orcid": "https://orcid.org/0000-0002-3387-4674"
        },
        {
          "name": "Tianrui Li",
          "openalex_id": "A5070559820",
          "orcid": "https://orcid.org/0000-0001-7780-104X"
        },
        {
          "name": "Xilin Chen",
          "openalex_id": "A5083420537",
          "orcid": "https://orcid.org/0000-0003-3024-4404"
        },
        {
          "name": "Ming Zhou",
          "openalex_id": "A5100701572",
          "orcid": "https://orcid.org/0000-0002-2551-2964"
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-15",
      "abstract": "With the recent success of the pre-training technique for NLP and image-linguistic tasks, some video-linguistic pre-training works are gradually developed to improve video-text related downstream tasks. However, most of the existing multimodal models are pre-trained for understanding tasks, leading to a pretrain-finetune discrepancy for generation tasks. This paper proposes UniVL: a Unified Video and Language pre-training model for both multimodal understanding and generation. It comprises four components, including two single-modal encoders, a cross encoder, and a decoder with the Transformer backbone. Five objectives, including video-text joint, conditioned masked language model (CMLM), conditioned masked frame model (CMFM), video-text alignment, and language reconstruction, are designed to train each of the components. We further develop two pre-training strategies, stage by stage pre-training (StagedP) and enhanced video representation (EnhancedV), to make the training process of the UniVL more effective. The pre-train is carried out on a sizeable instructional video dataset HowTo100M. Experimental results demonstrate that the UniVL can learn strong video-text representation and achieves state-of-the-art results on five downstream tasks.",
      "cited_by_count": 93,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "http://export.arxiv.org/pdf/2002.06353"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Topic Modeling",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 62,
      "url": "https://openalex.org/W3006320872"
    },
    {
      "openalex_id": "W4210894209",
      "doi": "10.1109/access.2022.3149798",
      "title": "Framework for Deep Learning-Based Language Models Using Multi-Task Learning in Natural Language Understanding: A Systematic Literature Review and Future Directions",
      "authors": [
        {
          "name": "Rahul M. Samant",
          "openalex_id": "A5000591434",
          "orcid": "https://orcid.org/0000-0002-5158-9180",
          "institutions": [
            "Symbiosis International University"
          ]
        },
        {
          "name": "Mrinal Bachute",
          "openalex_id": "A5079625677",
          "orcid": "https://orcid.org/0000-0002-6647-9347",
          "institutions": [
            "Symbiosis International University"
          ]
        },
        {
          "name": "Shilpa Gite",
          "openalex_id": "A5084518207",
          "orcid": "https://orcid.org/0000-0003-3882-7030",
          "institutions": [
            "Symbiosis International University"
          ]
        },
        {
          "name": "Ketan Kotecha",
          "openalex_id": "A5077770842",
          "orcid": "https://orcid.org/0000-0003-2653-3780",
          "institutions": [
            "Symbiosis International University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-01",
      "abstract": "Learning human languages is a difficult task for a computer. However, Deep Learning (DL) techniques have enhanced performance significantly for almost all-natural language processing (NLP) tasks. Unfortunately, these models cannot be generalized for all the NLP tasks with similar performance. NLU (Natural Language Understanding) is a subset of NLP including tasks, like machine translation, dialogue-based systems, natural language inference, text entailment, sentiment analysis, etc. The advancement in the field of NLU is the collective performance enhancement in all these tasks. Even though MTL (Multi-task Learning) was introduced before Deep Learning, it has gained significant attention in the past years. This paper aims to identify, investigate, and analyze various language models used in NLU and NLP to find directions for future research. The Systematic Literature Review (SLR) is prepared using the literature search guidelines proposed by Kitchenham and Charters on various language models between 2011 and 2021. This SLR points out that the unsupervised learning method-based language models show potential performance improvement. However, they face the challenge of designing the general-purpose framework for the language model, which will improve the performance of multi-task NLU and the generalized representation of knowledge. Combining these approaches may result in a more efficient and robust multi-task NLU. This SLR proposes building steps for a conceptual framework to achieve goals of enhancing the performance of language models in the field of NLU.",
      "cited_by_count": 108,
      "type": "article",
      "source": {
        "name": "IEEE Access",
        "type": "journal",
        "issn": [
          "2169-3536"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://ieeexplore.ieee.org/ielx7/6287639/9668973/09706456.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Sentiment Analysis and Opinion Mining"
      ],
      "referenced_works_count": 126,
      "url": "https://openalex.org/W4210894209"
    },
    {
      "openalex_id": "W4367047590",
      "doi": "10.1109/tpami.2023.3269220",
      "title": "SignBERT+: Hand-Model-Aware Self-Supervised Pre-Training for Sign Language Understanding",
      "authors": [
        {
          "name": "Hezhen Hu",
          "openalex_id": "A5035950233",
          "orcid": "https://orcid.org/0000-0003-0327-1562",
          "institutions": [
            "University of Science and Technology of China"
          ]
        },
        {
          "name": "Weichao Zhao",
          "openalex_id": "A5057827327",
          "orcid": "https://orcid.org/0000-0001-7098-1690",
          "institutions": [
            "University of Science and Technology of China"
          ]
        },
        {
          "name": "Wengang Zhou",
          "openalex_id": "A5046805800",
          "orcid": "https://orcid.org/0000-0003-1690-9836",
          "institutions": [
            "University of Science and Technology of China"
          ]
        },
        {
          "name": "Houqiang Li",
          "openalex_id": "A5078141810",
          "orcid": "https://orcid.org/0000-0003-2188-3028",
          "institutions": [
            "University of Science and Technology of China"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-04-26",
      "abstract": "Hand gesture serves as a crucial role during the expression of sign language. Current deep learning based methods for sign language understanding (SLU) are prone to over-fitting due to insufficient sign data resource and suffer limited interpretability. In this paper, we propose the first self-supervised pre-trainable SignBERT+ framework with model-aware hand prior incorporated. In our framework, the hand pose is regarded as a visual token, which is derived from an off-the-shelf detector. Each visual token is embedded with gesture state and spatial-temporal position encoding. To take full advantage of current sign data resource, we first perform self-supervised learning to model its statistics. To this end, we design multi-level masked modeling strategies (joint, frame and clip) to mimic common failure detection cases. Jointly with these masked modeling strategies, we incorporate model-aware hand prior to better capture hierarchical context over the sequence. After the pre-training, we carefully design simple yet effective prediction heads for downstream tasks. To validate the effectiveness of our framework, we perform extensive experiments on three main SLU tasks, involving isolated and continuous sign language recognition (SLR), and sign language translation (SLT). Experimental results demonstrate the effectiveness of our method, achieving new state-of-the-art performance with a notable gain.",
      "cited_by_count": 95,
      "type": "article",
      "source": {
        "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "type": "journal",
        "issn": [
          "0162-8828",
          "1939-3539",
          "2160-9292"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2305.04868"
      },
      "topics": [
        "Hand Gesture Recognition Systems",
        "Human Pose and Action Recognition",
        "Hearing Impairment and Communication"
      ],
      "referenced_works_count": 137,
      "url": "https://openalex.org/W4367047590"
    },
    {
      "openalex_id": "W4385571244",
      "doi": "10.18653/v1/2023.acl-short.70",
      "title": "Counterfactual reasoning: Testing language models\u2019 understanding of hypothetical scenarios",
      "authors": [
        {
          "name": "Jiaxuan Li",
          "openalex_id": "A5100333831",
          "orcid": "https://orcid.org/0000-0002-3766-0876",
          "institutions": [
            "University of California, Irvine"
          ]
        },
        {
          "name": "Lang Yu",
          "openalex_id": "A5100562361",
          "institutions": [
            "Seattle University"
          ]
        },
        {
          "name": "Allyson Ettinger",
          "openalex_id": "A5012068726",
          "institutions": [
            "Seattle University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge\u2014however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nuances of counterfactuals, we find that only GPT-3 shows sensitivity to these nuances, though this sensitivity is also non-trivially impacted by lexical associative factors.",
      "cited_by_count": 6,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2023.acl-short.70.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Language and cultural evolution"
      ],
      "referenced_works_count": 16,
      "url": "https://openalex.org/W4385571244"
    },
    {
      "openalex_id": "W4404205059",
      "doi": "10.36227/techrxiv.173121393.30482183/v1",
      "title": "Sorry, I am an AI Language Model: Understanding the Limitations of ChatGPT",
      "authors": [
        {
          "name": "Nitin Naik",
          "openalex_id": "A5089628794",
          "orcid": "https://orcid.org/0000-0002-0659-9646",
          "institutions": [
            "Aston University"
          ]
        },
        {
          "name": "Dishita Naik",
          "openalex_id": "A5108365537",
          "institutions": [
            "Birmingham City University"
          ]
        },
        {
          "name": "Ishita Naik",
          "openalex_id": "A5070738296",
          "institutions": [
            "King Edward VII Hospital"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-11-10",
      "abstract": null,
      "cited_by_count": 8,
      "type": "preprint",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.173121393.30482183"
      },
      "topics": [
        "Artificial Intelligence in Healthcare and Education",
        "COVID-19 diagnosis using AI",
        "Machine Learning in Healthcare"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4404205059"
    },
    {
      "openalex_id": "W4386185600",
      "doi": "10.48550/arxiv.2308.12966",
      "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
      "authors": [
        {
          "name": "Jinze Bai",
          "openalex_id": "A5063334231"
        },
        {
          "name": "Shuai Bai",
          "openalex_id": "A5101014470",
          "orcid": "https://orcid.org/0000-0002-6896-8590"
        },
        {
          "name": "Shusheng Yang",
          "openalex_id": "A5004788654"
        },
        {
          "name": "Shijie Wang",
          "openalex_id": "A5100374850",
          "orcid": "https://orcid.org/0000-0002-7990-4883"
        },
        {
          "name": "Sinan Tan",
          "openalex_id": "A5008661936",
          "orcid": "https://orcid.org/0000-0003-2035-2479"
        },
        {
          "name": "Peng Wang",
          "openalex_id": "A5100396097",
          "orcid": "https://orcid.org/0000-0002-9218-9132"
        },
        {
          "name": "Junyang Lin",
          "openalex_id": "A5100612233",
          "orcid": "https://orcid.org/0000-0001-9931-383X"
        },
        {
          "name": "Chang Zhou",
          "openalex_id": "A5100613561",
          "orcid": "https://orcid.org/0000-0002-6029-1132"
        },
        {
          "name": "Jingren Zhou",
          "openalex_id": "A5057864403",
          "orcid": "https://orcid.org/0000-0002-4220-2634"
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-08-24",
      "abstract": "In this work, we introduce the Qwen-VL series, a set of large-scale vision-language models (LVLMs) designed to perceive and understand both texts and images. Starting from the Qwen-LM as a foundation, we endow it with visual capacity by the meticulously designed (i) visual receptor, (ii) input-output interface, (iii) 3-stage training pipeline, and (iv) multilingual multimodal cleaned corpus. Beyond the conventional image description and question-answering, we implement the grounding and text-reading ability of Qwen-VLs by aligning image-caption-box tuples. The resulting models, including Qwen-VL and Qwen-VL-Chat, set new records for generalist models under similar model scales on a broad range of visual-centric benchmarks (e.g., image captioning, question answering, visual grounding) and different settings (e.g., zero-shot, few-shot). Moreover, on real-world dialog benchmarks, our instruction-tuned Qwen-VL-Chat also demonstrates superiority compared to existing vision-language chatbots. Code, demo and models are available at https://github.com/QwenLM/Qwen-VL.",
      "cited_by_count": 129,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2308.12966"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Topic Modeling",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4386185600"
    },
    {
      "openalex_id": "W2907492528",
      "doi": "10.1109/tnnls.2020.2978386",
      "title": "A Comprehensive Survey on Graph Neural Networks",
      "authors": [
        {
          "name": "Zonghan Wu",
          "openalex_id": "",
          "orcid": "https://orcid.org/0000-0003-4450-7738",
          "institutions": [
            "University of Technology Sydney"
          ]
        },
        {
          "name": "Shirui Pan",
          "openalex_id": "",
          "orcid": "https://orcid.org/",
          "institutions": [
            "Monash University"
          ]
        },
        {
          "name": "Fengwen Chen",
          "openalex_id": "",
          "institutions": [
            "University of Technology Sydney"
          ]
        },
        {
          "name": "Guodong Long",
          "openalex_id": "",
          "orcid": "https://orcid.org/0000-0003-3740-9515",
          "institutions": [
            "University of Technology Sydney"
          ]
        },
        {
          "name": "Chengqi Zhang",
          "openalex_id": "",
          "orcid": "https://orcid.org/0000-0001-5715-7154",
          "institutions": [
            "University of Technology Sydney"
          ]
        },
        {
          "name": "Philip S. Yu",
          "openalex_id": "",
          "institutions": [
            "University of Illinois Chicago"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-03-24",
      "abstract": "Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.",
      "cited_by_count": 8036,
      "type": "article",
      "source": {
        "name": "IEEE Transactions on Neural Networks and Learning Systems",
        "type": "journal",
        "issn": [
          "2162-237X",
          "2162-2388"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/1901.00596"
      },
      "topics": [
        "Advanced Graph Neural Networks",
        "Graph Theory and Algorithms",
        "Brain Tumor Detection and Classification"
      ],
      "referenced_works_count": 167,
      "url": "https://openalex.org/W2907492528"
    },
    {
      "openalex_id": "W4389574762",
      "doi": "10.1088/1361-6404/ad1420",
      "title": "How understanding large language models can inform the use of ChatGPT in physics education",
      "authors": [
        {
          "name": "Giulia Polverini",
          "openalex_id": "A5092926042",
          "orcid": "https://orcid.org/0000-0001-9280-4329",
          "institutions": [
            "Uppsala University"
          ]
        },
        {
          "name": "Bor Gregorcic",
          "openalex_id": "A5062907082",
          "orcid": "https://orcid.org/0000-0002-9185-628X",
          "institutions": [
            "Uppsala University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-12-11",
      "abstract": "Abstract The paper aims to fulfil three main functions: (1) to serve as an introduction for the physics education community to the functioning of large language models (LLMs), (2) to present a series of illustrative examples demonstrating how prompt-engineering techniques can impact LLMs performance on conceptual physics tasks and (3) to discuss potential implications of the understanding of LLMs and prompt engineering for physics teaching and learning. We first summarise existing research on the performance of a popular LLM-based chatbot (ChatGPT) on physics tasks. We then give a basic account of how LLMs work, illustrate essential features of their functioning, and discuss their strengths and limitations. Equipped with this knowledge, we discuss some challenges with generating useful output with ChatGPT-4 in the context of introductory physics, paying special attention to conceptual questions and problems. We then provide a condensed overview of relevant literature on prompt engineering and demonstrate through illustrative examples how selected prompt-engineering techniques can be employed to improve ChatGPT-4 \u2019s output on conceptual introductory physics problems. Qualitatively studying these examples provides additional insights into ChatGPT\u2019s functioning and its utility in physics problem-solving. Finally, we consider how insights from the paper can inform the use of LLMs in the teaching and learning of physics.",
      "cited_by_count": 81,
      "type": "article",
      "source": {
        "name": "European Journal of Physics",
        "type": "journal",
        "issn": [
          "0143-0807",
          "1361-6404"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://iopscience.iop.org/article/10.1088/1361-6404/ad1420/pdf"
      },
      "topics": [
        "Topic Modeling",
        "Online Learning and Analytics",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "referenced_works_count": 116,
      "url": "https://openalex.org/W4389574762"
    },
    {
      "openalex_id": "W4390722831",
      "doi": "10.1145/3610977.3634966",
      "title": "Understanding Large-Language Model (LLM)-powered Human-Robot Interaction",
      "authors": [
        {
          "name": "Callie Y. Kim",
          "openalex_id": "A5008142086",
          "orcid": "https://orcid.org/0009-0001-4195-8317",
          "institutions": [
            "University of Wisconsin\u2013Madison"
          ]
        },
        {
          "name": "Christine P. Lee",
          "openalex_id": "A5057025083",
          "orcid": "https://orcid.org/0000-0003-0991-8072",
          "institutions": [
            "University of Wisconsin\u2013Madison"
          ]
        },
        {
          "name": "Bilge Mutlu",
          "openalex_id": "A5017344436",
          "orcid": "https://orcid.org/0000-0002-9456-1495",
          "institutions": [
            "University of Wisconsin\u2013Madison"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-03-10",
      "abstract": "Large-language models (LLMs) hold significant promise in improving\\nhuman-robot interaction, offering advanced conversational skills and\\nversatility in managing diverse, open-ended user requests in various tasks and\\ndomains. Despite the potential to transform human-robot interaction, very\\nlittle is known about the distinctive design requirements for utilizing LLMs in\\nrobots, which may differ from text and voice interaction and vary by task and\\ncontext. To better understand these requirements, we conducted a user study (n\\n= 32) comparing an LLM-powered social robot against text- and voice-based\\nagents, analyzing task-based requirements in conversational tasks, including\\nchoose, generate, execute, and negotiate. Our findings show that LLM-powered\\nrobots elevate expectations for sophisticated non-verbal cues and excel in\\nconnection-building and deliberation, but fall short in logical communication\\nand may induce anxiety. We provide design implications both for robots\\nintegrating LLMs and for fine-tuning LLMs for use with robots.\\n",
      "cited_by_count": 88,
      "type": "preprint",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3610977.3634966"
      },
      "topics": [
        "Social Robot Interaction and HRI",
        "AI in Service Interactions",
        "Speech and dialogue systems"
      ],
      "referenced_works_count": 78,
      "url": "https://openalex.org/W4390722831"
    },
    {
      "openalex_id": "W4391828195",
      "doi": "10.1145/3635059.3635104",
      "title": "Large Language Models versus Natural Language Understanding and Generation",
      "authors": [
        {
          "name": "Nikitas \u039d. Karanikolas",
          "openalex_id": "A5081787499",
          "orcid": "https://orcid.org/0000-0003-1777-892X",
          "institutions": [
            "University of West Attica"
          ]
        },
        {
          "name": "Eirini Manga",
          "openalex_id": "A5018070314",
          "orcid": "https://orcid.org/0000-0002-3477-6275",
          "institutions": [
            "University of West Attica"
          ]
        },
        {
          "name": "Nikoletta E. Samaridi",
          "openalex_id": "A5056277282",
          "orcid": "https://orcid.org/0000-0001-9799-2197",
          "institutions": [
            "University of West Attica"
          ]
        },
        {
          "name": "Eleni Tousidou",
          "openalex_id": "A5073445782",
          "orcid": "https://orcid.org/0000-0002-1581-0642",
          "institutions": [
            "University of Thessaly"
          ]
        },
        {
          "name": "Michael Vassilakopoulos",
          "openalex_id": "A5046792635",
          "orcid": "https://orcid.org/0000-0003-2256-5523",
          "institutions": [
            "University of Thessaly"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-11-24",
      "abstract": "In recent years, the process humans adopt to learn a foreign language has moved from the strict \"Grammar \u2013Translation\" method, which is based mainly on grammar and syntax rules, to more innovative processes, resulting to the more modern \"Communicative approach\". As its name states, this approach focuses on the coherent communication with native speakers and the cultivation of oral skills, without taking into consideration, at least at the first stages, the rules that govern the language.",
      "cited_by_count": 58,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3635059.3635104"
      },
      "topics": [
        "Speech and dialogue systems",
        "Natural Language Processing Techniques",
        "Topic Modeling"
      ],
      "referenced_works_count": 54,
      "url": "https://openalex.org/W4391828195"
    },
    {
      "openalex_id": "W3161374759",
      "doi": "10.18653/v1/2021.naacl-main.102",
      "title": "Understanding by Understanding Not: Modeling Negation in Language Models",
      "authors": [
        {
          "name": "Arian Hosseini",
          "openalex_id": "A5088377167",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al",
            "Microsoft Research Montr\u00e9al (Canada)",
            "McGill University",
            "Microsoft (Canada)"
          ]
        },
        {
          "name": "Siva Reddy",
          "openalex_id": "A5102886212",
          "institutions": [
            "Microsoft Research Montr\u00e9al (Canada)",
            "Universit\u00e9 de Montr\u00e9al",
            "Microsoft (Canada)",
            "McGill University"
          ]
        },
        {
          "name": "Dzmitry Bahdanau",
          "openalex_id": "A5010465328",
          "institutions": [
            "Universit\u00e9 de Montr\u00e9al",
            "McGill University",
            "Microsoft (Canada)",
            "Microsoft Research Montr\u00e9al (Canada)"
          ]
        },
        {
          "name": "R Devon Hjelm",
          "openalex_id": "A5074900697",
          "institutions": [
            "Microsoft Research Montr\u00e9al (Canada)",
            "McGill University",
            "Microsoft (Canada)",
            "Universit\u00e9 de Montr\u00e9al"
          ]
        },
        {
          "name": "Alessandro Sordoni",
          "openalex_id": "A5108137151",
          "institutions": [
            "Microsoft Research Montr\u00e9al (Canada)",
            "Universit\u00e9 de Montr\u00e9al",
            "McGill University",
            "Microsoft (Canada)"
          ]
        },
        {
          "name": "Aaron Courville",
          "openalex_id": "A5112608251",
          "orcid": "https://orcid.org/0000-0001-6223-0301",
          "institutions": [
            "McGill University",
            "Universit\u00e9 de Montr\u00e9al",
            "Microsoft Research Montr\u00e9al (Canada)",
            "Microsoft (Canada)"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-01-01",
      "abstract": "Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R Devon Hjelm, Alessandro Sordoni, Aaron Courville. Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.",
      "cited_by_count": 40,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2021.naacl-main.102.pdf"
      },
      "topics": [
        "Natural Language Processing Techniques",
        "Topic Modeling",
        "Text Readability and Simplification"
      ],
      "referenced_works_count": 43,
      "url": "https://openalex.org/W3161374759"
    },
    {
      "openalex_id": "W4392384758",
      "doi": "10.1145/3616855.3635772",
      "title": "K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization",
      "authors": [
        {
          "name": "Cheng Deng",
          "openalex_id": "A5059632585",
          "orcid": "https://orcid.org/0000-0002-3171-823X",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Tianhang Zhang",
          "openalex_id": "A5102019907",
          "orcid": "https://orcid.org/0009-0006-6234-4409",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Zhongmou He",
          "openalex_id": "A5033329145",
          "orcid": "https://orcid.org/0000-0002-5863-5370",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Q L Chen",
          "openalex_id": "A5085297651",
          "orcid": "https://orcid.org/0009-0008-7349-4546",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Yuanyuan Shi",
          "openalex_id": "A5039873723",
          "orcid": "https://orcid.org/0009-0001-0791-015X",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Yi Xu",
          "openalex_id": "A5101848162",
          "orcid": "https://orcid.org/0000-0002-5280-6132",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Luoyi Fu",
          "openalex_id": "A5048486573",
          "orcid": "https://orcid.org/0000-0001-7796-9168",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Weinan Zhang",
          "openalex_id": "A5090720315",
          "orcid": "https://orcid.org/0000-0002-0127-2425",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Xinbing Wang",
          "openalex_id": "A5034483183",
          "orcid": "https://orcid.org/0000-0002-0357-8356",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Chenghu Zhou",
          "openalex_id": "A5023919188",
          "orcid": "https://orcid.org/0000-0003-3331-2302",
          "institutions": [
            "Shanghai Jiao Tong University",
            "Institute of Geographic Sciences and Natural Resources Research"
          ]
        },
        {
          "name": "Zhouhan Lin",
          "openalex_id": "A5024900991",
          "orcid": "https://orcid.org/0009-0009-7204-0689",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        },
        {
          "name": "Junxian He",
          "openalex_id": "A5015879697",
          "orcid": "https://orcid.org/0009-0007-9559-6941",
          "institutions": [
            "Shanghai Jiao Tong University"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-03-04",
      "abstract": "Large language models (LLMs) have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pre-trained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1 million pieces of geoscience literature, and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can efficiently gather domain-specific data and construct domain-supervised data, even in situations where manpower is scarce. Meanwhile, we equip K2 with the abilities of using tools to be a naive geoscience aide. Experiments conducted on the GeoBench demonstrate the effectiveness of our approach and datasets on geoscience knowledge understanding and utilization.We open-source all the training data and K2 model checkpoints at https://github.com/davendw49/k2",
      "cited_by_count": 56,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Geological Modeling and Analysis"
      ],
      "referenced_works_count": 12,
      "url": "https://openalex.org/W4392384758"
    },
    {
      "openalex_id": "W4387892136",
      "doi": "10.48550/arxiv.2310.13548",
      "title": "Towards Understanding Sycophancy in Language Models",
      "authors": [
        {
          "name": "Mrinank Sharma",
          "openalex_id": "A5003223014",
          "orcid": "https://orcid.org/0000-0002-4304-7963",
          "institutions": [
            "Gesellschaft f\u00fcr Fertigungstechnik und Entwicklung",
            "Technology Holding (United States)"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-10-20",
      "abstract": "Human feedback is commonly utilized to finetune AI assistants. But human feedback may also encourage model responses that match user beliefs over truthful ones, a behaviour known as sycophancy. We investigate the prevalence of sycophancy in models whose finetuning procedure made use of human feedback, and the potential role of human preference judgments in such behavior. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophancy across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a non-negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of state-of-the-art AI assistants, likely driven in part by human preference judgments favoring sycophantic responses.",
      "cited_by_count": 53,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2310.13548"
      },
      "topics": [
        "Topic Modeling",
        "Explainable Artificial Intelligence (XAI)",
        "Reinforcement Learning in Robotics"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4387892136"
    },
    {
      "openalex_id": "W4386083024",
      "doi": "10.1109/cvpr52729.2023.02214",
      "title": "LAVENDER: Unifying Video-Language Understanding as Masked Language Modeling",
      "authors": [
        {
          "name": "Linjie Li",
          "openalex_id": "A5100657555",
          "orcid": "https://orcid.org/0000-0003-0867-8863",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Zhe Gan",
          "openalex_id": "A5066666034",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Kevin Lin",
          "openalex_id": "A5074764224",
          "orcid": "https://orcid.org/0000-0002-1236-9847",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Chung-Ching Lin",
          "openalex_id": "A5065235694",
          "orcid": "https://orcid.org/0000-0003-3296-9062",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Zicheng Liu",
          "openalex_id": "A5101728117",
          "orcid": "https://orcid.org/0000-0001-5894-7828",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Ce Liu",
          "openalex_id": "A5101758608",
          "orcid": "https://orcid.org/0009-0002-3686-9237",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        },
        {
          "name": "Lijuan Wang",
          "openalex_id": "A5100436501",
          "orcid": "https://orcid.org/0000-0002-2517-2728",
          "institutions": [
            "Microsoft Research (United Kingdom)"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-06-01",
      "abstract": "Unified vision-language frameworks have greatly advanced in recent years, most of which adopt an encoder-decoder architecture to unify image-text tasks as sequence-to-sequence generation. However, existing video-language (VidL) models still require task-specific designs in model architecture and training objectives for each task. In this work, we explore a unified VidL framework LAVENDER, where Masked Language Modeling [13] (MLM) is used as the common interface for all pre-training and downstream tasks. Such unification leads to a simplified model architecture, where only a lightweight MLM head, instead of a decoder with much more parameters, is needed on top of the multimodal encoder. Surprisingly, experimental results show that this unified framework achieves competitive performance on 14 VidL benchmarks, covering video question answering, text-to-video retrieval and video captioning. Extensive analyses further demonstrate Lavender can (i) seamlessly support all downstream tasks with just a single set of parameter values when multi-task fine-tuned; (ii) generalize to various downstream tasks with limited training samples; and (iii) enable zero-shot evaluation on video question answering tasks. Code is available at https://github.com/microsoft/LAVENDER.",
      "cited_by_count": 57,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Human Pose and Action Recognition",
        "Domain Adaptation and Few-Shot Learning"
      ],
      "referenced_works_count": 122,
      "url": "https://openalex.org/W4386083024"
    },
    {
      "openalex_id": "W4319599994",
      "doi": "10.3390/drones7020114",
      "title": "Semantic Scene Understanding with Large Language Models on Unmanned Aerial Vehicles",
      "authors": [
        {
          "name": "J. de Curt\u00f2",
          "openalex_id": "A5002158202",
          "orcid": "https://orcid.org/0000-0002-8334-4719",
          "institutions": [
            "Universitat Polit\u00e8cnica de Val\u00e8ncia",
            "Universitat Oberta de Catalunya",
            "Goethe University Frankfurt",
            "Hong Kong Science and Technology Parks Corporation"
          ]
        },
        {
          "name": "I. de Zarz\u00e0",
          "openalex_id": "A5066504412",
          "orcid": "https://orcid.org/0000-0002-5844-7871",
          "institutions": [
            "Hong Kong Science and Technology Parks Corporation",
            "Goethe University Frankfurt",
            "Universitat Polit\u00e8cnica de Val\u00e8ncia",
            "Universitat Oberta de Catalunya"
          ]
        },
        {
          "name": "Carlos T. Calafate",
          "openalex_id": "A5066242048",
          "orcid": "https://orcid.org/0000-0001-5729-3041",
          "institutions": [
            "Universitat Polit\u00e8cnica de Val\u00e8ncia"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-02-08",
      "abstract": "Unmanned Aerial Vehicles (UAVs) are able to provide instantaneous visual cues and a high-level data throughput that could be further leveraged to address complex tasks, such as semantically rich scene understanding. In this work, we built on the use of Large Language Models (LLMs) and Visual Language Models (VLMs), together with a state-of-the-art detection pipeline, to provide thorough zero-shot UAV scene literary text descriptions. The generated texts achieve a GUNNING Fog median grade level in the range of 7\u201312. Applications of this framework could be found in the filming industry and could enhance user experience in theme parks or in the advertisement sector. We demonstrate a low-cost highly efficient state-of-the-art practical implementation of microdrones in a well-controlled and challenging setting, in addition to proposing the use of standardized readability metrics to assess LLM-enhanced descriptions.",
      "cited_by_count": 57,
      "type": "article",
      "source": {
        "name": "Drones",
        "type": "journal",
        "issn": [
          "2504-446X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.mdpi.com/2504-446X/7/2/114/pdf?version=1675837513"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Domain Adaptation and Few-Shot Learning",
        "Human Pose and Action Recognition"
      ],
      "referenced_works_count": 22,
      "url": "https://openalex.org/W4319599994"
    },
    {
      "openalex_id": "W3176481196",
      "doi": "10.18653/v1/2021.findings-acl.370",
      "title": "VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding",
      "authors": [
        {
          "name": "Hu Xu",
          "openalex_id": "A5101230845",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Gargi Ghosh",
          "openalex_id": "A5024230879",
          "orcid": "https://orcid.org/0000-0003-1328-2425",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Po-Yao Huang",
          "openalex_id": "A5063149046",
          "orcid": "https://orcid.org/0000-0002-3319-5145",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Prahal Arora",
          "openalex_id": "A5080488188",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Masoumeh Aminzadeh",
          "openalex_id": "A5084792905",
          "orcid": "https://orcid.org/0000-0003-2853-0356",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Christoph Feichtenhofer",
          "openalex_id": "A5036069974",
          "orcid": "https://orcid.org/0000-0001-9756-7238",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Florian Metze",
          "openalex_id": "A5085262529",
          "orcid": "https://orcid.org/0000-0002-6663-8600",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Luke Zettlemoyer",
          "openalex_id": "A5067919401",
          "orcid": "https://orcid.org/0009-0008-8296-0764",
          "institutions": [
            "Carnegie Mellon University"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-01-01",
      "abstract": "Hu Xu, Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph Feichtenhofer, Florian Metze, Luke Zettlemoyer. Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. 2021.",
      "cited_by_count": 84,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2021.findings-acl.370.pdf"
      },
      "topics": [
        "Multimodal Machine Learning Applications",
        "Human Pose and Action Recognition",
        "Topic Modeling"
      ],
      "referenced_works_count": 47,
      "url": "https://openalex.org/W3176481196"
    },
    {
      "openalex_id": "W4385571325",
      "doi": "10.18653/v1/2023.acl-long.230",
      "title": "A fine-grained comparison of pragmatic language understanding in humans and language models",
      "authors": [
        {
          "name": "Jennifer J. Hu",
          "openalex_id": "A5067533298",
          "orcid": "https://orcid.org/0000-0002-0021-5699",
          "institutions": [
            "Massachusetts Institute of Technology",
            "Institute of Cognitive and Brain Sciences"
          ]
        },
        {
          "name": "Sammy Floyd",
          "openalex_id": "A5032945435",
          "orcid": "https://orcid.org/0000-0003-2011-9191",
          "institutions": [
            "Massachusetts Institute of Technology",
            "Sarah Lawrence College",
            "Institute of Cognitive and Brain Sciences"
          ]
        },
        {
          "name": "Olessia Jouravlev",
          "openalex_id": "A5074950287",
          "orcid": "https://orcid.org/0000-0001-6449-9419",
          "institutions": [
            "Carleton University"
          ]
        },
        {
          "name": "Evelina Fedorenko",
          "openalex_id": "A5081808595",
          "orcid": "https://orcid.org/0000-0003-3823-514X",
          "institutions": [
            "Massachusetts Institute of Technology",
            "McGovern Institute for Brain Research",
            "Institute of Cognitive and Brain Sciences"
          ]
        },
        {
          "name": "Edward Gibson",
          "openalex_id": "A5021445004",
          "orcid": "https://orcid.org/0000-0002-5912-883X",
          "institutions": [
            "Massachusetts Institute of Technology",
            "Institute of Cognitive and Brain Sciences"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "Pragmatics and non-literal language understanding are essential to human communication, and present a long-standing challenge for artificial language models. We perform a fine-grained comparison of language models and humans on seven pragmatic phenomena, using zero-shot prompting on an expert-curated set of English materials. We ask whether models (1) select pragmatic interpretations of speaker utterances, (2) make similar error patterns as humans, and (3) use similar linguistic cues as humans to solve the tasks. We find that the largest models achieve high accuracy and match human error patterns: within incorrect responses, models favor literal interpretations over heuristic-based distractors. We also find preliminary evidence that models and humans are sensitive to similar linguistic cues. Our results suggest that pragmatic behaviors can emerge in models without explicitly constructed representations of mental states. However, models tend to struggle with phenomena relying on social expectation violations.",
      "cited_by_count": 40,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://aclanthology.org/2023.acl-long.230.pdf"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Speech and dialogue systems"
      ],
      "referenced_works_count": 86,
      "url": "https://openalex.org/W4385571325"
    },
    {
      "openalex_id": "W4390043316",
      "doi": "10.1145/3596490",
      "title": "Shortcut Learning of Large Language Models in Natural Language Understanding",
      "authors": [
        {
          "name": "Mengnan Du",
          "openalex_id": "A5072191151",
          "orcid": "https://orcid.org/0000-0002-1614-6069",
          "institutions": [
            "New Jersey Institute of Technology"
          ]
        },
        {
          "name": "Fengxiang He",
          "openalex_id": "A5100635369",
          "orcid": "https://orcid.org/0000-0001-5584-2385",
          "institutions": [
            "University of Edinburgh"
          ]
        },
        {
          "name": "Na Zou",
          "openalex_id": "A5084497683",
          "orcid": "https://orcid.org/0000-0003-1984-795X",
          "institutions": [
            "Texas A&M University"
          ]
        },
        {
          "name": "Dacheng Tao",
          "openalex_id": "A5074103823",
          "orcid": "https://orcid.org/0000-0001-7225-5449",
          "institutions": [
            "University of Sydney"
          ]
        },
        {
          "name": "Xia Hu",
          "openalex_id": "A5068477431",
          "orcid": "https://orcid.org/0000-0003-2234-3226",
          "institutions": [
            "Rice University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-12-21",
      "abstract": "Shortcuts often hinder the robustness of large language models.",
      "cited_by_count": 51,
      "type": "article",
      "source": {
        "name": "Communications of the ACM",
        "type": "journal",
        "issn": [
          "0001-0782",
          "1557-7317"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "bronze",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3596490"
      },
      "topics": [
        "Topic Modeling",
        "Natural Language Processing Techniques",
        "Multimodal Machine Learning Applications"
      ],
      "referenced_works_count": 40,
      "url": "https://openalex.org/W4390043316"
    },
    {
      "openalex_id": "W3161223924",
      "doi": "10.1109/icassp39728.2021.9414922",
      "title": "Semi-Supervised Spoken Language Understanding via Self-Supervised Speech and Language Model Pretraining",
      "authors": [
        {
          "name": "Cheng-I Lai",
          "openalex_id": "A5010825170",
          "orcid": "https://orcid.org/0000-0002-2343-8596"
        },
        {
          "name": "Yung-Sung Chuang",
          "openalex_id": "A5058729228",
          "orcid": "https://orcid.org/0000-0002-1723-5063",
          "institutions": [
            "National Taiwan University"
          ]
        },
        {
          "name": "Hung-yi Lee",
          "openalex_id": "A5040508737",
          "orcid": "https://orcid.org/0000-0002-9654-5747",
          "institutions": [
            "National Taiwan University"
          ]
        },
        {
          "name": "Shang-Wen Li",
          "openalex_id": "A5029566548",
          "orcid": "https://orcid.org/0000-0003-0656-9874",
          "institutions": [
            "Amazon (United States)"
          ]
        },
        {
          "name": "James Glass",
          "openalex_id": "A5112758056",
          "orcid": "https://orcid.org/0000-0002-3097-360X"
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-05-13",
      "abstract": "Much recent work on Spoken Language Understanding (SLU) is limited in at least one of three ways: models were trained on oracle text input and neglected ASR errors, models were trained to predict only intents without the slot values, or models were trained on a large amount of in-house data. In this paper, we propose a clean and general framework to learn semantics directly from speech with semi-supervision from transcribed or untranscribed speech to address these issues. Our framework is built upon pretrained end-to-end (E2E) ASR and self-supervised language models, such as BERT, and fine-tuned on a limited amount of target SLU data. We study two semi-supervised settings for the ASR component: supervised pretraining on transcribed speech, and unsupervised pretraining by replacing the ASR encoder with self-supervised speech representations, such as wav2vec. In parallel, we identify two essential criteria for evaluating SLU models: environmental noise-robustness and E2E semantics evaluation. Experiments on ATIS show that our SLU framework with speech as input can perform on par with those using oracle text as input in semantics understanding, even though environmental noise is present and a limited amount of labeled semantics data is available for training.",
      "cited_by_count": 51,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Topic Modeling",
        "Speech Recognition and Synthesis",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 48,
      "url": "https://openalex.org/W3161223924"
    }
  ],
  "count": 40,
  "errors": []
}
