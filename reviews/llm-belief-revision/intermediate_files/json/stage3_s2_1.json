{
  "status": "success",
  "source": "semantic_scholar",
  "query": "LLM cognition understanding",
  "results": [
    {
      "paperId": "8cf3233a41b8519bca7dfdfa9f50ae2883266a2a",
      "title": "Going Whole Hog: A Philosophical Defense of AI Cognition",
      "authors": [
        {
          "name": "H. Cappelen",
          "authorId": "2944535"
        },
        {
          "name": "J. Dever",
          "authorId": "2300117"
        }
      ],
      "year": 2025,
      "abstract": "This work defends the 'Whole Hog Thesis': sophisticated Large Language Models (LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing understanding, beliefs, desires, knowledge, and intentions. We argue against prevailing methodologies in AI philosophy, rejecting starting points based on low-level computational details ('Just an X' fallacy) or pre-existing theories of mind. Instead, we advocate starting with simple, high-level observations of LLM behavior (e.g., answering questions, making suggestions) -- defending this data against charges of metaphor, loose talk, or pretense. From these observations, we employ 'Holistic Network Assumptions' -- plausible connections between mental capacities (e.g., answering implies knowledge, knowledge implies belief, action implies intention) -- to argue for the full suite of cognitive states. We systematically rebut objections based on LLM failures (hallucinations, planning/reasoning errors), arguing these don't preclude agency, often mirroring human fallibility. We address numerous 'Games of Lacks', arguing that LLMs do not lack purported necessary conditions for cognition (e.g., semantic grounding, embodiment, justification, intrinsic intentionality) or that these conditions are not truly necessary, often relying on anti-discriminatory arguments comparing LLMs to diverse human capacities. Our approach is evidential, not functionalist, and deliberately excludes consciousness. We conclude by speculating on the possibility of LLMs possessing 'alien' contents beyond human conceptual schemes.",
      "citationCount": 5,
      "doi": "10.48550/arXiv.2504.13988",
      "arxivId": "2504.13988",
      "url": "https://www.semanticscholar.org/paper/8cf3233a41b8519bca7dfdfa9f50ae2883266a2a",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2504.13988"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "8e53bdd4f204aed92a09bd2fed535d0d1a6e728c",
      "title": "Disembodied Meaning? Generative AI and Understanding",
      "authors": [
        {
          "name": "Jordi Vallverd\u00fa",
          "authorId": "2351123536"
        },
        {
          "name": "Iv\u00e1n Redondo",
          "authorId": "2351129215"
        }
      ],
      "year": 2025,
      "abstract": "This study explores the cognitive and philosophical implications of Large Language Models (LLMs), focusing on their ability to generate meaning without embodiment. Grounded in the coherence-based semantics framework, the research challenges traditional views that emphasize the necessity of embodied cognition for meaningful language comprehension. Through a theoretical and comparative analysis, this paper examines the limitations of embodied cognition paradigms, such as the symbol grounding problem and critiques like Searle\u2019s Chinese Room, and evaluates the practical capabilities of LLMs. The methodology integrates philosophical inquiry with empirical evidence, including case studies on LLM performance in tasks such as medical licensing exams, multilingual communication, and policymaking. Key findings suggest that LLMs simulate meaning-making processes by leveraging statistical patterns and relational coherence within language, demonstrating a form of operational understanding that rivals some aspects of human cognition. Ethical concerns, such as biases in training data and societal implications of LLM applications, are also analyzed, with recommendations for improving fairness and transparency. By reframing LLMs as disembodied yet effective cognitive systems, this study contributes to ongoing debates in artificial intelligence and cognitive science. It highlights their potential to complement human cognition in education, policymaking, and other fields while advocating for responsible deployment to mitigate ethical risks.",
      "citationCount": 2,
      "doi": "10.30564/fls.v7i3.8060",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/8e53bdd4f204aed92a09bd2fed535d0d1a6e728c",
      "venue": "Forum for Linguistic Studies",
      "journal": {
        "name": "Forum for Linguistic Studies"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "1dcf42fd384734b6232006cd9bab276625aa3ebe",
      "title": "Representation in large language models",
      "authors": [
        {
          "name": "Cameron C. Yetman",
          "authorId": "2338269498"
        }
      ],
      "year": 2025,
      "abstract": "The extraordinary success of recent Large Language Models (LLMs) on a diverse array of tasks has led to an explosion of scientific and philosophical theorizing aimed at explaining how they do what they do. Unfortunately, disagreement over fundamental theoretical issues has led to stalemate, with entrenched camps of LLM optimists and pessimists often committed to very different views of how these systems work. Overcoming stalemate requires agreement on fundamental questions, and the goal of this paper is to address one such question, namely: is LLM behavior driven partly by representation-based information processing of the sort implicated in biological cognition, or is it driven entirely by processes of memorization and stochastic table look-up? This is a question about what kind of algorithm LLMs implement, and the answer carries serious implications for higher level questions about whether these systems have beliefs, intentions, concepts, knowledge, and understanding. I argue that LLM behavior is partially driven by representation-based information processing, and then I describe and defend a series of practical techniques for investigating these representations and developing explanations on their basis. The resulting account provides a groundwork for future theorizing about language models and their successors.",
      "citationCount": 3,
      "doi": "10.48550/arXiv.2501.00885",
      "arxivId": "2501.00885",
      "url": "https://www.semanticscholar.org/paper/1dcf42fd384734b6232006cd9bab276625aa3ebe",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2501.00885"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "f872b16ebab7b9a23c09dbd73c71fe1c69621a30",
      "title": "Pratiche visive e immaginazione algoritmica/ Visual Practices and Algorithmic Imagination",
      "authors": [
        {
          "name": "Massimo Balestrini",
          "authorId": "2395200848"
        }
      ],
      "year": 2025,
      "abstract": "This paper articulates a theoretical and methodological framework for understanding the visual apparatus of ViaggIAccademici as a locus of negotiation between human cognition and algorithmic generativity. Rather than treating generative AI as a merely operative tool, the study conceptualises prompting as a form of visual dramaturgy through which the theatrical text is reconfigured into a sequence of iconogenic units. The integration of LLM-mediated descriptions, hand-drawn studies and diffusion-based image synthesis reveals how artistic intentionality is modulated, refracted and at times destabilised by the latent structures governing machine-learning models. By incorporating a customised painterly dataset, the research examines stylistic drift, the epistemic status of the glitch and the emergence of visual indeterminacy as constitutive aesthetic conditions rather than technical contingencies. The resulting corpus of images and videos operates not as representational support but as a critical dispositif that expands the dramaturgical field, interrogating the boundaries between authorship, perception and algorithmic inference. The paper ultimately argues that contemporary artistic practice in the context of generative AI demands a shift toward a paradigm of co-emergent imagination, in which human and computational agencies converge to produce novel regimes of visual sense-making.",
      "citationCount": 0,
      "doi": "10.54103/2039-9251/30236",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f872b16ebab7b9a23c09dbd73c71fe1c69621a30",
      "venue": "Itinera",
      "journal": {
        "name": "Itinera"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "d4346af837aa6c2bb4a341cfe9bd91862ea5910a",
      "title": "Large Knowledge Model: Perspectives and Challenges",
      "authors": [
        {
          "name": "Huajun Chen",
          "authorId": "2269769030"
        }
      ],
      "year": 2023,
      "abstract": "Humankind's understanding of the world is fundamentally linked to our perception and cognition, with \\emph{human languages} serving as one of the major carriers of \\emph{world knowledge}. In this vein, \\emph{Large Language Models} (LLMs) like ChatGPT epitomize the pre-training of extensive, sequence-based world knowledge into neural networks, facilitating the processing and manipulation of this knowledge in a parametric space. This article explores large models through the lens of\"knowledge\". We initially investigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in enhancing LLMs, covering aspects like knowledge-augmented language model, structure-inducing pre-training, knowledgeable prompts, structured CoT, knowledge editing, semantic tools for LLM and knowledgeable AI agents. Subsequently, we examine how LLMs can boost traditional symbolic knowledge bases, encompassing aspects like using LLM as KG builder and controller, structured knowledge pretraining, and LLM-enhanced symbolic reasoning. Considering the intricate nature of human knowledge, we advocate for the creation of \\emph{Large Knowledge Models} (LKM), specifically engineered to manage diversified spectrum of knowledge structures. This promising undertaking would entail several key challenges, such as disentangling knowledge base from language models, cognitive alignment with human knowledge, integration of perception and cognition, and building large commonsense models for interacting with physical world, among others. We finally propose a five-\"A\"principle to distinguish the concept of LKM.",
      "citationCount": 22,
      "doi": "10.3724/2096-7004.di.2024.0001",
      "arxivId": "2312.02706",
      "url": "https://www.semanticscholar.org/paper/d4346af837aa6c2bb4a341cfe9bd91862ea5910a",
      "venue": "Data Intelligence",
      "journal": {
        "name": "Data Intell.",
        "pages": "587-620",
        "volume": "6"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "343237d6c825d4a6c36d77c4d0ef56dc440dc7c7",
      "title": "A rebuttal of two common deflationary stances against LLM cognition",
      "authors": [
        {
          "name": "Zak Hussain",
          "authorId": "2302450822"
        },
        {
          "name": "Rui Mata",
          "authorId": "2184033930"
        },
        {
          "name": "D. U. Wulff",
          "authorId": "2302732683"
        }
      ],
      "year": 2025,
      "abstract": ",",
      "citationCount": 2,
      "doi": "10.18653/v1/2025.findings-acl.1242",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/343237d6c825d4a6c36d77c4d0ef56dc440dc7c7",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "journal": {
        "pages": "24208-24213"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "aa81ad7b9eabe929a563f4da6ccdc0b5cc225cc8",
      "title": "A Survey on Socratic Meta-Cognition for LLM Truth Verification and related Frameworks",
      "authors": [
        {
          "name": "Pinaki Bose",
          "authorId": "2396143317"
        }
      ],
      "year": 2025,
      "abstract": "The proliferation of large language models (LLMs) across high-stakes domains necessitates a paradigm shift in how their truthfulness and reliability are assessed. This paper surveys the core challenges of LLM untruthfulness, specifically addressing the phenomena of hallucinations, pervasive bias, and the fundamental epistemological problem of a lack of a single ground truth. It proposes that Socratic metacognition\u2014an integrated approach combining the introspective self-regulation of metacognition with the critical, question-based inquiry of the Socratic method\u2014offers a robust solution. The report delineates the theoretical foundations of both human and computational metacognition, operationalizes the Socratic method for artificial intelligence (AI), and synthesizes existing architectural and conceptual frameworks. By examining models such as the Metacognitive Integrated Dual-Cycle Architecture (MIDCA) and the SocraticAI multi-agent system, a unified conceptual framework is proposed. This framework envisions a self-regulating system that uses a structured, question-based dialogue to identify and rectify its own logical inconsistencies and factual inaccuracies. The paper's contribution is a synthesis of disparate research fields, demonstrating a path toward building more reliable, transparent, and trustworthy LLMs that can navigate complex, ambiguous information spaces with a greater degree of verifiability.",
      "citationCount": 0,
      "doi": "10.71097/ijaidr.v16.i2.1577",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/aa81ad7b9eabe929a563f4da6ccdc0b5cc225cc8",
      "venue": "Journal of Advances in Developmental Research",
      "journal": {
        "name": "Journal of Advances in Developmental Research"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "712b0f08e3b535c0dd83b46256fa152c0a7a8d88",
      "title": "Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
      "authors": [
        {
          "name": "Lev Tankelevitch",
          "authorId": "2243304392"
        },
        {
          "name": "Elena L. Glassman",
          "authorId": "2257972100"
        },
        {
          "name": "Jessica He",
          "authorId": "2200904395"
        },
        {
          "name": "Majeed Kazemitabaar",
          "authorId": "3136345"
        },
        {
          "name": "A. Kittur",
          "authorId": "145234497"
        },
        {
          "name": "Mina Lee",
          "authorId": "2357271951"
        },
        {
          "name": "Srishti Palani",
          "authorId": "144358729"
        },
        {
          "name": "Advait Sarkar",
          "authorId": "2242912880"
        },
        {
          "name": "Gonzalo A. Ramos",
          "authorId": "2057749310"
        },
        {
          "name": "Yvonne Rogers",
          "authorId": "2105221115"
        },
        {
          "name": "Hariharan Subramonyam",
          "authorId": "2301051721"
        }
      ],
      "year": 2025,
      "abstract": "We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI.",
      "citationCount": 4,
      "doi": "10.1145/3706599.3706745",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/712b0f08e3b535c0dd83b46256fa152c0a7a8d88",
      "venue": "CHI Extended Abstracts",
      "journal": {
        "name": "Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book"
      ]
    },
    {
      "paperId": "5679475ee8b341a9d36bd13e6e76889cd6ed40a4",
      "title": "The multidimensional profile methodology (MPM) for comparative cognition: towards a universal strategy of understanding animal minds",
      "authors": [
        {
          "name": "L. Dung",
          "authorId": "2066549789"
        },
        {
          "name": "Albert Newen",
          "authorId": "2263978951"
        }
      ],
      "year": 2025,
      "abstract": null,
      "citationCount": 1,
      "doi": "10.1007/s11098-025-02363-3",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/5679475ee8b341a9d36bd13e6e76889cd6ed40a4",
      "venue": "Philosophical Studies",
      "journal": {
        "name": "Philosophical Studies"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "bcbfcfd8edf2a91047fa8625ddbc6c16326ce10a",
      "title": "Understanding, Protecting, and Augmenting Human Cognition with Generative AI: A Synthesis of the CHI 2025 Tools for Thought Workshop",
      "authors": [
        {
          "name": "Lev Tankelevitch",
          "authorId": "2243304392"
        },
        {
          "name": "Elena L. Glassman",
          "authorId": "2257972100"
        },
        {
          "name": "Jessica He",
          "authorId": "2377902244"
        },
        {
          "name": "A. Kittur",
          "authorId": "145234497"
        },
        {
          "name": "Mina Lee",
          "authorId": "2357271951"
        },
        {
          "name": "Srishti Palani",
          "authorId": "144358729"
        },
        {
          "name": "Advait Sarkar",
          "authorId": "2242912880"
        },
        {
          "name": "Gonzalo A. Ramos",
          "authorId": "2057749310"
        },
        {
          "name": "Yvonne Rogers",
          "authorId": "2377790894"
        },
        {
          "name": "Hari Subramonyam",
          "authorId": "2283933152"
        }
      ],
      "year": 2025,
      "abstract": "Generative AI (GenAI) radically expands the scope and capability of automation for work, education, and everyday tasks, a transformation posing both risks and opportunities for human cognition. How will human cognition change, and what opportunities are there for GenAI to augment it? Which theories, metrics, and other tools are needed to address these questions? The CHI 2025 workshop on Tools for Thought aimed to bridge an emerging science of how the use of GenAI affects human thought, from metacognition to critical thinking, memory, and creativity, with an emerging design practice for building GenAI tools that both protect and augment human thought. Fifty-six researchers, designers, and thinkers from across disciplines as well as industry and academia, along with 34 papers and portfolios, seeded a day of discussion, ideation, and community-building. We synthesize this material here to begin mapping the space of research and design opportunities and to catalyze a multidisciplinary community around this pressing area of research.",
      "citationCount": 1,
      "doi": "10.48550/arXiv.2508.21036",
      "arxivId": "2508.21036",
      "url": "https://www.semanticscholar.org/paper/bcbfcfd8edf2a91047fa8625ddbc6c16326ce10a",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2508.21036"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "f9af4d25d5c3cbcb546711d8ba477cef9aabdbb3",
      "title": "Reason, Understanding and Cognition in Religious Education in The Context of The Educational Value of Cognitive Processes",
      "authors": [
        {
          "name": "\u0130smail Demir",
          "authorId": "2337940687"
        }
      ],
      "year": 2025,
      "abstract": "This study examines the educational value of cognitive processes in religious education from a multidimensional perspective and aims to analyze how reasoning, understanding, and cognition-based approaches can be integrated into curricula. Focusing solely on the transmission of information in religious education limits students' intellectual, affective, and behavioral development, leading to superficial and temporary learning in the internalization of religious values. The importance of this research stems from its contribution to the restructuring of religious education by evaluating contemporary cognitive development theories alongside the approaches based on reason, wisdom, and contemplation in classical Islamic thought. Structured using a qualitative research design, this study deeply examines curricula, textbooks, learning outcomes, and methods through document analysis. Furthermore, the theoretical framework is built around a constructivist approach. Cognitive development approaches of theorists such as Piaget, Vygotsky, Bloom, Bruner, and Gardner are examined within the context of religious education, and the pedagogical contributions of methods such as concept maps, discussion techniques, dramatization, and project-based learning are evaluated. The findings indicate that cognitive objectives in religious education programs are often limited to knowledge and comprehension, and that higher-order cognitive skills (analysis, evaluation, and creation) are not adequately addressed. Furthermore, student-centered methods such as discussion, dramatization, and project-based activities were found to contribute to a deeper and more meaningful understanding of religious concepts. The study suggests that religious education should be transformed from a purely transmission-based approach into a cognitively based structure that supports critical thinking, problem-solving, meaning-making, and value-oriented life skills.",
      "citationCount": 0,
      "doi": "10.59902/yazit.1762758",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f9af4d25d5c3cbcb546711d8ba477cef9aabdbb3",
      "venue": "Yaz\u0131t K\u00fclt\u00fcr Bilimleri Dergisi",
      "journal": {
        "name": "YAZIT K\u00fclt\u00fcr Bilimleri Dergisi"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "5ff7406abe59d9d3fa1c05e5b1d96331b58d55ad",
      "title": "PROBLEMS OF COGNITION AND UNDERSTANDING IN ARTISTIC CREATION",
      "authors": [
        {
          "name": "Pavel D. Simashenkov Pavel D. Simashenkov",
          "authorId": "2370218017"
        }
      ],
      "year": 2025,
      "abstract": "The article is devoted to the aesthetic aspects of imaginative thinking. The methods of cognition implemented in scientific research and in the field of art are studied in a comparative way. Based on the results of the comparison, the features characteristic of the interpretation of the image in artistic creation are highlighted: when implemented in art, the idea sacrifices integrity in the name of liveliness, an infinite variety of manifestations. The research hypothesis (methods of cognition consistent with the human mind are exhausted by analogies and associations) leads the author to a number of generalizations concerning the problems of understanding in art. The author believes that the aesthetics of a work of art should remain unsolved, it is the ecology of creativity, it contains the secrets (and not the laws) of harmony.",
      "citationCount": 0,
      "doi": "10.32340/2949-2912-2025-1-56-63",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/5ff7406abe59d9d3fa1c05e5b1d96331b58d55ad",
      "venue": "Topical Issues of Culture, Art, Education",
      "journal": {
        "name": "Topical Issues of Culture, Art, Education"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "b0fb729f4b80a328dcc6ec9ee96321c025dd0f7b",
      "title": "The Unification of Intelligence Across Systems: A Noesological Framework for Understanding Cognition, Technology, and Society",
      "authors": [
        {
          "name": "Pitshou Moleka",
          "authorId": "2122701450"
        }
      ],
      "year": 2025,
      "abstract": ": This article presents a groundbreaking exploration of noesology as a scientific discipline that unifies multiple forms of intelligence\u2014human, artificial, and collective\u2014into a coherent framework. Noesology integrates concepts from cognitive science, artificial intelligence, evolutionary biology, and complex systems theory to understand how intelligence emerges and interacts across various systems. By drawing on theoretical insights and empirical evidence, this work introduces a novel model for studying intelligence across human, machine, and collective systems, which has profound implications for future research in artificial intelligence, human-machine collaboration, and social governance. Through the integration of interdisciplinary perspectives, the paper aims to lay the foundation for noesology as a central field of study in cognitive science and beyond.",
      "citationCount": 0,
      "doi": "10.18178/jaai.2025.3.3.224-233",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/b0fb729f4b80a328dcc6ec9ee96321c025dd0f7b",
      "venue": "Journal of Advances in Artificial Intelligence",
      "journal": {
        "name": "Journal of Advances in Artificial Intelligence"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "6b53e6b48e18dcb7f139e10f8d31e00f26b14692",
      "title": "Understanding the limits to animal cognition",
      "authors": [
        {
          "name": "Scarlett R. Howard",
          "authorId": "9938852"
        },
        {
          "name": "Andrew B. Barron",
          "authorId": "2394416738"
        }
      ],
      "year": 2024,
      "abstract": null,
      "citationCount": 12,
      "doi": "10.1016/j.cub.2024.02.043",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6b53e6b48e18dcb7f139e10f8d31e00f26b14692",
      "venue": "Current Biology",
      "journal": {
        "name": "Current Biology",
        "pages": "R294-R300",
        "volume": "34"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "484b3460952d88dab32ccac4a4f4a2222b72545a",
      "title": "Explanation versus Understanding: On Two Roles of Dynamical Systems Theory in Extended Cognition Research",
      "authors": [
        {
          "name": "Katarzyna Ku\u015b",
          "authorId": "2288636545"
        },
        {
          "name": "Krzysztof W\u00f3jtowicz",
          "authorId": "2241883934"
        }
      ],
      "year": 2024,
      "abstract": "It is widely believed that mathematics carries a substantial part of the explanatory burden in science. However, mathematics can also play important heuristic roles of a different kind, being a source of new ideas and approaches, allowing us to build toy models, enhancing expressive power and providing fruitful conceptualizations. In this paper, we focus on the application of dynamical systems theory (DST) within the extended cognition (EC) field of cognitive science, considering this case study to be a good illustration of a general phenomenon. In the paper, we justify both a negative and a positive claim. The negative claim is that dynamical systems theory hardly plays any explanatory role in EC research. We justify our claim by analyzing several accounts of the explanatory role of mathematics and stressing the way mathematical arguments are used in explanations. Our positive claim is that even though, for now, DST has no explanatory power in many of the EC approaches, it still plays an important heuristic role there. In particular, using mathematical notions improves the expressive power of the language and gives a sense of understanding of the phenomena under investigation. The case study of EC allows us to identify and analyze this important role of mathematics, which seems to be neglected in contemporary discussions.",
      "citationCount": 1,
      "doi": "10.1007/s10699-024-09940-5",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/484b3460952d88dab32ccac4a4f4a2222b72545a",
      "venue": "Foundations of Science",
      "journal": {
        "name": "Foundations of Science",
        "pages": "175 - 200",
        "volume": "30"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "944dd28033346eee48a2f3d7b4b27a128114bfe6",
      "title": "Materialistic dialectics as an epistemological basis of a realistic approach to understanding and cognition of truth in various spheres of cognition, \nIncluding in criminal proceedings",
      "authors": [
        {
          "name": "Valery V. Melnik",
          "authorId": "2311971440"
        }
      ],
      "year": 2024,
      "abstract": "In the article, using the methodology of system analysis, system-functional, system-structural and system-component aspects of the system approach, as well as the method of expert assessments of authoritative specialists professing a realistic approach to understanding and cognition of truth, materialistic dialectics is considered as a composite This part of the realistic theory of knowledge, the epistemological basis of a realistic approach to understanding and knowing the truth in various spheres of cognition, including in criminal proceedings. It is substantiated that one of the reasons for the unproductiveness of the endless discussion between supporters and opponents of the concept of objective truth in the Russian criminal process is that some modern participants in this discussion from both sides in their understanding of dialectical materialism as the epistemological basis of the realistic approach to understanding and knowing the truth stopped at the level of Soviet official philosophy, not taking into account that dialectical materialism is productively developing through philosophical comprehension within the framework of complex and systematic approaches of the achievements of various branches of the natural sciences and humanities covered by the concept of \u201ccognitive sciences\u201d, which contributes to a deeper understanding of the foundations, system-forming factors of the realistic approach to understanding and cognition of truth.",
      "citationCount": 0,
      "doi": "10.31857/s1026945224020082",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/944dd28033346eee48a2f3d7b4b27a128114bfe6",
      "venue": "\u0413\u043e\u0441\u0443\u0434\u0430\u0440\u0441\u0442\u0432\u043e \u0438 \u043f\u0440\u0430\u0432\u043e",
      "journal": {
        "name": "Gosudarstvo i pravo"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "e27c027702a10224de23882b66cceeb468d4d484",
      "title": "Mikkonen, Jukka, Philosophy, Literature and Understanding: On Reading and Cognition",
      "authors": [
        {
          "name": "Rym Lina Mohammed-Azizi",
          "authorId": "2268625541"
        }
      ],
      "year": 2024,
      "abstract": null,
      "citationCount": 2,
      "doi": "10.25138/18.2.br2",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e27c027702a10224de23882b66cceeb468d4d484",
      "venue": "Kritike: An Online Journal of Philosophy",
      "journal": {
        "name": "Kritike: An Online Journal of Philosophy"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "ab60ca888dfe60bc7a50f47bd483737523943682",
      "title": "Thought Anchors: Which LLM Reasoning Steps Matter?",
      "authors": [
        {
          "name": "Paul C. Bogdan",
          "authorId": "2339777782"
        },
        {
          "name": "Uzay Macar",
          "authorId": "2114970738"
        },
        {
          "name": "Neel Nanda",
          "authorId": "2051128902"
        },
        {
          "name": "Arthur Conmy",
          "authorId": "2131632310"
        }
      ],
      "year": 2025,
      "abstract": "Current frontier large-language models rely on reasoning to achieve state-of-the-art performance. Many existing interpretability are limited in this area, as standard methods have been designed to study single forward passes of a model rather than the multi-token computational steps that unfold during reasoning. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We introduce a black-box method that measures each sentence's counterfactual importance by repeatedly sampling replacement sentences from the model, filtering for semantically different ones, and continuing the chain of thought from that point onwards to quantify the sentence's impact on the distribution of final answers. We discover that certain sentences can have an outsized impact on the trajectory of the reasoning trace and final answer. We term these sentences \\textit{thought anchors}. These are generally planning or uncertainty management sentences, and specialized attention heads consistently attend from subsequent sentences to thought anchors. We further show that examining sentence-sentence causal links within a reasoning trace gives insight into a model's behavior. Such information can be used to predict a problem's difficulty and the extent different question domains involve sequential or diffuse reasoning. As a proof-of-concept, we demonstrate that our techniques together provide a practical toolkit for analyzing reasoning models by conducting a detailed case study of how the model solves a difficult math problem, finding that our techniques yield a consistent picture of the reasoning trace's structure. We provide an open-source tool (thought-anchors.com) for visualizing the outputs of our methods on further problems. The convergence across our methods shows the potential of sentence-level analysis for a deeper understanding of reasoning models.",
      "citationCount": 43,
      "doi": "10.48550/arXiv.2506.19143",
      "arxivId": "2506.19143",
      "url": "https://www.semanticscholar.org/paper/ab60ca888dfe60bc7a50f47bd483737523943682",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2506.19143"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "f143c81a4845006ec7d1c1a25ba2f80144e02673",
      "title": "Pr\u00e9cis of Philosophy, Literature and Understanding: On Reading and Cognition",
      "authors": [
        {
          "name": "Jukka Mikkonen",
          "authorId": "34560228"
        }
      ],
      "year": 2023,
      "abstract": "This pr\u00e9cis gives an overview of my book Philosophy, Literature, and Understanding: On Reading and Cognition which is the subject of a book symposium in Philosophia. The overview covers the book\u2019s four chapters that explore i) the nature of literary imagination, ii) the epistemic value of narratives, iii) the concepts of cognition, knowledge and understanding with regard to fiction, and iv) evidence for claims about the epistemic impact of literary works on their readers.",
      "citationCount": 4,
      "doi": "10.1007/s11406-023-00686-1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f143c81a4845006ec7d1c1a25ba2f80144e02673",
      "venue": "Philosophia",
      "journal": {
        "name": "Philosophia",
        "pages": "5 - 9",
        "volume": "52"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "d94407e2abffb2d7df3cf62fb20f45080ed503a3",
      "title": "Afactivism about understanding cognition",
      "authors": [
        {
          "name": "Samuel D. Taylor",
          "authorId": "50655985"
        }
      ],
      "year": 2023,
      "abstract": "Here, I take alethic views of understanding to be all views that hold that whether an explanation is true or false matters for whether that explanation provides understanding. I then argue that there is (as yet) no naturalistic defence of alethic views of understanding in cognitive science, because there is no agreement about the correct descriptions of the content of cognitive scientific explanations. I use this claim to argue for the provisional acceptance of afactivism in cognitive science, which is the view that the truth or falsity of an explanation of cognition is irrelevant to whether that explanation provides understanding. I conclude by discussing the relation between understanding in cognitive science and understanding in other domains.",
      "citationCount": 1,
      "doi": "10.1007/s13194-023-00544-7",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/d94407e2abffb2d7df3cf62fb20f45080ed503a3",
      "venue": "European Journal for Philosophy of Science",
      "journal": {
        "name": "European Journal for Philosophy of Science",
        "pages": "1-22",
        "volume": "13"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "19e26525c993c9632d8c9bc3ad81998de6af2200",
      "title": "From reinforcement learning to agency: Frameworks for understanding basal cognition",
      "authors": [
        {
          "name": "Gabriella Seifert",
          "authorId": "2275379149"
        },
        {
          "name": "Ava Sealander",
          "authorId": "2275376641"
        },
        {
          "name": "Sarah Marzen",
          "authorId": "2275375011"
        },
        {
          "name": "Michael Levin",
          "authorId": "2314971093"
        }
      ],
      "year": 2023,
      "abstract": null,
      "citationCount": 9,
      "doi": "10.1016/j.biosystems.2023.105107",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/19e26525c993c9632d8c9bc3ad81998de6af2200",
      "venue": "Biosyst.",
      "journal": {
        "name": "Bio Systems",
        "pages": "\n          105107\n        "
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "a9d4d97ee2942aa2800ac4d871f9508a2421c791",
      "title": "Systematism\u2014The Evolution from Holistic Cognition to Systematic Understanding",
      "authors": [
        {
          "name": "Hongjian Yuan",
          "authorId": "2260872517"
        },
        {
          "name": "Yaru Chen",
          "authorId": "2260437298"
        }
      ],
      "year": 2023,
      "abstract": ": Starting from the ancient philosophical proposition of \u201cthe whole is greater than the sum of its parts\u201d, this article attempts to answer the different responses of different holistic theories to \u201c1 + 1 > 2\u201d in different times. When trying to de\ufb01ne systems or systematism, due to the introduction of the concept of exchange and traditional holism, one must ask the question of how to sublimate them into modern systems theory? How does systems philosophy counteract-eat the traditional holism step by step and reshape holism under the framework of systematism?",
      "citationCount": 1,
      "doi": "10.3390/cmsf2023008090",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/a9d4d97ee2942aa2800ac4d871f9508a2421c791",
      "venue": "IS4SI Summit 2023",
      "journal": {
        "name": "IS4SI Summit 2023"
      },
      "publicationTypes": null
    },
    {
      "paperId": "7a9559ac8b1185832487de45b13b8a3e3ffcc2fc",
      "title": "Unveiling the evolution of generative AI (GAI): a comprehensive and investigative analysis toward LLM models (2021\u20132024) and beyond",
      "authors": [
        {
          "name": "Zarif Bin Akhtar",
          "authorId": "1560377819"
        }
      ],
      "year": 2024,
      "abstract": "This comprehensive exploration of recent breakthroughs in artificial intelligence (AI) traversed the realms of language models, computer vision, and generative models, unraveling the intricacies of cutting-edge technologies such as GPT-3.5, GPT-4, Pix2Seq, and multimodal models in terms of generative AI. In this multifaceted journey, the focus extended beyond technological prowess to ethical considerations, emphasizing responsible AI practices guided by Google's AI Principles. The nuanced discussions encapsulated the transformative impact of AI on user experiences across various Google products and toolsets, paving the way for a future where natural language interaction, creative content generation, and multimodal understanding redefine human\u2013computer interactions. The research investigation showcased not only the advancements themselves but also the critical lens through which these innovations are approached, underscoring the importance of ethical and responsible AI in shaping the technological landscape.",
      "citationCount": 56,
      "doi": "10.1186/s43067-024-00145-1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7a9559ac8b1185832487de45b13b8a3e3ffcc2fc",
      "venue": "Journal of Electrical Systems and Information Technology",
      "journal": {
        "name": "Journal of Electrical Systems and Information Technology",
        "volume": "11"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "3a737b91918866f0c0b1ae17e48102d15988fb0c",
      "title": "Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?",
      "authors": [
        {
          "name": "Amar Lakel",
          "authorId": "2400143180"
        }
      ],
      "year": 2025,
      "abstract": "This paper proposes an epistemological shift in the analysis of large generative models, replacing the category''Large Language Models''(LLM) with that of''Large Discourse Models''(LDM), and then with that of Artificial Discursive Agent (ADA). The theoretical framework is based on an ontological triad distinguishing three regulatory instances: the apprehension of the phenomenal regularities of the referential world, the structuring of embodied cognition, and the structural-linguistic sedimentation of the utterance within a socio-historical context. LDMs, operating on the product of these three instances (the document), model the discursive projection of a portion of human experience reified by the learning corpus. The proposed program aims to replace the''fascination/fear''dichotomy with public trials and procedures that make the place, uses, and limits of artificial discursive agents in contemporary social space decipherable, situating this approach within a perspective of governance and co-regulation involving the State, industry, civil society, and academia.",
      "citationCount": 0,
      "doi": null,
      "arxivId": "2512.19117",
      "url": "https://www.semanticscholar.org/paper/3a737b91918866f0c0b1ae17e48102d15988fb0c",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "74339c0a0bc20a3c2c582546fed7d46cb7b25b6d",
      "title": "THE EXPERIENCE OF UNDERSTANDING THE CONCEPTS OF FAITH, REASON AND COGNITION BY THE THINKERS OF KIEVAN RUS IN THE CONTEXT OF THE EPISTEMOLOGICAL TRADITION OF EARLY BYZANTINE PATRISTICS",
      "authors": [
        {
          "name": "A. Volkova",
          "authorId": "153865295"
        }
      ],
      "year": 2022,
      "abstract": "The article analyzes the influence of the philosophical and theological tradition of the religious gnosis of Byzantine patristic thought of the early period on the epistemological views of the leading Kievan Rus thinkers, viz. Kliment Smolyatich and Cyril of Turov. It considers the two main development lines of the idea about knowledge of God in the ancient Russian culture: the ascetic, monastic one (adopted by Feodosiy Pechersky, etc.) and the \"secular\", actually philosophical one (adopted by Kliment Smolyatich, Cyril of Turov, etc.). Special attention in the article is paid to the study of the correlation between the concepts of faith, reason and cognition in epistemological judgments presented in early Byzantine patristics, and their reflection in the philosophical works of Cyril of Turov and Kliment Smolyatich.",
      "citationCount": 0,
      "doi": "10.31079/1992-2868-2022-19-3-82-88",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/74339c0a0bc20a3c2c582546fed7d46cb7b25b6d",
      "venue": "The Humanities and Social Studies in the Far East",
      "journal": {
        "name": "The Humanities And Social Studies In The Far East"
      },
      "publicationTypes": null
    },
    {
      "paperId": "b010b21dd14feac2997b5f68cb21f83611df10ad",
      "title": "Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation",
      "authors": [
        {
          "name": "Adam Kostka",
          "authorId": "2363936352"
        },
        {
          "name": "Jaroslaw A. Chudziak",
          "authorId": "2363931693"
        }
      ],
      "year": 2025,
      "abstract": "Recently, the field of Multi-Agent Systems (MAS) has gained popularity as researchers are trying to develop artificial intelligence capable of efficient collective reasoning. Agents based on Large Language Models (LLMs) perform well in isolated tasks, yet struggle with higher-order cognition required for adaptive collaboration. Human teams achieve synergy not only through knowledge sharing, but also through recursive reasoning, structured critique, and the ability to infer others'mental states. Current artificial systems lack these essential mechanisms, limiting their ability to engage in sophisticated collective reasoning. This work explores cognitive processes that enable effective collaboration, focusing on adaptive theory of mind (ToM) and systematic critical evaluation. We investigate three key questions. First, how does the ability to model others'perspectives enhance coordination and reduce redundant reasoning? Second, to what extent does structured critique improve reasoning quality by identifying logical gaps and mitigating biases? Third, the interplay of these mechanisms can lead to emergent cognitive synergy, where the collective intelligence of the system exceeds the sum of its parts. Through an empirical case study on complex decision making, we show that the integration of these cognitive mechanisms leads to more coherent, adaptive, and rigorous agent interactions. This article contributes to the field of cognitive science and AI research by presenting a structured framework that emulates human-like collaborative reasoning MAS. It highlights the significance of dynamic ToM and critical evaluation in advancing multi-agent systems'ability to tackle complex, real-world challenges.",
      "citationCount": 2,
      "doi": "10.48550/arXiv.2507.21969",
      "arxivId": "2507.21969",
      "url": "https://www.semanticscholar.org/paper/b010b21dd14feac2997b5f68cb21f83611df10ad",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2507.21969"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "60241d59ef73d889e74451aa8717845aaa285b38",
      "title": "Sound and Complete Neurosymbolic Reasoning with LLM-Grounded Interpretations",
      "authors": [
        {
          "name": "Bradley P. Allen",
          "authorId": "2343834405"
        },
        {
          "name": "P. Chhikara",
          "authorId": "1416534710"
        },
        {
          "name": "Thomas Macaulay Ferguson",
          "authorId": "2373397410"
        },
        {
          "name": "Filip Ilievski",
          "authorId": "2339272132"
        },
        {
          "name": "Paul T. Groth",
          "authorId": "2249760863"
        }
      ],
      "year": 2025,
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, but they exhibit problems with logical consistency in the output they generate. How can we harness LLMs'broad-coverage parametric knowledge in formal reasoning despite their inconsistency? We present a method for directly integrating an LLM into the interpretation function of the formal semantics for a paraconsistent logic. We provide experimental evidence for the feasibility of the method by evaluating the function using datasets created from several short-form factuality benchmarks. Unlike prior work, our method offers a theoretical framework for neurosymbolic reasoning that leverages an LLM's knowledge while preserving the underlying logic's soundness and completeness properties.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2507.09751",
      "arxivId": "2507.09751",
      "url": "https://www.semanticscholar.org/paper/60241d59ef73d889e74451aa8717845aaa285b38",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2507.09751"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "f933a641f95dbce728921352e33a6bc257268aac",
      "title": "The Epistemic Downside of Using LLM-Based Generative AI in Academic Writing",
      "authors": [
        {
          "name": "B. Tang",
          "authorId": "5195691"
        }
      ],
      "year": 2025,
      "abstract": "There is now widespread use of large language (LLM)-based generative artificial intelligence (AI) tools in academic research and writing. While these are convenient, quick, and output enhancing, they also arguably incur ethical issues, such as questionable authenticity and plagiarism. Here, I explore epistemological aspects of AI use in academic writing and posit that there is evidence for three related pitfalls in AI use that should not be ignored. These include (1) epistemic detriment or harm in terms of illusions of understanding, (2) potential for cognitive dulling or impairment, and (3) AI dependency (both habitual and/or emotional). Thus, any potential infringements of academic ethics aside, AI use in academic writing incurs intrinsic problems that are epistemic in nature. These epistemic downsides call for restraint and moderation beyond regulatory measures to address ethical issues in AI use.",
      "citationCount": 0,
      "doi": "10.3390/publications13040063",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f933a641f95dbce728921352e33a6bc257268aac",
      "venue": "Publications",
      "journal": {
        "name": "Publications"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "01c2369f079c0b6a4fc5e659a3ce95ed262c6aed",
      "title": "\u0412\u043f\u043b\u0438\u0432 \u0432\u0435\u043b\u0438\u043a\u0438\u0445 \u043c\u043e\u0432\u043d\u0438\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 (LLM) \u043d\u0430 \u043f\u0456\u0434\u0445\u043e\u0434\u0438 \u0434\u043e \u0432\u0438\u0437\u043d\u0430\u0447\u0435\u043d\u043d\u044f \u043f\u043e\u043d\u044f\u0442\u0442\u044f \u043a\u0440\u0435\u0430\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0456",
      "authors": [
        {
          "name": "\u042e. \u041f. \u0422\u0430\u0434\u0435\u0454\u0432",
          "authorId": "119243275"
        }
      ],
      "year": 2025,
      "abstract": "This article provides a comprehensive theoretical analysis of how large language models (LLMs) transform contemporary approaches to defining creativity. The study draws on classical psychological, philosophical, and sociocultural theories, particularly concepts of divergent and convergent thinking and the distinction between P-creativity (psychological) and H-creativity (historical). The research employs conceptual analysis, integrating insights from psychology of creativity, philosophy of science, pedagogy, and AI studies to examine methodological shifts in understanding creativity as both psychological and sociocultural phenomenon. \nThe analysis reveals ambivalent effects of LLM integration into creative, educational, and scientific practices. While these models enhance fluency and short-term productivity, they introduce significant risks: homogenization of thinking through reproduction of dominant patterns, reduction of autonomous creative capacity, and transformation of authorship in human-machine collaboration. LLMs effectively support P-creativity by expanding users' cognitive space, yet their H-creativity capacity remains limited as they operate within existing linguistic patterns. \nA critical finding concerns the validity crisis in traditional psychometric creativity assessment. Conventional instruments, including Torrance Tests, require methodological revision to account for algorithmic support. Quantitative increases in idea generation do not guarantee enhanced originality, as LLM outputs favor statistical probability over genuine innovation. \nThe paper outlines future research directions in developing process-oriented assessment models that account for human-AI interaction specifics in educational and scientific contexts.",
      "citationCount": 0,
      "doi": "10.63437/3083-6433-2025-2(35)-17",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/01c2369f079c0b6a4fc5e659a3ce95ed262c6aed",
      "venue": "\u041f\u0435\u0434\u0430\u0433\u043e\u0433\u0456\u0447\u043d\u0456 \u0456\u043d\u043d\u043e\u0432\u0430\u0446\u0456\u0457: \u0456\u0434\u0435\u0457, \u0440\u0435\u0430\u043b\u0456\u0457, \u043f\u0435\u0440\u0441\u043f\u0435\u043a\u0442\u0438\u0432\u0438",
      "journal": {
        "name": "\u041f\u0435\u0434\u0430\u0433\u043e\u0433\u0456\u0447\u043d\u0456 \u0456\u043d\u043d\u043e\u0432\u0430\u0446\u0456\u0457: \u0456\u0434\u0435\u0457, \u0440\u0435\u0430\u043b\u0456\u0457, \u043f\u0435\u0440\u0441\u043f\u0435\u043a\u0442\u0438\u0432\u0438"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "1ebcfd4bddebe01dbfb737b77ceb6233d71fe08e",
      "title": "Wide Reflective Equilibrium in LLM Alignment: Bridging Moral Epistemology and AI Safety",
      "authors": [
        {
          "name": "Matthew E. Brophy",
          "authorId": "2364747695"
        }
      ],
      "year": 2025,
      "abstract": "As large language models (LLMs) become more powerful and pervasive across society, ensuring these systems are beneficial, safe, and aligned with human values is crucial. Current alignment techniques, like Constitutional AI (CAI), involve complex iterative processes. This paper argues that the Method of Wide Reflective Equilibrium (MWRE) -- a well-established coherentist moral methodology -- offers a uniquely apt framework for understanding current LLM alignment efforts. Moreover, this methodology can substantively augment these processes by providing concrete pathways for improving their dynamic revisability, procedural legitimacy, and overall ethical grounding. Together, these enhancements can help produce more robust and ethically defensible outcomes. MWRE, emphasizing the achievement of coherence between our considered moral judgments, guiding moral principles, and relevant background theories, arguably better represents the intricate reality of LLM alignment and offers a more robust path to justification than prevailing foundationalist models or simplistic input-output evaluations. While current methods like CAI bear a structural resemblance to MWRE, they often lack its crucial emphasis on dynamic, bi-directional revision of principles and the procedural legitimacy derived from such a process. While acknowledging various disanalogies (e.g., consciousness, genuine understanding in LLMs), the paper demonstrates that MWRE serves as a valuable heuristic for critically analyzing current alignment efforts and for guiding the future development of more ethically sound and justifiably aligned AI systems.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2506.00415",
      "arxivId": "2506.00415",
      "url": "https://www.semanticscholar.org/paper/1ebcfd4bddebe01dbfb737b77ceb6233d71fe08e",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2506.00415"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "fa7b66d098676603d4fa97d8de0bb3b66bfe5007",
      "title": "The Erosion of LLM Signatures: Can We Still Distinguish Human and LLM-Generated Scientific Ideas After Iterative Paraphrasing?",
      "authors": [
        {
          "name": "Sadat Shahriar",
          "authorId": "9742303"
        },
        {
          "name": "Navid Ayoobi",
          "authorId": "1573691807"
        },
        {
          "name": "Arjun Mukherjee",
          "authorId": "2322430871"
        }
      ],
      "year": 2025,
      "abstract": "With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs'research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated scientific idea remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4\\% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.",
      "citationCount": 0,
      "doi": null,
      "arxivId": "2512.05311",
      "url": "https://www.semanticscholar.org/paper/fa7b66d098676603d4fa97d8de0bb3b66bfe5007",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "ab326bc43899a7b8f7eb27cf2ae8c3d26fc2931f",
      "title": "The Cognition Role to Understanding Planning and Architectural Production",
      "authors": [
        {
          "name": "Ahmed S. Al-Khafaji",
          "authorId": "2060325192"
        },
        {
          "name": "Nadia A. Al-salam",
          "authorId": "2129257667"
        },
        {
          "name": "T. R. Alrobaee",
          "authorId": "1519355374"
        }
      ],
      "year": 2021,
      "abstract": "This paper focuses on the concept of cognition and its clarification in the light of Islamic epistemology. Knowledge passes through two essential parts: conception and assent. Conception explains simple knowledge, while assent explains knowledge involving a judgment. The paper proceeded with the identification of the problem of relationship blurring between cognition and knowledge. The external and inner senses have explained the relationship between the stages of knowledge and cognition. The external senses receive stimuli and form primary conceptions. These conceptions transfer to the first part of the inner senses, which is common sense; it collects the sensations and transmits them to pictorial power. Secondary conceptions are formed, accompanied by feeling. Then, the estimative power role emerges in imparting meaning to be stored in memory, here knowledge is suspicion, and the perception is achieved. Finally, the images reach the thinking power to impart the specific meaning of the image, which constitutes cognition. Using the Hagia Sophia Case Study, the paper reached important indices in clarifying the cognition stages and understanding of planning and architectural production. These indices were represented by: color, scale, lighting, the harmony of the building with its surroundings, and the meanings associated with cultural, social, and civilized values.\u00a0Doi: 10.28991/cej-2021-03091715 Full Text: PDF",
      "citationCount": 8,
      "doi": "10.28991/CEJ-2021-03091715",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/ab326bc43899a7b8f7eb27cf2ae8c3d26fc2931f",
      "venue": "Civil Engineering Journal",
      "journal": {
        "name": "Civil Engineering Journal"
      },
      "publicationTypes": null
    },
    {
      "paperId": "f0692c7f3990b625cecc8b68aaaf8f463fd9ddff",
      "title": "EXPERIENCE OF UNDERSTANDING THE PROCESS OF COGNITION IN THE KAZAN THEISTIC SCHOOL OF THE SECOND HALF OF THE 19TH CENTURY IN THE CONTEXT OF THE INFLUENCE OF EMPIRICAL PHILOSOPHY",
      "authors": [
        {
          "name": "S. V. Pishun",
          "authorId": "134748341"
        }
      ],
      "year": 2022,
      "abstract": "On the example of the analysis of the creativity of representatives of the Kazan theistic school, the presence of an empirical model of metaphysics of knowledge in spiritual and academic science as an alternative to Orthodox religious and philosophical rationalism was revealed. The tradition of interpreting the role of religious feeling in the process of knowledge among teachers of the Kazan Theological Academy is outlined. The role of British empiricism as one of the sources of the empirical version of Orthodox philosophical epistemology has been identified",
      "citationCount": 0,
      "doi": "10.31079/1992-2868-2022-19-3-89-93",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f0692c7f3990b625cecc8b68aaaf8f463fd9ddff",
      "venue": "The Humanities and Social Studies in the Far East",
      "journal": {
        "name": "The Humanities And Social Studies In The Far East"
      },
      "publicationTypes": null
    },
    {
      "paperId": "a322b20a6e3c52e25a46608ed81df8b0608cd73e",
      "title": "Lack of Understanding and the Desire for Re-Cognition",
      "authors": [
        {
          "name": "Majsa Allelin",
          "authorId": "2095924289"
        }
      ],
      "year": 2022,
      "abstract": "No abstract available.",
      "citationCount": 0,
      "doi": "10.3384/confero.2001-4562.221114",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/a322b20a6e3c52e25a46608ed81df8b0608cd73e",
      "venue": "Confero: Essays on Education, Philosophy and Politics",
      "journal": {
        "name": "Confero: Essays on Education, Philosophy and Politics"
      },
      "publicationTypes": null
    },
    {
      "paperId": "afa767d8a0e48100414d575e0fb1373db80c1a5a",
      "title": "QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning",
      "authors": [
        {
          "name": "Mohammad AL-Smadi",
          "authorId": "2339667791"
        }
      ],
      "year": 2025,
      "abstract": "This paper presents our approach and results for SubTask 1: Islamic Inheritance Reasoning at QIAS 2025, a shared task focused on evaluating Large Language Models (LLMs) in understanding and reasoning within Islamic inheritance knowledge. We fine-tuned the Fanar-1-9B causal language model using Low-Rank Adaptation (LoRA) and integrated it into a Retrieval-Augmented Generation (RAG) pipeline. Our system addresses the complexities of Islamic inheritance law, including comprehending inheritance scenarios, identifying eligible heirs, applying fixed-share rules, and performing precise calculations. Our system achieved an accuracy of 0.858 in the final test, outperforming other competitive models such as, GPT 4.5, LLaMA, Fanar, Mistral and ALLaM evaluated with zero-shot prompting. Our results demonstrate that QU-NLP achieves near state-of-the-art accuracy (85.8%), excelling especially on advanced reasoning (97.6%) where it outperforms Gemini 2.5 and OpenAI's o3. This highlights that domain-specific fine-tuning combined with retrieval grounding enables mid-scale Arabic LLMs to surpass frontier models in Islamic inheritance reasoning.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2508.15854",
      "arxivId": "2508.15854",
      "url": "https://www.semanticscholar.org/paper/afa767d8a0e48100414d575e0fb1373db80c1a5a",
      "venue": "Proceedings of The Third Arabic Natural Language Processing Conference: Shared Tasks",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2508.15854"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "4d091032d1d28e566802ca9beea1421361b5d03b",
      "title": "Leveraging Ethical Narratives to Enhance LLM\u2010AutoML Generated Machine Learning Models",
      "authors": [
        {
          "name": "Jordan Nelson",
          "authorId": "2330204627"
        },
        {
          "name": "Michalis Pavlidis",
          "authorId": "34667222"
        },
        {
          "name": "Andrew Fish",
          "authorId": "2330029838"
        },
        {
          "name": "Nikolaos Polatidis",
          "authorId": "3045368"
        },
        {
          "name": "Yannis Manolopoulos",
          "authorId": "2182067085"
        }
      ],
      "year": 2025,
      "abstract": "The growing popularity of generative AI and large language models (LLMs) has sparked innovation alongside debate, particularly around issues of plagiarism and intellectual property law. However, a less\u2010discussed concern is the quality of code generated by these models, which often contains errors and encourages poor programming practices. This paper proposes a novel solution by integrating LLMs with automated machine learning (AutoML). By leveraging AutoML's strengths in hyperparameter tuning and model selection, we present a framework for generating robust and reliable machine learning (ML) algorithms. Our approach incorporates natural language processing (NLP) and natural language understanding (NLU) techniques to interpret chatbot prompts, enabling more accurate and customisable ML model generation through AutoML. To ensure ethical AI practices, we have also introduced a filtering mechanism to address potential biases and enhance accountability. The proposed methodology not only demonstrates practical implementation but also achieves high predictive accuracy, offering a viable solution to current challenges in LLM\u2010based code generation. In summary, this paper introduces a new application of NLP and NLU to extract features from chatbot prompts, feeding them into an AutoML system to generate ML algorithms. This approach is framed within a rigorous ethical framework, addressing concerns of bias and accountability while enhancing the reliability of code generation.",
      "citationCount": 0,
      "doi": "10.1111/exsy.70072",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4d091032d1d28e566802ca9beea1421361b5d03b",
      "venue": "Expert Syst. J. Knowl. Eng.",
      "journal": {
        "name": "Expert Systems",
        "volume": "42"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "b98cc2649cf2b9fe82aac92273dae30bc5792308",
      "title": "Thought Branches: Interpreting LLM Reasoning Requires Resampling",
      "authors": [
        {
          "name": "Uzay Macar",
          "authorId": "2114970738"
        },
        {
          "name": "Paul C. Bogdan",
          "authorId": "2339777782"
        },
        {
          "name": "Senthooran Rajamanoharan",
          "authorId": "35185194"
        },
        {
          "name": "Neel Nanda",
          "authorId": "2367045798"
        }
      ],
      "year": 2025,
      "abstract": "Most work interpreting reasoning models studies only a single chain-of-thought (CoT), yet these models define distributions over many possible CoTs. We argue that studying a single sample is inadequate for understanding causal influence and the underlying computation. Though fully specifying this distribution is intractable, it can be understood by sampling. We present case studies using resampling to investigate model decisions. First, when a model states a reason for its action, does that reason actually cause the action? In\"agentic misalignment\"scenarios, we resample specific sentences to measure their downstream effects. Self-preservation sentences have small causal impact, suggesting they do not meaningfully drive blackmail. Second, are artificial edits to CoT sufficient for steering reasoning? These are common in literature, yet take the model off-policy. Resampling and selecting a completion with the desired property is a principled on-policy alternative. We find off-policy interventions yield small and unstable effects compared to resampling in decision-making tasks. Third, how do we understand the effect of removing a reasoning step when the model may repeat it post-edit? We introduce a resilience metric that repeatedly resamples to prevent similar content from reappearing downstream. Critical planning statements resist removal but have large effects when eliminated. Fourth, since CoT is sometimes\"unfaithful\", can our methods teach us anything in these settings? Adapting causal mediation analysis, we find that hints that have a causal effect on the output without being explicitly mentioned exert a subtle and cumulative influence on the CoT that persists even if the hint is removed. Overall, studying distributions via resampling enables reliable causal analysis, clearer narratives of model reasoning, and principled CoT interventions.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2510.27484",
      "arxivId": "2510.27484",
      "url": "https://www.semanticscholar.org/paper/b98cc2649cf2b9fe82aac92273dae30bc5792308",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2510.27484"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "dbea049770ab7c6593307dc6633db6d9f1fb8900",
      "title": "Biases, evolutionary mismatch and the comparative analysis of human versus artificial cognition: a comment on Macmillan-Scott and Musolesi (2024)",
      "authors": [
        {
          "name": "P. Sacco",
          "authorId": "3130592"
        }
      ],
      "year": 2025,
      "abstract": "The paper by Macmillan-Scott & Musolesi [1] provides an insightful analysis of the rational reasoning capabilities of large language models (LLMs) using cognitive tasks originally designed to study human decision-making biases. Their findings reveal systematic differences between human and LLM reasoning. This raises important questions about the nature of these differences and the appropriateness of using abstract notions of rationality as benchmarks for evaluating both human and artificial cognition. Human cognitive patterns often characterized as departures from rationality can be better understood through the lens of evolutionary mismatch\u2014the disparity between our inherited cognitive tools and contemporary environmental demands [2,3]. Heuristics and biases that may seem irrational from a modern, abstract perspective could have been highly adaptive in the context of foraging, social coordination and survival in small-scale societies [4,5]. These cognitive tools, rather than being purely genetically specified modules, are better conceptualized as \u2018cognitive gadgets\u2019\u2014culturally inherited thinking tools built upon genetically evolved learning capacities [6]. Over the course of human evolutionary history, our basic capacities for social learning and cultural transmission developed within specific ecological and social contexts [7], providing the foundation for more sophisticated cognitive tools that emerged through cultural evolution [8].",
      "citationCount": 1,
      "doi": "10.1098/rsos.241017",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/dbea049770ab7c6593307dc6633db6d9f1fb8900",
      "venue": "Royal Society Open Science",
      "journal": {
        "name": "Royal Society Open Science",
        "volume": "12"
      },
      "publicationTypes": [
        "LettersAndComments",
        "JournalArticle"
      ]
    },
    {
      "paperId": "3826491c6c81c3c69d43a821d71f2f7602c2a261",
      "title": "Lyotard's Immiscible Modes of Meaning: the plasticity of sensation and cognition and its significance for understanding Lyotard's relation to Hegel",
      "authors": [
        {
          "name": "Elka Yasmin Joyce Sadler",
          "authorId": "2090113201"
        }
      ],
      "year": 2021,
      "abstract": null,
      "citationCount": 0,
      "doi": "10.26180/13667381.V1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/3826491c6c81c3c69d43a821d71f2f7602c2a261",
      "venue": "",
      "journal": {
        "name": "",
        "volume": ""
      },
      "publicationTypes": null
    },
    {
      "paperId": "edeccc9e6ff15aef811910648093d440ae0bc5d4",
      "title": "Custom and Cognition: Towards an Understanding of Religious Belief",
      "authors": [
        {
          "name": "M. Hernandez",
          "authorId": "84324862"
        }
      ],
      "year": 2021,
      "abstract": null,
      "citationCount": 0,
      "doi": "10.38119/CACS.2021.25.1",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/edeccc9e6ff15aef811910648093d440ae0bc5d4",
      "venue": "",
      "journal": {
        "name": "Episteme",
        "pages": "3-21",
        "volume": "25"
      },
      "publicationTypes": null
    }
  ],
  "count": 40,
  "errors": []
}
