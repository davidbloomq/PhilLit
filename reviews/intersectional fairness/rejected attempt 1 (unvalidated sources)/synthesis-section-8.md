# Section 8: Conclusion

This literature review has synthesized 95 papers across six domains—algorithmic fairness and intersectionality (machine learning), philosophy of intersectionality, social ontology, measurement theory and construct validity, normative frameworks for fairness, and applied epistemology—to establish a systematic gap in scholarship on intersectional fairness. Each domain provides sophisticated analysis of challenges that intersectional fairness poses. The machine learning community has developed increasingly innovative technical methods for handling sparse intersectional data, from multicalibration frameworks to hierarchical approaches. Philosophers have revealed deep complexities in understanding what intersectionality is and how intersectional groups should be conceived. Measurement theorists have shown that operationalization is never neutral but always embeds ontological commitments. Normative theorists have offered frameworks from prioritarianism to sufficientarianism for evaluating fairness. Epistemologists have analyzed uncertainty, epistemic justice, and the responsibilities of making inferences about groups.

Yet examining these literatures together reveals what individual literatures miss: the interaction between statistical uncertainty and ontological uncertainty creates a genuine dilemma for intersectional fairness that cannot be resolved through incremental advances within existing frameworks. The dilemma has two horns that mutually exacerbate each other. More intersectional groups create statistical challenges (exponential growth, data sparsity, infeasible sample complexity)—this is well-documented in machine learning. Which intersectional groups exist and warrant consideration is ontologically uncertain (definitional dilemmas, competing metaphysics, contested categories)—this is well-documented in philosophy. But these are not independent problems. Taking ontological considerations seriously (emergence, non-additivity, context-dependence) suggests including many intersectional groups, which exacerbates statistical challenges. Statistical constraints create pressure to limit groups, which requires answering ontological questions that philosophy shows are deeply contested. Each horn makes the other worse.

The gap is not that either horn is unrecognized. Both are thoroughly analyzed within their respective literatures. The gap is the absence of recognition that they *interact* to create a dilemma. Machine learning researchers assume groups can be specified (treating the ontological problem as solved) and focus on statistical challenges. Philosophers analyze intersectionality without considering statistical constraints (treating the statistical problem as outside their domain). Measurement theorists, normative theorists, and epistemologists largely proceed as if these problems can be addressed separately. This disciplinary organization has created a systematic blind spot: the interaction falls between fields, with each assuming the other has solved its piece.

Our review identifies specific moments where existing work approaches the dilemma without fully recognizing it. Jacobs and Wallach (2021) argue that fairness is an essentially contested construct with different theoretical understandings—an insight that could extend to group specification but does not in their analysis, and which does not connect theoretical contestedness to statistical consequences. Celis et al. (2022) note that assessing fairness with multiple attributes "may be unfeasible in most practical cases"—recognizing statistical infeasibility but not connecting it to ontological debates about which groups to include. Jorba and López de Sa (2024) develop intersectionality as emergence—a philosophical advance that has implications for which groups exist but without discussion of statistical challenges this creates. Hüllermeier and Waegeman (2021) distinguish epistemic from aleatoric uncertainty—an epistemological framework applicable to intersectional groups but developed without engaging ontological debates about which groups that framework should apply to.

These moments of near-recognition underscore that the dilemma is not obvious or trivial. Excellent scholarship in multiple domains has worked on related problems without quite seeing the interaction. This makes the gap systematic rather than accidental—a product of how scholarship is organized rather than individual oversight.

The contribution of framing intersectional fairness as a genuine dilemma arising from statistical-ontological interaction is thus both diagnostic and generative. Diagnostically, it names a blind spot that has persisted across multiple literatures despite growing attention to intersectional fairness. It explains why both technical advances (better methods for sparse data) and philosophical clarifications (clearer ontologies of groups) feel insufficient—because addressing one horn without the other leaves the dilemma unresolved. Generatively, recognizing the dilemma suggests that what is needed is not more progress within existing frameworks but new approaches that grapple directly with the interaction.

Such approaches might take various forms. One possibility is developing normative frameworks specifically for the dilemma—principles for navigating trade-offs between ontological inclusivity and statistical reliability rather than treating these as independent desiderata. Another possibility is participatory methods that involve affected communities in determining which intersectional groups matter, making the ontological question a matter of democratic deliberation rather than expert specification, though this still must address how to handle statistical constraints when communities identify numerous groups. A third possibility is developing statistical methods specifically designed for the ontological uncertainty case—methods that remain valid when the set of groups itself is uncertain or contested, rather than presupposing a known group specification. A fourth possibility is measurement approaches that embrace rather than resolve ontological uncertainty—frameworks that can operate with multiple, overlapping group specifications rather than requiring a single definitive categorization.

These are merely possibilities suggested by recognizing the dilemma. The point is not to solve the dilemma within a literature review but to establish its existence and novelty. Our analysis demonstrates that across 95 papers spanning machine learning, philosophy, measurement theory, normative theory, and epistemology, none frame intersectional fairness as this kind of dilemma. Technical papers assume ontological problems are solved; philosophical papers proceed without statistical constraints; other literatures assume both can be addressed separately. The interaction—the mutual exacerbation whereby ontological considerations push toward more groups while statistical constraints push toward fewer—goes unrecognized.

This gap has practical consequences. Current approaches to intersectional fairness make implicit choices about which horn to privilege: statistical approaches prioritize feasibility (fewer groups), critical approaches prioritize inclusivity (more groups), pragmatic approaches seek compromises without acknowledging the underlying dilemma. Making these choices explicit—recognizing them as navigating a genuine dilemma rather than solving a technical problem—would change both the framing and the stakes of intersectional fairness work. It would clarify that disagreements about intersectional fairness are not merely about which methods to use but about how to navigate irreducible tensions between ontological commitments and statistical constraints.

For researchers, the dilemma framing suggests new questions. Rather than "how can we achieve fairness for intersectional groups?" (which presupposes the dilemma is solvable), we might ask: "how should we navigate trade-offs between ontological inclusivity and statistical reliability?" "What makes a compromise between these desiderata legitimate or just?" "Who should have authority to make these trade-offs?" These questions require integrating perspectives from computer science, philosophy, political theory, and affected communities—genuinely interdisciplinary work rather than parallel disciplinary analyses.

For practitioners, the dilemma framing provides language for challenges they likely already face. Practitioners building fairness-aware systems must decide which groups to assess fairness for—a decision that involves both statistical realities (some groups have sparse data) and normative commitments (some groups may be marginalized despite sparse data). Recognizing this as navigating a dilemma rather than solving a technical problem can make the difficulty feel less like a failure of expertise and more like an inherent complexity requiring judgment.

For policymakers and auditors, the dilemma framing suggests that algorithmic fairness requirements should account for this complexity. Regulations requiring "fairness for all groups" may be practically infeasible given statistical constraints; regulations requiring only a minimal set of groups may exclude intersectional communities. Policy might better focus on the *process* of navigating the dilemma—requiring transparency about which groups are included/excluded, justification for these choices, and participation by affected communities—rather than mandating specific outcomes that may be impossible given the statistical-ontological interaction.

In conclusion, this review establishes a novel framing of intersectional algorithmic fairness as a genuine dilemma arising from the interaction between statistical uncertainty and ontological uncertainty. While existing scholarship has made tremendous progress understanding each problem separately—with machine learning developing sophisticated methods for sparse data, philosophy revealing deep complexities in intersectionality's nature, and related fields contributing measurement, normative, and epistemic perspectives—no existing work recognizes these as interacting problems that mutually exacerbate each other. The gap is systematic: disciplinary organization has created a blind spot where the interaction falls between fields. Recognizing the dilemma reframes the challenge from "solve both problems independently" to "navigate the interaction where solving one worsens the other." This reframing is both diagnostic (explaining why progress has felt insufficient) and generative (suggesting new research directions, practical approaches, and policy frameworks). The dilemma may not be fully resolvable, but recognizing it as a dilemma—rather than treating it as two separate problems awaiting technical and philosophical solutions—is a necessary first step toward more sophisticated, honest, and effective approaches to intersectional fairness in algorithmic systems.
