## Introduction

The symbol grounding problem asks a deceptively simple question: how do the symbols manipulated by computational systems acquire meaning that is intrinsic to those systems rather than parasitic on external human interpretation? Harnad (1990) crystallized this challenge by observing that purely symbolic systems face an infinite regress analogous to trying to learn Chinese from a Chinese-only dictionary. Symbols defined only in terms of other symbols remain semantically empty unless some are grounded in something beyond the symbolic realm itself. This formulation emerged directly from engagement with Searle's (1980) Chinese Room argument, which purported to demonstrate that syntactic manipulation could never constitute semantic understanding. Where Searle drew skeptical conclusions about artificial intelligence entirely, Harnad proposed a constructive response: hybrid systems combining symbolic processing with sensorimotor grounding might break the regress.

Yet the problem's very formulation embeds substantive assumptions about the nature of meaning. This review investigates whether the symbol grounding problem presupposes a particular meta-semantic framework that philosophers of language have contested. Three central questions guide this investigation. First, do philosophers of language genuinely engage with the symbol grounding problem, or do they find its framing theoretically problematic from the outset? Second, does the problem presuppose a narrow meta-semantic view---specifically, a denotational or referentialist semantics where meaning fundamentally consists in word-world relations requiring causal grounding? Third, where has philosophical discussion of the symbol grounding problem gone, particularly in light of recent developments in artificial intelligence?

Taddeo and Floridi (2005) provided a systematic review establishing that proposed solutions uniformly failed what they termed the "zero semantic commitment condition"---the requirement that genuine solutions not presuppose the semantic capacities they purport to explain. Their analysis revealed that debates about grounding solutions often proceed without examining whether the problem itself is well-posed. More recently, Gubelmann (2024) has argued explicitly that the symbol grounding problem arises only when one presupposes questionable theories of meaning, particularly the computational theory of mind and denotational semantics. Under pragmatist alternatives where meaning is constituted by normative patterns of use, the grounding problem purportedly dissolves.

The emergence of large language models has reinvigorated these debates with new urgency. Contemporary philosophers remain sharply divided: some maintain that LLMs simply lack grounding and therefore genuine understanding, while others argue that sensory grounding was never necessary for semantic competence, or that LLMs circumvent rather than solve or fail the grounding challenge. These divergent verdicts trace, we shall argue, to divergent prior commitments about what meaning requires.

This review proceeds as follows. Section 1 examines the symbol grounding problem's formulation and traces its philosophical roots in debates about intentionality. Section 2 applies meta-semantic frameworks from philosophy of language---referentialism, inferentialism, use theories, and contemporary meta-semantics---to evaluate whether the problem presupposes contested theoretical commitments. Section 3 articulates specific research gaps and examines how LLM debates have reshaped the grounding question. The conclusion synthesizes findings and positions the contribution of exposing the symbol grounding problem's meta-semantic presuppositions.
