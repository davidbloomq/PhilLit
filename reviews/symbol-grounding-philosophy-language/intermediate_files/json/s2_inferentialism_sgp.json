{
  "status": "success",
  "source": "semantic_scholar",
  "query": "inferentialism symbol grounding",
  "results": [
    {
      "paperId": "511f450211ded1bad72d7984402c717328b816d3",
      "title": "A Unified Formal Theory on the Logical Limits of Symbol Grounding",
      "authors": [
        {
          "name": "Zhangchi Liu",
          "authorId": "2383142182"
        }
      ],
      "year": 2025,
      "abstract": "This paper synthesizes a series of formal proofs to construct a unified theory on the logical limits of the Symbol Grounding Problem. We distinguish between internal meaning (sense), which formal systems can possess via axioms, and external grounding (reference), which is a necessary condition for connecting symbols to the world. We demonstrate through a four-stage argument that meaningful grounding within a formal system must arise from a process that is external, dynamic, and non-fixed algorithmic. First, we show that for a purely symbolic system, the impossibility of grounding is a direct consequence of its definition. Second, we extend this limitation to systems with any finite, static set of pre-established meanings (Semantic Axioms). By formally modeling the computationalist hypothesis-which equates grounding with internal derivation-we prove via G\\\"odelian arguments that such systems cannot consistently and completely define a\"groundability predicate\"for all truths. Third, we demonstrate that the\"grounding act\"for emergent meanings cannot be inferred from internal rules but requires an axiomatic, meta-level update. Drawing on Turing's concept of Oracle Machines and Piccinini's analysis of the mathematical objection, we identify this update as physical transduction. Finally, we prove that this process cannot be simulated by a fixed judgment algorithm, validating the logical necessity of embodied interaction.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2509.20409",
      "arxivId": "2509.20409",
      "url": "https://www.semanticscholar.org/paper/511f450211ded1bad72d7984402c717328b816d3",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2509.20409"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "eee43a9337df7ca428e78d0217bd0691a9927c09",
      "title": "A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem",
      "authors": [
        {
          "name": "Luciano Floridi",
          "authorId": "2259952291"
        },
        {
          "name": "Yiyang Jia",
          "authorId": "2400358926"
        },
        {
          "name": "Fernando Tohm'e",
          "authorId": "2214095508"
        }
      ],
      "year": 2025,
      "abstract": "This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.",
      "citationCount": 0,
      "doi": null,
      "arxivId": "2512.09117",
      "url": "https://www.semanticscholar.org/paper/eee43a9337df7ca428e78d0217bd0691a9927c09",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "6c5eb8a5b5c9a496ad86bd8020275d7b43163d9d",
      "title": "An Algorithmic Information-Theoretic Perspective on the Symbol Grounding Problem",
      "authors": [
        {
          "name": "Zhangchi Liu",
          "authorId": "2383142182"
        }
      ],
      "year": 2025,
      "abstract": "This paper provides a definitive, unifying framework for the Symbol Grounding Problem (SGP) by reformulating it within Algorithmic Information Theory (AIT). We demonstrate that the grounding of meaning is a process fundamentally constrained by information-theoretic limits, thereby unifying the G\\\"odelian (self-reference) and No Free Lunch (statistical) perspectives. We model a symbolic system as a universal Turing machine and define grounding as an act of information compression. The argument proceeds in four stages. First, we prove that a purely symbolic system cannot ground almost all possible\"worlds\"(data strings), as they are algorithmically random and thus incompressible. Second, we show that any statically grounded system, specialized for compressing a specific world, is inherently incomplete because an adversarial, incompressible world relative to the system can always be constructed. Third, the\"grounding act\"of adapting to a new world is proven to be non-inferable, as it requires the input of new information (a shorter program) that cannot be deduced from the system's existing code. Finally, we use Chaitin's Incompleteness Theorem to prove that any algorithmic learning process is itself a finite system that cannot comprehend or model worlds whose complexity provably exceeds its own. This establishes that meaning is the open-ended process of a system perpetually attempting to overcome its own information-theoretic limitations.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2510.05153",
      "arxivId": "2510.05153",
      "url": "https://www.semanticscholar.org/paper/6c5eb8a5b5c9a496ad86bd8020275d7b43163d9d",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2510.05153"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "074f988f0bf1f7feeea0c0abce0bdb8ecc0f5a2a",
      "title": "Symbol grounding for generative AI: lessons learned from interpretive ABM",
      "authors": [
        {
          "name": "M. Neumann",
          "authorId": "2105962062"
        },
        {
          "name": "Vanessa Dirksen",
          "authorId": "2351504396"
        }
      ],
      "year": 2025,
      "abstract": "This perspective article argues that not only humanities benefit and are transformed by recent AI developments but AI might also benefit from the humanities. This is demonstrated with regard to the symbol grounding problem in AI by considering that meaning is not the outcome of a two-way relation between an object and a brain (or AI) but of the negotiation of meaning in the triadic relation between objects, symbols, and human practices. This is common in the interpretive social research tradition of the humanities. We argue that AI benefits from embedding generative methods in interpretive social research methodologies. This can be achieved by using the example of the recently developed methodology of interpretive agent-based simulation (iABM). This methodology enables the generation of counterfactual narratives anchored in ethnographic evidence and hermeneutically interpreted, producing symbolically grounded and plausible futures. Criteria for plausibility correspond to contemporary guidelines for assessing trustworthy AI, namely human agency and oversight, transparency, and auditability.",
      "citationCount": 0,
      "doi": "10.3389/fcomp.2025.1508004",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/074f988f0bf1f7feeea0c0abce0bdb8ecc0f5a2a",
      "venue": "Frontiers Comput. Sci.",
      "journal": {
        "name": "Frontiers Comput. Sci.",
        "volume": "7"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "b48f456b4866fce64036a600f82db6ae4e9d542e",
      "title": "A Neuro-Symbolic Approach to Symbol Grounding for ALC-Ontologies",
      "authors": [
        {
          "name": "Xuan Wu",
          "authorId": "2269056418"
        },
        {
          "name": "Yizheng Zhao",
          "authorId": "2261292865"
        }
      ],
      "year": 2025,
      "abstract": "Neuro-symbolic computing aims to integrate neural learning with symbolic reasoning to address the fundamental challenge of symbol grounding. While neural networks excel at pattern recognition, they struggle to maintain logical consistency. Conversely, symbolic systems provide formal reasoning capabilities but lack mechanisms for handling perceptual uncertainty. This paper introduces EmALC , a novel neuro-symbolic framework that bridges neural perception with symbolic logic through differentiable fuzzy semantics. Our approach addresses a key limitation of existing methods: while previous neuro-symbolic approaches like Logic Tensor Networks employ first-order fuzzy logic, where key reasoning problems are undecidable, EmALC ensures decidable reasoning by leveraging a fuzzy variant of ALC -- a decidable fragment of first-order logic. Unlike previous approaches that often compromise logical soundness for learning capability, EmALC maintains provable semantic consistency through a hierarchical loss function while mitigating reasoning shortcuts via rule-based revision strategies. Experimental evaluation demonstrates EmALC's effectiveness: on ontology revision tasks, it achieves 100% success rate in correcting masked groundings while preserving semantic integrity; on semantic image interpretation tasks, it improves object classification F1-scores by up to 5.56% through ontology-guided knowledge revision.",
      "citationCount": 0,
      "doi": "10.1145/3711896.3736926",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/b48f456b4866fce64036a600f82db6ae4e9d542e",
      "venue": "Knowledge Discovery and Data Mining",
      "journal": {
        "name": "Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "8995865f02d8799fc104d3bbfc22476aaeb45755",
      "title": "Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark",
      "authors": [
        {
          "name": "Shoko Oka",
          "authorId": "2366066462"
        }
      ],
      "year": 2025,
      "abstract": "Recent advancements in large language models (LLMs) have revitalized philosophical debates surrounding artificial intelligence. Two of the most fundamental challenges - namely, the Frame Problem and the Symbol Grounding Problem - have historically been viewed as unsolvable within traditional symbolic AI systems. This study investigates whether modern LLMs possess the cognitive capacities required to address these problems. To do so, I designed two benchmark tasks reflecting the philosophical core of each problem, administered them under zero-shot conditions to 13 prominent LLMs (both closed and open-source), and assessed the quality of the models' outputs across five trials each. Responses were scored along multiple criteria, including contextual reasoning, semantic coherence, and information filtering. The results demonstrate that while open-source models showed variability in performance due to differences in model size, quantization, and instruction tuning, several closed models consistently achieved high scores. These findings suggest that select modern LLMs may be acquiring capacities sufficient to produce meaningful and stable responses to these long-standing theoretical challenges.",
      "citationCount": 0,
      "doi": "10.5281/zenodo.15617317",
      "arxivId": "2506.07896",
      "url": "https://www.semanticscholar.org/paper/8995865f02d8799fc104d3bbfc22476aaeb45755",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2506.07896"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "3e09d0a44dfc2213fda8443cd85b6fbec48f1d76",
      "title": "Principles of logical deduction with the deep learning problem and the symbol grounding problem",
      "authors": [
        {
          "name": "Wako Takanashi",
          "authorId": "2293336378"
        }
      ],
      "year": 2025,
      "abstract": null,
      "citationCount": 0,
      "doi": "10.1299/jsmekanto.2025.31.04c21",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/3e09d0a44dfc2213fda8443cd85b6fbec48f1d76",
      "venue": "The Proceedings of Conference of Kanto Branch",
      "journal": {
        "name": "The Proceedings of Conference of Kanto Branch"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "82fd866b13d97763e738660f2a077eddc854c3ea",
      "title": "Pragmatic Norms Are All You Need \u2013 Why The Symbol Grounding Problem Does Not Apply to LLMs",
      "authors": [
        {
          "name": "Reto Gubelmann",
          "authorId": "119338633"
        }
      ],
      "year": 2024,
      "abstract": "Do LLMs fall prey to Harnad\u2019s symbol grounding problem (SGP), as it has recently been claimed? We argue that this is not the case. Starting out with countering the arguments of Bender and Koller (2020), we trace the origins of the SGP to the computational theory of mind (CTM), and we show that it only arises with natural language when questionable theories of meaning are presupposed. We conclude by showing that it would apply to LLMs only if they were interpreted in the manner of how the CTM conceives the mind, i.e., by postulating that LLMs rely on a version of a language of thought, or by adopting said questionable theories of meaning; since neither option is rational, we conclude that the SGP does not apply to LLMs.",
      "citationCount": 9,
      "doi": "10.18653/v1/2024.emnlp-main.651",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/82fd866b13d97763e738660f2a077eddc854c3ea",
      "venue": "Conference on Empirical Methods in Natural Language Processing",
      "journal": {
        "pages": "11663-11678"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "4106342a079eecadd4a4a1d39eabd4a50e0a7cd1",
      "title": "The Symbol Grounding Problem",
      "authors": [
        {
          "name": "S. Harnad",
          "authorId": "2293327"
        }
      ],
      "year": 1990,
      "abstract": null,
      "citationCount": 3571,
      "doi": "10.1016/0167-2789(90)90087-6",
      "arxivId": "cs/9906002",
      "url": "https://www.semanticscholar.org/paper/4106342a079eecadd4a4a1d39eabd4a50e0a7cd1",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "cs.AI/9906002"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "af9b9412998c5e590f831b1076c842f6193de9ab",
      "title": "The Difficulties in Symbol Grounding Problem and the Direction for Solving It",
      "authors": [
        {
          "name": "Jianhui Li",
          "authorId": "48514373"
        },
        {
          "name": "Haohao Mao",
          "authorId": "2162838180"
        }
      ],
      "year": 2022,
      "abstract": "The symbol grounding problem (SGP) proposed by Stevan Harnad in 1990, originates from Searle\u2019s \u201cChinese Room Argument\u201d and refers to the problem of how a pure symbolic system acquires its meaning. While many solutions to this problem have been proposed, all of them have encountered inconsistencies to different extents. A recent approach for resolving the problem is to divide the SGP into hard and easy problems echoing the distinction between hard and easy problems for resolving the enigma of consciousness. This however turns out not to be an ideal strategy: Everything related to consciousness that cannot be well-explained by present theories can be categorized as a hard problem which as a consequence would doom the SGP to irresolvability. We therefore argue that the SGP can be regarded as a general problem of how an AI system can have intentionality, and develop a theoretical direction for its solution.",
      "citationCount": 4,
      "doi": "10.3390/philosophies7050108",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/af9b9412998c5e590f831b1076c842f6193de9ab",
      "venue": "Philosophies",
      "journal": {
        "name": "Philosophies"
      },
      "publicationTypes": null
    },
    {
      "paperId": "52430a8a726c2877fb7acbc28e92dfb83f6c54bf",
      "title": "Symbol Grounding Precedes Interpretation",
      "authors": [
        {
          "name": "H. Pattee",
          "authorId": "1838903"
        }
      ],
      "year": 2021,
      "abstract": null,
      "citationCount": 3,
      "doi": "10.1007/s12304-021-09458-4",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/52430a8a726c2877fb7acbc28e92dfb83f6c54bf",
      "venue": "Biosemiotics",
      "journal": {
        "name": "Biosemiotics",
        "pages": "561 - 568",
        "volume": "14"
      },
      "publicationTypes": null
    },
    {
      "paperId": "014958763a88e38e215a94f41311d0a772b94781",
      "title": "Symbol Grounding via Chaining of Morphisms",
      "authors": [
        {
          "name": "Ruiting Lian",
          "authorId": "47783226"
        },
        {
          "name": "B. Goertzel",
          "authorId": "1738080"
        },
        {
          "name": "L. Vepstas",
          "authorId": "2043228"
        },
        {
          "name": "David Hanson",
          "authorId": "2067443379"
        },
        {
          "name": "Changle Zhou",
          "authorId": "2110841882"
        }
      ],
      "year": 2017,
      "abstract": "A new model of symbol grounding is presented, in which the structures of natural language, logical semantics, perception and action are represented categorically, and symbol grounding is modeled via the composition of morphisms between the relevant categories. This model gives conceptual insight into the fundamentally systematic nature of symbol grounding, and also connects naturally to practical real-world AI systems in current research and commercial use. Specifically, it is argued that the structure of linguistic syntax can be modeled as a certain asymmetric monoidal category, as e.g. implicit in the link grammar formalism; the structure of spatiotemporal relationships and action plans can be modeled similarly using \"image grammars\" and \"action grammars\"; and common-sense logical semantic structure can be modeled using dependently-typed lambda calculus with uncertain truth values. Given these formalisms, the grounding of linguistic descriptions in spatiotemporal perceptions and coordinated actions consists of following morphisms from language to logic through to spacetime and body (for comprehension), and vice versa (for generation). The mapping is indicated between the spatial relationships in the Region Connection Calculus and Allen Interval Algebra and corresponding entries in the link grammar syntax parsing dictionary. Further, the abstractions introduced here are shown to naturally model the structures and systems currently being deployed in the context of using the OpenCog cognitive architecture to control Hanson Robotics humanoid robots.",
      "citationCount": 7,
      "doi": null,
      "arxivId": "1703.04368",
      "url": "https://www.semanticscholar.org/paper/014958763a88e38e215a94f41311d0a772b94781",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/1703.04368"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "eeee2d5f636d01ec00fae1fd856fdf930230a546",
      "title": "An Epistemological Approach to the Symbol Grounding Problem - The Difference Between Perception and Demonstrative Knowledge and Two Ways of Being Meaningful",
      "authors": [
        {
          "name": "Jodi Guazzini",
          "authorId": "103531747"
        }
      ],
      "year": 2017,
      "abstract": null,
      "citationCount": 2,
      "doi": "10.1007/978-3-319-96448-5_4",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/eeee2d5f636d01ec00fae1fd856fdf930230a546",
      "venue": "Conference on Philosophy and Theory of Artificial Intelligence",
      "journal": {
        "pages": "36-39"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "1b26adab948c797d9410a3952bf42a6ffb0cde55",
      "title": "Semantics and symbol grounding in Turing machine processes",
      "authors": [
        {
          "name": "Anna Sarosiek",
          "authorId": "2079469189"
        }
      ],
      "year": 2018,
      "abstract": "The aim of the paper is to present the underlying reason of the unsolved symbol grounding problem. The Church-Turing Thesis states that a physical problem, for which there is an algorithm of solution, can be solved by a Turing machine, but machine operations neglect the semantic relationship between symbols and their meaning. Symbols are objects that are manipulated on rules based on their shapes. The computations are independent of the context, mental states, emotions, or feelings. The symbol processing operations are interpreted by the machine in a way quite different from the cognitive processes. Cognitive activities of living organisms and computation differ from each other, because of the way they act in the real word. The result is the problem of mutual understanding of symbol grounding.",
      "citationCount": 1,
      "doi": "10.15633/SS.2492",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/1b26adab948c797d9410a3952bf42a6ffb0cde55",
      "venue": "Semina Scientiarum",
      "journal": {
        "name": "Semina Scientiarum"
      },
      "publicationTypes": null
    },
    {
      "paperId": "7b3a26eb954ec159cd2faf7862233736b169a153",
      "title": "Meaning and the Machine:Beyond the Symbol-Grounding Problem",
      "authors": [
        {
          "name": "Terry McDonough",
          "authorId": "71293733"
        }
      ],
      "year": 2018,
      "abstract": null,
      "citationCount": 0,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7b3a26eb954ec159cd2faf7862233736b169a153",
      "venue": "",
      "journal": {
        "name": "",
        "volume": ""
      },
      "publicationTypes": null
    },
    {
      "paperId": "4a8fbf446baa8ac226fd81a4e4a077f12f639791",
      "title": "First-person experience, artificial intelligence and the symbol grounding problem",
      "authors": [
        {
          "name": "\u0413\u0430\u0441\u043f\u0430\u0440\u044f\u043d \u0414\u0438\u0430\u043d\u0430 \u042d\u0434\u0438\u043a\u043e\u0432\u043d\u0430",
          "authorId": "2099072373"
        }
      ],
      "year": 2017,
      "abstract": null,
      "citationCount": 0,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4a8fbf446baa8ac226fd81a4e4a077f12f639791",
      "venue": "",
      "journal": {
        "name": "",
        "volume": ""
      },
      "publicationTypes": null
    },
    {
      "paperId": "b1a01ed1105c821797ee5626a3b0894e3c701b9a",
      "title": "Symbol Grounding Problem and causal theory of reference",
      "authors": [
        {
          "name": "K. Bielecka",
          "authorId": "2325880"
        }
      ],
      "year": 2016,
      "abstract": null,
      "citationCount": 8,
      "doi": "10.1016/J.NEWIDEAPSYCH.2015.01.006",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/b1a01ed1105c821797ee5626a3b0894e3c701b9a",
      "venue": "",
      "journal": {
        "name": "New Ideas in Psychology",
        "pages": "77-85",
        "volume": "40"
      },
      "publicationTypes": null
    },
    {
      "paperId": "83b4d29e4048c6b21732fd7193e7be805bfd5577",
      "title": "Information in the philosophy of AI and the symbol grounding problem",
      "authors": [
        {
          "name": "S. Bringsjord",
          "authorId": "1797985"
        }
      ],
      "year": 2016,
      "abstract": null,
      "citationCount": 0,
      "doi": "10.4324/9781315757544.CH11",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/83b4d29e4048c6b21732fd7193e7be805bfd5577",
      "venue": "",
      "journal": {
        "name": "",
        "volume": ""
      },
      "publicationTypes": null
    },
    {
      "paperId": "bae295eecc2efcc0a744079c6c60d1fa6b0959e0",
      "title": "The symbol grounding problem \u2026 remains unsolved",
      "authors": [
        {
          "name": "S. Bringsjord",
          "authorId": "1797985"
        }
      ],
      "year": 2015,
      "abstract": null,
      "citationCount": 12,
      "doi": "10.1080/0952813X.2014.940139",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/bae295eecc2efcc0a744079c6c60d1fa6b0959e0",
      "venue": "Journal of experimental and theoretical artificial intelligence (Print)",
      "journal": {
        "name": "Journal of Experimental & Theoretical Artificial Intelligence",
        "pages": "63 - 72",
        "volume": "27"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "7ac9cdd3c00ffb7ff4d31a063b8c2ced94d2f910",
      "title": "A Critical Review on the Symbol Grounding Problem as an Issue of Autonomous Agents",
      "authors": [
        {
          "name": "Richard Cubek",
          "authorId": "1737168"
        },
        {
          "name": "W. Ertel",
          "authorId": "1710696"
        },
        {
          "name": "G. Palm",
          "authorId": "1774384"
        }
      ],
      "year": 2015,
      "abstract": null,
      "citationCount": 12,
      "doi": "10.1007/978-3-319-24489-1_21",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7ac9cdd3c00ffb7ff4d31a063b8c2ced94d2f910",
      "venue": "Deutsche Jahrestagung f\u00fcr K\u00fcnstliche Intelligenz",
      "journal": {
        "pages": "256-263"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    }
  ],
  "count": 20,
  "errors": []
}
